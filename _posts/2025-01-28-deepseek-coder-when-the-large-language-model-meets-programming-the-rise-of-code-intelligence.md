---
layout: post
title: "DeepSeek-Coder: When the Large Language Model Meets Programming - The Rise of Code Intelligence"
date: 2024-01-25 14:17:53
author: "DeepSeek-AI"
categories: "Language-Models"
tags: ["Repository-Level-Data-Construction", "Fill-in-the-Middle-Code-Completion", "Cross-File-Code-Completion", "Long-Context-Adaptation", "Instruction-Tuning", "Grouped-Query-Attention", "Rotary-Positional-Embeddings"]
cover: /assets/images/language-models.jpg
use_math: true
---
### TL;DR
#### 이 연구를 시작하게 된 배경과 동기는 무엇입니까?
최근 CodeLlama와 StarCoder 등의 연구를 통해 대규모 언어 모델의 코드 도메인 적용이 큰 잠재력을 보여주었습니다. 그러나 대부분의 강력한 코드 생성 모델들이 비공개 소스로 제공되어 광범위한 연구와 개발이 제한되는 문제가 있었습니다. 또한 기존 모델들은 프로젝트 수준의 코드 이해와 생성에 한계를 보였으며, 자연어 이해와 수학적 추론 능력이 부족했습니다. DeepSeek-Coder는 이러한 한계를 극복하고 오픈소스 기반의 고성능 코드 생성 모델을 개발하고자 시작되었습니다.

#### 이 연구에서 제시하는 새로운 해결 방법은 무엇입니까?
DeepSeek-Coder는 세 가지 주요 혁신을 제시합니다. 첫째, 87개 프로그래밍 언어를 포괄하는 2조 개의 토큰으로 구성된 대규모 데이터셋을 구축하고, 저장소 수준의 데이터 구성 방식을 도입하여 파일 간 상호 관계를 이해하도록 했습니다. 둘째, Fill-In-Middle(FIM) 학습 전략을 도입하여 코드의 중간 부분을 채우는 능력을 향상시켰습니다. 셋째, 16K 토큰의 확장된 컨텍스트 윈도우를 통해 더 복잡하고 긴 코딩 작업을 처리할 수 있게 했습니다.

#### 제안된 방법은 어떻게 구현되었습니까?
구현은 크게 세 단계로 이루어졌습니다. 먼저, GitHub 데이터 크롤링과 엄격한 필터링 과정을 통해 고품질의 코드 데이터셋을 구축했습니다. 이 과정에서 의존성 파싱과 위상 정렬 알고리즘을 활용하여 파일 간 관계를 분석했습니다. 다음으로, FIM 학습을 위해 PSM(Prefix-Suffix-Middle)과 SPM(Suffix-Prefix-Middle) 모드를 구현하고, 50% PSM 비율을 최적의 학습 정책으로 선택했습니다. 마지막으로, DeepSeek-LLM-7B Base 모델을 기반으로 추가 사전 학습을 진행하여 자연어 이해와 수학적 추론 능력을 향상시켰습니다.

#### 이 연구의 결과가 가지는 의미는 무엇입니까?
이 연구의 결과는 코드 생성 분야에서 중요한 의미를 갖습니다. DeepSeek-Coder-Base 33B는 다양한 벤치마크에서 기존 오픈소스 모델들을 능가했으며, 특히 6.7B 모델이 34B 파라미터의 CodeLlama와 대등한 성능을 보여준 것은 효율적인 모델 설계의 중요성을 입증했습니다. 또한 DeepSeek-Coder-Instruct 33B가 GPT-3.5 Turbo를 능가하는 성능을 보여준 것은 오픈소스 모델도 상업용 모델과 경쟁할 수 있음을 증명했습니다. 더불어 DeepSeek-Coder-v1.5의 개발을 통해 코드 생성 모델이 강력한 일반 목적 언어 모델을 기반으로 구축되어야 한다는 새로운 방향성을 제시했습니다.
- - -
## DeepSeek-Coder: 코드 인텔리전스의 부상과 대규모 언어 모델의 만남

최근 CodeLlama와 StarCoder 등의 연구에서 보여준 것처럼, 대규모 언어 모델을 코드 도메인에 적용하는 것은 소프트웨어 개발 분야에서 큰 잠재력을 보여주고 있습니다. DeepSeek-Coder는 이러한 흐름을 더욱 발전시켜, 코드 생성과 이해 능력을 한 단계 높은 수준으로 끌어올리는 것을 목표로 합니다.

이 연구는 코드 인텔리전스 분야에서 중요한 전환점을 제시합니다. 특히 SantaCoder와 InCoder 등 이전 연구들이 보여준 한계를 극복하고, 더욱 정교한 코드 생성 능력을 구현하고자 했습니다. DeepSeek-Coder는 대규모 언어 모델의 강력한 표현력과 코드 특화 학습을 결합하여, 프로그래밍 분야에서 실질적인 도움을 줄 수 있는 도구로 발전하고자 합니다.

## DeepSeek-Coder: 코드 인텔리전스의 혁신과 오픈소스의 만남

### 서론

대규모 언어 모델의 급속한 발전은 소프트웨어 개발 분야의 코드 인텔리전스를 혁신적으로 변화시켰습니다. 그러나 대부분의 강력한 모델들이 비공개 소스로 제공되어 광범위한 연구와 개발이 제한되는 문제가 있었습니다. 이러한 한계를 극복하고자 DeepSeek-Coder 시리즈를 소개합니다. 이 모델은 1.3B부터 33B까지 다양한 크기로 제공되며, 2조 개의 토큰으로 처음부터 학습된 오픈소스 코드 모델입니다.

DeepSeek-Coder는 고품질의 프로젝트 수준 코드 데이터셋으로 사전 학습되었으며, 16K 윈도우 크기의 Fill-in-the-blank 태스크를 활용하여 코드 생성과 채우기 능력을 향상시켰습니다. 광범위한 평가 결과, DeepSeek-Coder는 다양한 벤치마크에서 기존 오픈소스 코드 모델들을 능가할 뿐만 아니라, Codex와 GPT-3.5와 같은 비공개 모델들의 성능도 뛰어넘는 것으로 나타났습니다.

![성능 비교](https://ar5iv.org//html/2401.14196/assets/figures/PLT.png)

위 그림은 LeetCode 주간 코딩 대회에서 다양한 AI/ML 모델들의 성능을 비교한 것입니다. 레이더 차트는 Python, Java, JavaScript, C# 등 여러 프로그래밍 언어에서의 성능을 보여주며, DeepSeek-Coder-7B와 DeepSeek-Coder-33B가 다양한 언어에서 우수한 성능을 보여주고 있습니다. 이는 자동화된 코드 생성과 경쟁 프로그래밍 과제 해결 능력에서 큰 발전을 이루었음을 시사합니다.

특히 주목할 만한 점은 DeepSeek-Coder 모델이 연구와 상업적 사용 모두를 허용하는 개방적인 라이선스 하에 제공된다는 것입니다. 이는 코드 인텔리전스 분야의 발전을 가속화하고, 더 많은 연구자와 개발자들이 혁신적인 기술을 활용할 수 있게 해줄 것으로 기대됩니다.
### 연구의 주요 기여

DeepSeek-Coder 시리즈는 코드 인텔리전스 분야에서 몇 가지 중요한 혁신을 이루었습니다. 먼저, 87개의 프로그래밍 언어를 포괄하는 2조 개의 토큰으로 구성된 대규모 데이터셋을 활용하여 모델을 학습시켰습니다. 이는 기존의 오픈소스 모델들이 다루지 못했던 규모와 다양성을 제공합니다.

특히 주목할 만한 점은 저장소 수준의 데이터 구성 방식입니다. 이는 단순히 개별 파일 단위의 코드를 학습하는 것을 넘어서, 저장소 내의 파일 간 상호 관계를 이해하고 활용할 수 있도록 합니다. 이러한 접근 방식은 크로스파일 코드 생성 능력을 크게 향상시켰습니다.

Fill-In-Middle(FIM) 학습 전략의 도입도 중요한 혁신입니다. 이 방식은 기존의 다음 토큰 예측 손실 함수와 함께 사용되어, 모델의 코드 완성 능력을 더욱 강화했습니다. Li와 연구진과 Bavarian과 연구진의 연구를 기반으로 한 이 접근법은 코드의 중간 부분을 채우는 능력을 향상시켜, 더욱 자연스럽고 정확한 코드 생성을 가능하게 합니다.

16K 토큰의 확장된 컨텍스트 길이는 더 복잡하고 긴 코딩 작업을 처리할 수 있게 해줍니다. 이는 실제 개발 환경에서 자주 발생하는 대규모 코드베이스 작업에 특히 유용합니다. 이러한 기술적 혁신들의 결과로, DeepSeek-Coder-Base 33B는 모든 벤치마크에서 기존 오픈소스 코드 모델들을 능가하는 성능을 보여주었으며, DeepSeek-Coder-Instruct 33B는 OpenAI GPT-3.5 Turbo를 대부분의 평가 지표에서 앞서는 결과를 달성했습니다.

특히 주목할 만한 점은 DeepSeek-Coder-Base 7B가 CodeLlama-33B와 같은 5배 더 큰 모델들과 비교해도 경쟁력 있는 성능을 보여준다는 것입니다. 이는 모델 아키텍처의 효율성과 학습 방법론의 우수성을 입증하는 결과입니다.
### 연구 방법론의 혁신성

DeepSeek-Coder의 핵심 기술적 혁신은 대규모 코드 데이터셋의 효과적인 활용에 있습니다. 87개 프로그래밍 언어에서 수집된 2조 개의 토큰을 활용한 학습 과정에서, 저자들은 단순한 토큰 수준의 학습을 넘어서는 혁신적인 접근 방식을 도입했습니다. 특히 저장소 수준의 데이터 구성은 코드의 문맥적 이해를 크게 향상시켰습니다.

Fill-In-Middle 학습 방식은 코드 생성의 유연성을 획기적으로 개선했습니다. 이 방식은 다음과 같은 수식으로 표현됩니다.

\\[ P_{\text{FIM}}(\text{middle} \vert \text{prefix}, \text{suffix}) = \frac{1}{Z} \exp(\text{score}(\text{prefix}, \text{middle}, \text{suffix})) \\]

여기서 \\( Z \\)는 정규화 상수이며, score 함수는 주어진 prefix와 suffix 사이에 들어갈 middle 부분의 적합성을 평가합니다. 이러한 접근 방식은 기존의 단방향 생성 모델의 한계를 극복하고, 코드의 전후 문맥을 모두 고려한 자연스러운 코드 생성을 가능하게 합니다.

16K 토큰의 확장된 컨텍스트 윈도우는 실제 개발 환경에서 발생하는 복잡한 코드 구조를 더 효과적으로 처리할 수 있게 해줍니다. 이는 다음과 같은 이점을 제공합니다.

\\[ \text{Context}_{\text{effective}} = \min(16384, \text{length}(\text{code})) \\]

이러한 기술적 혁신들의 조합은 DeepSeek-Coder가 기존 모델들과 차별화되는 핵심 요소입니다. 특히 저장소 수준의 데이터 구성은 다음과 같은 학습 목표를 통해 구현됩니다.

\\[ \mathcal{L}\_{\text{repo}} = \sum_{f \in \text{Files}} \mathcal{L}\_{\text{FIM}}(f) + \lambda \sum_{(f_i, f_j) \in \text{Related}} \mathcal{L}_{\text{cross}}(f_i, f_j) \\]

여기서 \\( \mathcal{L}\_{\text{FIM}} \\)은 개별 파일에 대한 Fill-In-Middle 손실이며, \\( \mathcal{L}_{\text{cross}} \\)는 관련된 파일들 간의 크로스 파일 이해도를 향상시키기 위한 손실 함수입니다. \\( \lambda \\)는 두 목표 간의 균형을 조절하는 하이퍼파라미터입니다.
### 실험 결과와 성능 평가

DeepSeek-Coder의 성능 평가는 다양한 공개 코드 관련 벤치마크를 통해 수행되었습니다. 특히 HumanEval, MBPP, LeetCode 주간 코딩 대회 등에서 모델의 코드 생성 및 문제 해결 능력을 종합적으로 평가했습니다. DeepSeek-Coder-Base 33B는 모든 벤치마크에서 기존 오픈소스 모델들을 능가하는 성능을 보여주었으며, 특히 주목할 만한 점은 DeepSeek-Coder-Instruct 33B가 OpenAI GPT-3.5 Turbo의 성능을 뛰어넘었다는 것입니다.

성능 평가는 다음과 같은 수식적 지표를 기반으로 이루어졌습니다.

\\[ \text{Performance}\_{\text{overall}} = \frac{1}{N} \sum_{i=1}^{N} \text{score}(\text{task}_i) \cdot w_i \\]

여기서 \\( N \\)은 평가 태스크의 총 수이며, \\( w_i \\)는 각 태스크의 가중치를 나타냅니다. 특히 코드 생성 태스크에서는 다음과 같은 평가 지표를 사용했습니다.

\\[ \text{CodeQuality} = \alpha \cdot \text{Correctness} + \beta \cdot \text{Efficiency} + \gamma \cdot \text{Readability} \\]

여기서 \\( \alpha, \beta, \gamma \\)는 각각 정확성, 효율성, 가독성에 대한 가중치를 나타냅니다.

### 모델 아키텍처의 효율성

DeepSeek-Coder의 주목할 만한 특징 중 하나는 모델 크기 대비 높은 성능입니다. 특히 DeepSeek-Coder-Base 7B가 CodeLlama-33B와 같은 훨씬 큰 모델들과 비교해도 경쟁력 있는 성능을 보여주는 것은 매우 중요한 의미를 갖습니다. 이는 모델 아키텍처의 효율성과 학습 방법론의 우수성을 입증하는 결과입니다.

이러한 효율성은 다음과 같은 최적화된 학습 전략을 통해 달성되었습니다.

\\[ \mathcal{L}\_{\text{total}} = \mathcal{L}\_{\text{base}} + \alpha \mathcal{L}\_{\text{FIM}} + \beta \mathcal{L}_{\text{repo}} \\]

여기서 \\( \mathcal{L}\_{\text{base}} \\)는 기본적인 언어 모델링 손실, \\( \mathcal{L}\_{\text{FIM}} \\)은 Fill-In-Middle 학습에 대한 손실, \\( \mathcal{L}_{\text{repo}} \\)는 저장소 수준의 이해도를 향상시키기 위한 손실을 나타냅니다. \\( \alpha \\)와 \\( \beta \\)는 각 손실 함수의 상대적 중요도를 조절하는 하이퍼파라미터입니다.

### 데이터 수집 및 전처리

DeepSeek-Coder의 학습 데이터셋은 소스 코드 87%, 영어 코드 관련 자연어 말뭉치 10%, 코드와 무관한 중국어 자연어 말뭉치 3%로 구성되어 있습니다. 영어 말뭉치는 GitHub의 마크다운 문서와 StackExchange에서 수집한 자료들로, 모델이 코드 관련 개념을 이해하고 라이브러리 사용법이나 버그 수정과 같은 작업을 수행하는 능력을 향상시키는 데 활용됩니다. 중국어 말뭉치는 고품질 문서들로 구성되어 있으며, 모델의 중국어 이해력을 높이는 데 사용됩니다.

![데이터셋 생성 절차](https://ar5iv.org//html/2401.14196/assets/x1.png)

위 그림은 데이터셋 생성 절차를 보여줍니다. 데이터 크롤링부터 시작하여 규칙 기반 필터링, 의존성 파싱, 저장소 수준의 중복 제거, 품질 검사에 이르는 전체 과정을 단계별로 나타내고 있습니다. 이러한 체계적인 접근을 통해 고품질의 학습 데이터를 구축할 수 있습니다.

#### GitHub 데이터 크롤링 및 필터링

2023년 2월 이전에 생성된 GitHub의 공개 저장소들을 수집하여, 87개의 프로그래밍 언어만을 선별했습니다. 데이터 처리량을 줄이기 위해 StarCoder 프로젝트에서 사용된 것과 유사한 필터링 규칙을 적용하여 낮은 품질의 코드를 사전에 제거했습니다. 이러한 필터링을 통해 전체 데이터의 32.8%만을 유지했습니다.

주요 필터링 규칙은 다음과 같습니다.
- 평균 줄 길이가 100자를 초과하거나 최대 줄 길이가 1000자를 넘는 파일 제외
- 알파벳 문자가 25% 미만인 파일 제거
- XSLT를 제외한 모든 언어에서 처음 100자 이내에 "<?xml version="이 포함된 파일 제외
- HTML 파일의 경우 가시적 텍스트와 HTML 코드의 비율을 고려하여, 가시적 텍스트가 전체 코드의 20% 이상이면서 100자 이상인 파일만 유지
- JSON과 YAML 파일은 데이터 중심 파일이 많으므로 50자에서 5000자 사이의 파일만 유지

#### 의존성 파싱

기존 연구들에서는 주로 파일 단위의 소스 코드로 사전 학습을 진행했지만, 이는 프로젝트 수준의 코드 시나리오를 효과적으로 처리하는 데 한계가 있었습니다. 이를 해결하기 위해 저장소 내 파일들 간의 의존성을 고려한 새로운 접근 방식을 도입했습니다.

파일 간의 의존성을 파싱하고, 각 파일이 의존하는 컨텍스트가 입력 시퀀스에서 해당 파일보다 앞에 위치하도록 정렬합니다. Python의 "import", C#의 "using", C의 "include"와 같은 호출 관계를 정규 표현식을 사용하여 추출합니다.
#### 의존성 분석을 위한 위상 정렬 알고리즘

의존성 분석을 위해 위상 정렬 알고리즘을 구현했습니다. 이 알고리즘은 파일들 간의 의존 관계를 그래프로 표현하고, 의존성을 고려한 순서로 파일들을 정렬합니다. 알고리즘의 핵심은 각 파일의 진입 차수(in-degree)를 추적하면서 최소 진입 차수를 가진 노드를 순차적으로 선택하는 것입니다.

알고리즘은 먼저 빈 인접 리스트 `graphs`와 진입 차수를 저장할 딕셔너리 `inDegree`를 초기화합니다. 모든 파일 쌍에 대해 의존성을 검사하여 그래프를 구성하고, 의존성이 발견될 때마다 해당 파일의 진입 차수를 증가시킵니다. 이후 연결되지 않은 서브그래프들을 식별하고, 각 서브그래프에 대해 수정된 위상 정렬을 수행합니다.

위상 정렬 과정에서는 표준적인 접근 방식과 달리 진입 차수가 0인 노드가 아닌, 최소 진입 차수를 가진 노드를 선택합니다. 이는 그래프 내의 순환 의존성을 처리할 수 있게 해줍니다. 선택된 노드는 결과 리스트에 추가되고, 해당 노드와 연결된 노드들의 진입 차수가 감소됩니다.

#### 저장소 수준의 중복 제거

대규모 언어 모델의 학습 데이터셋에서 중복 제거의 중요성은 여러 연구를 통해 입증되었습니다. 특히 Lee와 연구진은 언어 모델 학습 말뭉치에 많은 근접 중복이 존재하며, 긴 반복 문자열을 제거함으로써 모델의 성능을 향상시킬 수 있음을 보여주었습니다. Kocetkov와 연구진도 근접 중복 제거 방법을 적용하여 획기적인 성능 향상을 달성했으며, 코드 벤치마크 태스크에서 경쟁력 있는 성능을 얻기 위해서는 근접 중복 제거가 핵심적인 전처리 단계임을 강조했습니다.

DeepSeek-Coder에서는 기존 연구들과 차별화된 접근 방식을 채택했습니다. 파일 수준이 아닌 저장소 수준에서 중복 제거를 수행함으로써, 저장소의 구조적 완전성을 보존했습니다. 파일 수준의 중복 제거는 저장소 내 특정 파일들을 필터링하여 저장소의 구조를 훼손할 수 있기 때문입니다. 구체적으로, 저장소 수준에서 연결된 코드를 하나의 샘플로 취급하고 동일한 근접 중복 제거 알고리즘을 적용하여 저장소 구조의 무결성을 유지했습니다.
#### 품질 검사와 오염 방지

앞서 언급한 필터링 규칙 외에도 컴파일러와 품질 모델, 그리고 휴리스틱 규칙을 조합하여 저품질 데이터를 추가로 필터링했습니다. 이는 구문 오류가 있는 코드, 가독성이 떨어지는 코드, 모듈화가 부족한 코드 등을 제거하는 과정을 포함합니다.

테스트 셋의 정보가 GitHub에 존재할 수 있는 학습 데이터 오염을 방지하기 위해 n-gram 필터링 프로세스를 구현했습니다. 이 과정에서 HumanEval, MBPP, GSM8K, MATH 등의 소스에서 나온 docstring, 문제, 해답을 포함하는 파일들을 제거했습니다.

필터링 기준은 다음과 같은 규칙을 적용했습니다.
- 테스트 데이터와 동일한 10-gram 문자열을 포함하는 코드는 학습 데이터에서 제외
- 테스트 데이터의 문자열이 10-gram보다 짧지만 3-gram 이상인 경우, 정확한 매칭 방식으로 필터링

이러한 엄격한 품질 관리와 오염 방지 절차를 통해, 모델이 테스트 데이터를 사전에 접하지 않도록 보장하면서도 고품질의 학습 데이터를 구축할 수 있었습니다. 특히 Java가 전체 데이터의 18.63%로 가장 큰 비중을 차지하며, Python이 15.12%, C++가 11.39%로 그 뒤를 잇고 있습니다. 이는 현대 소프트웨어 개발에서 이들 언어의 중요성과 활용도를 반영합니다.

### 학습 정책

#### 학습 전략

DeepSeek-Coder의 학습은 두 가지 핵심 목표를 중심으로 이루어집니다. 첫 번째는 다음 토큰 예측(Next Token Prediction)이며, 두 번째는 중간 채우기(Fill-in-the-Middle, FIM) 방식입니다.

다음 토큰 예측은 고정 길이의 입력을 구성하기 위해 여러 파일들을 연결하고, 이를 기반으로 모델이 주어진 컨텍스트에서 다음에 올 토큰을 예측하도록 학습하는 방식입니다.

중간 채우기 방식은 코드 사전 학습 과정에서 특히 중요한 역할을 합니다. 프로그래밍 언어의 특수한 의존성으로 인해 단순한 다음 토큰 예측만으로는 주어진 컨텍스트와 이후 텍스트를 기반으로 중간에 들어갈 내용을 생성하는 능력을 충분히 학습하기 어렵기 때문입니다. 이를 해결하기 위해 Bavarian과 연구진, Li와 연구진이 제안한 Fill-in-the-Middle(FIM) 방식을 도입했습니다.

FIM은 텍스트를 세 부분으로 무작위로 나누고, 이 부분들의 순서를 재배치한 뒤 특수 문자로 연결하여 중간 채우기 사전 학습 태스크를 수행합니다. 이 방식은 PSM(Prefix-Suffix-Middle)과 SPM(Suffix-Prefix-Middle)이라는 두 가지 모드로 구현됩니다.

![FIM 목표의 효과성](https://ar5iv.org//html/2401.14196/assets/x2.png)

PSM 모드에서는 텍스트가 \\( \text{Prefix}, \text{Suffix}, \text{Middle} \\) 순서로 구성되어 중간 세그먼트가 접두사와 접미사 사이에 위치하게 됩니다. 반면 SPM 모드는 \\( \text{Suffix}, \text{Prefix}, \text{Middle} \\) 순서로 구성되어 다른 구조적 도전 과제를 제시합니다.

FIM 접근 방식의 효과를 검증하기 위해 일련의 실험을 수행했습니다. DeepSeek-Coder-Base 1.3B 모델을 사용하여 학습 데이터셋의 Python 서브셋에 대해 실험을 진행했으며, HumanEval-FIM 벤치마크를 통해 FIM 기법의 효과를 평가했습니다. 이 벤치마크는 HumanEval 솔루션에서 한 줄의 코드를 무작위로 가려두고 모델이 이를 예측하는 단일 라인 FIM 태스크입니다.

실험 결과, 100% FIM 비율에서 HumanEval-FIM에서 최고 성능을 보였지만, 이 경우 코드 완성 능력이 가장 약했습니다. 이는 FIM과 코드 완성 능력 사이의 트레이드오프가 존재함을 보여줍니다. 또한 50% PSM 비율이 MSP(Masked Span Prediction) 전략보다 우수한 성능을 보였습니다.

이러한 결과를 바탕으로 FIM 효율성과 코드 완성 능력의 균형을 위해 50% PSM 비율을 최종 학습 정책으로 선택했습니다. 구현에는 세 개의 특수 토큰을 도입했으며, 각 코드 파일을 \\( f_{\text{pre}} \\), \\( f_{\text{middle}} \\), \\( f_{\text{suf}} \\) 세 부분으로 나누어 다음과 같은 형식으로 학습 예제를 구성합니다.

\\[ \texttt{<\｜fim\_start\｜>}f_{\text{pre}}\texttt{<\｜fim\_hole\｜>}f_{\text{suf}}\texttt{<\｜fim\_end\｜>}f_{\text{middle}}\texttt{<\|eos\_token\|>} \\]

### 실험 결과 분석

DeepSeek-Coder의 성능을 평가하기 위해 코드 생성, FIM 코드 완성, 크로스 파일 코드 완성, 프로그램 기반 수학적 추론 등 네 가지 주요 과제에서 실험을 진행했습니다. 이 평가에서는 CodeGeeX2, StarCoder, CodeLlama, code-cushman-001, GPT-3.5, GPT-4와 같은 최신 대규모 언어 모델들과 비교 분석을 수행했습니다.

#### 코드 생성 성능 평가

HumanEval과 MBPP 벤치마크에서의 평가 결과, DeepSeek-Coder-Base는 HumanEval에서 평균 50.3%, MBPP에서 66.0%의 정확도를 달성했습니다. 특히 주목할 만한 점은 6.7B 파라미터 모델이 34B 파라미터를 가진 CodeLlama-Base보다 우수한 성능을 보였다는 것입니다. 명령어 미세조정 후에는 DeepSeek-Coder-Instruct가 GPT-3.5-Turbo의 성능을 능가했으며, OpenAI GPT-4와의 성능 격차를 크게 줄였습니다.

DS-1000 벤치마크 평가에서는 실제 데이터 과학 워크플로우에서의 코드 생성 능력을 테스트했습니다. 이 벤치마크는 Matplotlib, NumPy, Pandas, SciPy, Scikit-Learn, PyTorch, TensorFlow 등 7개 주요 라이브러리에 걸쳐 1,000개의 실용적인 태스크를 포함하고 있습니다. DeepSeek-Coder는 모든 라이브러리에서 높은 정확도를 보여주며, 실제 데이터 과학 워크플로우에서도 효과적으로 활용될 수 있음을 입증했습니다.

LeetCode 콘테스트 벤치마크에서는 2023년 7월부터 2024년 1월까지의 최신 문제들을 수집하여 평가를 진행했습니다. DeepSeek-Coder-Instruct 6.7B와 33B 모델은 각각 19.4%와 27.8%의 Pass@1 점수를 달성했으며, 특히 33B 모델은 GPT-3.5-Turbo를 능가하는 유일한 오픈소스 모델이 되었습니다. 체인 오브 소트(Chain-of-Thought) 프롬프팅을 적용했을 때 더 나은 성능을 보였으며, 특히 복잡한 문제에서 그 효과가 두드러졌습니다.

#### FIM 코드 완성 평가

DeepSeek-Coder 모델들은 사전 학습 과정에서 0.5의 FIM(Fill-In-the-Middle) 비율로 학습되었습니다. 이를 통해 주변 컨텍스트를 기반으로 코드의 빈 부분을 채우는 능력을 갖추게 되었습니다. Single-Line Infilling 벤치마크에서 평가한 결과, 1.3B 파라미터의 가장 작은 모델조차도 StarCoder와 CodeLlama와 같은 더 큰 모델들보다 우수한 성능을 보여주었습니다.

#### 크로스 파일 코드 완성 평가

크로스 파일 코드 완성 태스크에서는 Python, Java, TypeScript, C# 등 네 가지 프로그래밍 언어에 대해 평가를 진행했습니다. DeepSeek-Coder는 다른 모델들과 비교했을 때 일관되게 우수한 성능을 보여주었으며, 특히 저장소 수준의 사전 학습이 Java, TypeScript, C# 언어에서의 성능 향상에 기여했음을 확인했습니다.

#### 프로그램 기반 수학적 추론 평가

프로그램 기반 수학적 추론 능력을 평가하기 위해 PAL(Program-Aided Math Reasoning) 방법을 사용하여 GSM8K, MATH, GSM-Hard, SVAMP, TabMWP, ASDiv, MAWPS 등 7개의 벤치마크에서 평가를 진행했습니다. DeepSeek-Coder 모델들은 모든 벤치마크에서 뛰어난 성능을 보여주었으며, 특히 33B 변형 모델은 복잡한 수학적 계산과 문제 해결이 필요한 응용 분야에서의 잠재력을 입증했습니다.

### DeepSeek-Coder-v1.5: 일반 언어 모델을 통한 성능 향상

DeepSeek-Coder 모델의 자연어 이해와 수학적 추론 능력을 더욱 향상시키기 위해, 연구진은 DeepSeek-LLM-7B Base 모델을 기반으로 추가적인 사전 학습을 진행했습니다. 이 과정에서 2조 개의 토큰으로 구성된 다양한 데이터셋을 활용하여 DeepSeek-Coder-v1.5 7B를 개발했습니다.

#### 사전 학습 데이터 구성

DeepSeek-Coder-v1.5의 사전 학습 데이터는 다음과 같이 구성되었습니다.

- 소스 코드: 70%
- 마크다운과 스택익스체인지: 10%
- 코드 관련 자연어: 7%
- 수학 관련 자연어: 7%
- 중국어-영어 이중 언어: 6%

이러한 데이터 구성은 모델이 프로그래밍 능력을 유지하면서도 자연어 이해와 수학적 추론 능력을 향상시킬 수 있도록 설계되었습니다. 특히 DeepSeek-Coder-v1.5는 4K 컨텍스트 길이를 사용하여 다음 토큰 예측 목표만을 활용한 사전 학습을 진행했습니다.

#### 성능 평가 결과

DeepSeek-Coder-v1.5 7B와 DeepSeek-Coder 6.7B의 성능을 비교하기 위해 다양한 벤치마크에서 평가를 진행했습니다. 평가는 크게 세 가지 영역으로 나누어 진행되었습니다.

1. 프로그래밍 능력
- HumanEval: 다국어 프로그래밍 과제 평가
- MBPP: Python 프로그래밍 과제 평가

2. 수학적 추론 능력
- GSM8K: 기초 수학 문제 해결
- MATH: 고급 수학 문제 해결

3. 자연어 처리 능력
- MMLU: 다양한 분야의 지식 평가
- BBH: 추론 능력 평가
- HellaSwag: 상식적 추론 능력 평가
- Winogrande: 상식 추론과 모호성 해소 능력 평가
- ARC-Challenge: 과학적 추론 능력 평가

평가 결과, DeepSeek-Coder-Base-v1.5는 프로그래밍 성능에서 약간의 감소를 보였지만, 수학적 추론과 자연어 처리 능력에서는 이전 모델을 크게 앞서는 것으로 나타났습니다. 특히 GSM8K에서는 62.4%(이전 43.2%), MATH에서는 24.7%(이전 19.2%)의 성능을 보여주었으며, MMLU에서도 49.1%(이전 36.6%)로 큰 향상을 보였습니다.

DeepSeek-Coder-Instruct-v1.5 모델 역시 수학적 추론과 자연어 처리 분야에서 뛰어난 성능 향상을 보여주었습니다. GSM8K에서 72.6%, MATH에서 34.1%의 성능을 달성했으며, MMLU에서도 49.5%의 높은 정확도를 기록했습니다.

## DeepSeek-Coder: 코드 생성의 새로운 지평

### 결론과 연구의 의의

DeepSeek-Coder는 코딩을 위한 특화된 대규모 언어 모델 시리즈로, 1.3B, 6.7B, 33B 파라미터의 세 가지 규모로 개발되었습니다. 이 모델들은 프로젝트 수준에서 세심하게 선별된 코드 데이터셋을 기반으로 학습되었으며, "fill-in-the-blank" 사전 학습 목표를 활용하여 코드 채우기 능력을 향상시켰습니다. 특히 주목할 만한 혁신은 컨텍스트 윈도우를 16,384 토큰으로 확장한 것으로, 이를 통해 광범위한 코드 생성 작업에서 모델의 효과성이 크게 향상되었습니다.

평가 결과에 따르면, DeepSeek-Coder 시리즈의 최상위 모델인 DeepSeek-Coder-Base 33B는 다양한 표준 테스트에서 기존의 오픈소스 코드 모델들을 능가하는 성능을 보여주었습니다. 특히 주목할 만한 점은 DeepSeek-Coder-Base 6.7B 모델이 더 큰 규모의 34B 파라미터를 가진 CodeLlama와 대등한 성능을 보여주었다는 것입니다. 이는 사전 학습 데이터셋의 품질이 얼마나 중요한지를 입증하는 결과입니다.

DeepSeek-Coder-Base 모델의 제로샷 명령어 수행 능력을 향상시키기 위해 고품질 명령어 데이터로 미세조정을 진행했습니다. 그 결과 DeepSeek-Coder-Instruct 33B 모델은 코드 생성과 이해 분야에서 OpenAI의 GPT-3.5 Turbo를 능가하는 뛰어난 성능을 보여주었습니다.

더 나아가 DeepSeek-Coder-Base 모델의 자연어 이해 능력을 향상시키기 위해 DeepSeek-LLM 7B 체크포인트를 기반으로 추가 사전 학습을 진행했습니다. 이 과정에서 자연어, 코드, 수학 데이터를 포함하는 20억 토큰 규모의 다양한 데이터셋을 활용했으며, 그 결과로 DeepSeek-Coder-v1.5가 탄생했습니다. 이 새로운 모델은 이전 버전의 뛰어난 코딩 성능을 유지하면서도 자연어 이해 능력이 크게 향상되었습니다.

이러한 연구 결과는 효과적인 코드 중심 대규모 언어 모델이 강력한 일반 목적 언어 모델을 기반으로 구축되어야 한다는 저자들의 견해를 뒷받침합니다. 그 이유는 명확합니다. 코딩 작업을 효과적으로 해석하고 실행하기 위해서는 다양한 형태의 자연어로 표현되는 인간의 지시사항을 깊이 있게 이해할 수 있어야 하기 때문입니다.

앞으로 연구진은 더 큰 규모의 일반 목적 언어 모델을 기반으로 더욱 강력한 코드 중심 대규모 언어 모델을 개발하고 공개할 계획입니다. 이는 코드 생성과 이해 분야에서 새로운 지평을 열 것으로 기대됩니다.

### DeepSeek-Coder의 실제 활용 사례 분석

DeepSeek-Coder의 실제 활용 능력을 검증하기 위해 두 가지 대표적인 사례를 살펴보았습니다. 첫 번째는 데이터베이스 구축과 데이터 분석을 포함하는 다중 턴 대화이며, 두 번째는 LeetCode 문제 해결에 관한 것입니다.

![데이터베이스 구축 및 분석 예시](https://ar5iv.org//html/2401.14196/assets/x4.png)

위 그림은 Python을 사용하여 학생 정보를 포함하는 SQLite 데이터베이스를 구축하는 과정을 보여줍니다. 이 예시에서는 커서 객체 생성, SQL 쿼리 실행, 테이블 생성, 데이터 삽입 등의 핵심 기술 구성 요소를 포함하고 있습니다. 특히 주목할 만한 점은 데이터베이스 생성 후 학생 정보를 활용한 데이터 분석과 시각화까지 이어지는 완성도 높은 코드를 생성했다는 것입니다.

![LeetCode 문제 해결 예시](https://ar5iv.org//html/2401.14196/assets/x5.png)

두 번째 사례는 토너먼트에서 우승 팀을 찾는 LeetCode 문제 해결 과정을 보여줍니다. 이 문제는 2023년 11월에 공개된 것으로, 모델의 학습 데이터에 포함되지 않은 새로운 문제입니다. 해결 방법은 토너먼트를 방향 그래프로 표현하고, 진입 차수와 진출 차수를 기반으로 우승 팀을 결정하는 위상 정렬 알고리즘을 활용합니다.

특히 주목할 만한 점은 DeepSeek-Coder가 학습 데이터 분포를 벗어난 문제도 효과적으로 해결할 수 있다는 것입니다. 모델은 문제를 정확히 이해하고, 버그 없는 완성도 높은 코드를 생성했으며, 각 단계에 대한 상세한 설명도 함께 제공했습니다. 이는 모델이 단순히 학습 데이터를 기억하는 것을 넘어서, 실제 프로그래밍 문제 해결에 필요한 추론 능력을 갖추고 있음을 보여줍니다.

### DeepSeek-Coder-Base의 학습 과정 벤치마크 분석

DeepSeek-Coder-Base 모델의 학습 과정에서 성능 변화를 면밀히 추적하기 위해 다양한 벤치마크 평가를 수행했습니다. 이 평가를 위해 학습 데이터에서 신중하게 선별된 8,000개의 코드 파일로 구성된 검증 세트를 활용했습니다. 이 검증 세트는 모델의 성능을 정확하게 평가하기 위해 다양한 프로그래밍 언어와 코딩 스타일을 포함하도록 구성되었습니다.

![학습 과정 벤치마크](https://ar5iv.org//html/2401.14196/assets/x6.png)

위 그래프는 DeepSeek-Coder-Base 모델의 학습 과정에서 다양한 평가 지표의 변화를 보여줍니다. 주요 평가 지표에는 HumanEval-Pass@1, HumanEval-cpp-Pass@1, HumanEval-java-Pass@1, MBPP-Pass@1, HumanEvalFIM-EM, MeanHumanEval, Validation-Completion-EM, Validation-Completion-FIM-EM이 포함됩니다.

각 평가 지표는 모델의 서로 다른 능력을 측정합니다. HumanEval 관련 지표들은 Python, C++, Java 등 다양한 프로그래밍 언어에서의 코드 생성 능력을 평가하며, FIM(Fill-in-the-Middle) 관련 지표들은 주어진 코드의 중간 부분을 채우는 능력을 측정합니다. 특히 Validation-Completion 지표들은 실제 개발 환경에서 자주 발생하는 코드 완성 태스크에서의 성능을 평가합니다.

학습 토큰 수가 증가함에 따라 모든 평가 지표에서 지속적인 성능 향상이 관찰되었습니다. 이는 DeepSeek-Coder-Base가 학습 과정에서 점진적으로 더 나은 코드 이해와 생성 능력을 획득했음을 보여줍니다. 특히 주목할 만한 점은 다양한 프로그래밍 언어에 걸쳐 균형 잡힌 성능 향상이 이루어졌다는 것입니다.

- - -
### References
* [DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence](http://arxiv.org/pdf/2401.14196v2)
