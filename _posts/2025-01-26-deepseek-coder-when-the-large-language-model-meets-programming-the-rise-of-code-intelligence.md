---
layout: post
title: "DeepSeek-Coder: When the Large Language Model Meets Programming - The Rise of Code Intelligence"
date: 2024-01-25 14:17:53
author: "DeepSeek-AI"
categories: "Language-Models"
tags: ["Repository-Level-Data-Construction", "Fill-in-the-Middle-Code-Completion", "Cross-File-Code-Completion", "Long-Context-Adaptation", "Instruction-Tuning", "Reinforcement-Learning-Oriented-Pretraining"]
use_math: true
cover: /assets/images/language-models.webp
---
### TL;DR
#### 이 연구를 시작하게 된 배경과 동기는 무엇입니까?
최근 CodeLlama와 StarCoder와 같은 코드 특화 언어 모델들이 등장하면서 프로그래밍 분야에서 AI의 활용 가능성이 크게 확대되었습니다. 그러나 대부분의 고성능 모델들이 비공개 소스로 운영되면서 연구와 개발에 제약이 있었습니다. DeepSeek-Coder 연구는 이러한 한계를 극복하고 실제 개발 환경에서 더욱 실용적으로 활용될 수 있는 오픈소스 코드 생성 모델을 개발하고자 시작되었습니다. 특히 프로젝트 수준의 코드 이해와 생성 능력을 갖춘 모델의 필요성이 연구의 주요 동기가 되었습니다.

#### 이 연구에서 제시하는 새로운 해결 방법은 무엇입니까?
DeepSeek-Coder는 세 가지 주요 혁신을 제시합니다. 첫째, 저장소 수준의 코드 데이터를 활용한 사전 학습 방식을 도입하여 프로젝트 전체 맥락에서의 코드 이해 능력을 향상시켰습니다. 둘째, 16K 윈도우를 활용한 fill-in-the-middle 접근 방식을 통해 코드 완성 능력을 강화했습니다. 셋째, 자연어 이해력 향상을 위해 코드, 수학, 자연어 데이터를 균형있게 조합한 추가 사전 학습을 실시했습니다. 특히 의존성 분석과 토폴로지 정렬을 통해 파일 간의 관계를 고려한 학습 방식은 이 연구만의 독특한 접근법입니다.

#### 제안된 방법은 어떻게 구현되었습니까?
구현은 1.3B부터 33B까지 다양한 규모의 모델을 통해 이루어졌으며, 2조 개의 토큰으로 구성된 대규모 데이터셋을 기반으로 처음부터 학습되었습니다. 데이터셋은 소스 코드 87%, 영어 코드 관련 자연어 말뭉치 10%, 코드와 무관한 중국어 자연어 말뭉치 3%로 구성되었습니다. 학습 과정에서는 AdamW 옵티마이저를 사용했으며, 배치 크기와 학습률은 모델 규모에 따라 조정되었습니다. 특히 개인정보 보호를 위한 PII 제거 파이프라인과 저장소 수준의 중복 제거 과정이 철저하게 적용되었습니다.

#### 이 연구의 결과가 가지는 의미는 무엇입니까?
이 연구의 가장 큰 의의는 오픈소스 코드 모델 중 최고 성능을 달성했을 뿐만 아니라, Codex와 GPT-3.5와 같은 비공개 모델들의 성능도 뛰어넘었다는 점입니다. 특히 DeepSeek-Coder-Base 6.7B 모델이 34B 파라미터의 CodeLlama와 대등한 성능을 보여준 것은 효율적인 모델 설계의 중요성을 입증합니다. 또한 연구와 상업적 활용 모두를 허용하는 개방적인 라이선스 정책을 채택함으로써, 코드 지능 분야의 발전을 가속화하고 더 많은 개발자와 연구자들이 고성능 코드 모델을 활용할 수 있는 기회를 제공했습니다. 이는 인공지능 기술의 민주화라는 측면에서도 큰 의미를 가집니다.
- - -
## DeepSeek-Coder: 코드 지능의 부상과 대규모 언어 모델의 만남

### 서론

DeepSeek-Coder는 프로그래밍 분야에서 획기적인 발전을 이루어낸 대규모 언어 모델입니다. 이 연구는 DeepSeek-AI와 북경대학교 연구진이 공동으로 수행한 것으로, 코드 생성과 이해 능력을 크게 향상시킨 혁신적인 모델을 제시합니다.

최근 CodeLlama와 StarCoder와 같은 코드 특화 언어 모델들이 등장하면서 프로그래밍 분야에서 인공지능의 활용 가능성이 크게 확대되었습니다. DeepSeek-Coder는 이러한 발전 흐름 속에서 더욱 진보된 코드 지능을 구현하고자 하는 시도입니다. 특히 이 모델은 기존 연구들의 한계를 극복하고 실제 개발 환경에서 더욱 실용적으로 활용될 수 있는 성능을 목표로 개발되었습니다.

DeepSeek-Coder의 개발 과정에서는 대규모 코드 데이터셋에 대한 철저한 전처리와 개인정보 보호가 이루어졌습니다. SantaCoder 연구에서 제시된 PII(개인식별정보) 제거 파이프라인을 기반으로, 이메일 주소, IP 주소, 비밀키 등의 민감한 정보를 효과적으로 탐지하고 익명화하는 과정을 거쳤습니다. 이는 모델의 안전성과 신뢰성을 보장하는 중요한 기술적 기반이 되었습니다.

이 연구는 GitHub를 통해 공개되어 있어 누구나 접근하고 활용할 수 있습니다. 연구진은 모델의 개방성과 투명성을 통해 코드 지능 분야의 발전에 기여하고자 하며, 이는 인공지능 기술의 민주화라는 측면에서도 큰 의미를 가집니다.

## DeepSeek-Coder: 코드 지능의 혁신과 오픈소스의 만남

### 서론

대규모 언어 모델의 급속한 발전은 소프트웨어 개발 분야에서 코드 지능의 혁신적인 변화를 이끌어왔습니다. 그러나 현재 대부분의 고성능 모델들이 비공개 소스로 운영되면서 연구와 개발에 제약이 있었습니다. 이러한 한계를 극복하고자 DeepSeek-Coder 시리즈가 개발되었습니다. 이 모델은 1.3B부터 33B까지 다양한 규모로 제공되며, 2조 개의 토큰으로 구성된 대규모 데이터셋을 기반으로 처음부터 학습되었습니다.

![성능 비교](https://ar5iv.org//html/2401.14196/assets/figures/PLT.png)

위 그래프에서 볼 수 있듯이, DeepSeek-Coder는 LeetCode 주간 코딩 대회에서 뛰어난 성과를 보여주었습니다. 특히 Python과 JavaScript 분야에서 C++, Java, PHP 등 다른 언어들보다 우수한 성능을 보였으며, GPT-4-Turbo 변형 모델이 가장 높은 점수를 기록했습니다.

DeepSeek-Coder의 주요 특징은 프로젝트 수준의 고품질 코드 데이터를 기반으로 한 사전 학습과 16K 윈도우를 활용한 fill-in-the-blank 작업을 통한 코드 생성 및 채우기 기능 강화입니다. 광범위한 평가 결과, DeepSeek-Coder는 오픈소스 코드 모델 중 최고 성능을 달성했을 뿐만 아니라, Codex와 GPT-3.5와 같은 비공개 모델들의 성능도 뛰어넘었습니다.

특히 주목할 만한 점은 DeepSeek-Coder가 연구와 상업적 활용 모두를 허용하는 개방적인 라이선스 정책을 채택했다는 것입니다. 이는 코드 지능 분야의 발전을 가속화하고, 더 많은 개발자와 연구자들이 고성능 코드 모델을 활용할 수 있는 기회를 제공할 것으로 기대됩니다.
### 코드 지능의 현재와 도전 과제

소프트웨어 개발 분야에서 대규모 언어 모델의 발전은 코드 자동화와 생산성 향상에 큰 변화를 가져왔습니다. Touvron과 연구진이 개발한 최신 언어 모델들은 버그 감지부터 코드 생성까지 다양한 개발 작업을 자동화할 수 있는 잠재력을 보여주었습니다. 그러나 현재 이 분야는 오픈소스 모델과 비공개 모델 사이의 성능 격차라는 중요한 도전 과제에 직면해 있습니다.

### DeepSeek-Coder의 혁신적 접근

DeepSeek-Coder는 이러한 도전 과제를 해결하기 위해 독특한 접근 방식을 채택했습니다. 특히 저장소 수준의 데이터 구성을 사전 학습 단계에서 도입한 것이 주목할 만합니다. 이는 단순히 개별 파일이나 함수 수준의 코드를 학습하는 것을 넘어, 전체 프로젝트 맥락에서 코드를 이해하고 생성할 수 있는 능력을 향상시켰습니다.

모델의 코드 완성 능력을 더욱 강화하기 위해 Fill-In-Middle(FIM) 접근 방식도 도입되었습니다. 이는 Li와 연구진이 제안한 방식을 확장한 것으로, 코드의 중간 부분을 채우는 능력을 향상시켜 더 자연스러운 코드 생성을 가능하게 합니다. 또한 16K 토큰의 긴 컨텍스트 길이를 지원함으로써, 복잡하고 긴 코드도 효과적으로 처리할 수 있게 되었습니다.

### 성능과 평가

DeepSeek-Coder의 성능은 특히 주목할 만합니다. DeepSeek-Coder-Base 33B 모델은 모든 공개 벤치마크에서 기존 오픈소스 모델들을 능가했으며, DeepSeek-Coder-Instruct 33B는 GPT-3.5 Turbo의 성능을 뛰어넘어 GPT-4와의 격차를 크게 줄였습니다. 더욱 놀라운 점은 DeepSeek-Coder-Base 7B 모델이 CodeLlama-33B와 같은 5배 더 큰 모델들과 비교해도 경쟁력 있는 성능을 보여준다는 것입니다.

### DeepSeek-Coder의 데이터셋 구축 과정

DeepSeek-Coder의 학습 데이터셋은 소스 코드 87%, 영어 코드 관련 자연어 말뭉치 10%, 코드와 무관한 중국어 자연어 말뭉치 3%로 구성되어 있습니다. 영어 말뭉치는 GitHub의 마크다운 문서와 StackExchange에서 수집된 자료로, 모델이 코드 관련 개념을 이해하고 라이브러리 사용법과 버그 수정 같은 작업을 수행하는 능력을 향상시키는 데 활용됩니다. 중국어 말뭉치는 고품질 기사들로 구성되어 중국어 이해 능력을 향상시키는 데 사용됩니다.

#### 데이터 수집 및 전처리 파이프라인

![데이터셋 생성 절차](https://ar5iv.org//html/2401.14196/assets/x1.png)

데이터셋 구축 과정은 데이터 크롤링, 규칙 기반 필터링, 의존성 분석, 저장소 수준의 중복 제거, 품질 검사 단계로 이루어집니다. 먼저 GitHub에서 2023년 2월 이전에 생성된 공개 저장소들을 수집하고, 87개 프로그래밍 언어로 제한하여 데이터를 수집했습니다.

데이터 품질을 향상시키기 위해 StarCoder 프로젝트에서 사용된 것과 유사한 필터링 규칙을 적용했습니다. 이 규칙들은 평균 줄 길이가 100자를 초과하거나 최대 줄 길이가 1000자를 초과하는 파일, 알파벳 문자가 25% 미만인 파일을 제외합니다. XSLT를 제외한 모든 프로그래밍 언어에서 첫 100자 내에 "<?xml version="이 포함된 파일도 제외했습니다. HTML 파일의 경우 가시적 텍스트와 HTML 코드의 비율을 고려하여, 가시적 텍스트가 전체 코드의 20% 이상이면서 100자 이상인 파일만 유지했습니다. JSON과 YAML 파일은 데이터 중심 파일을 제거하기 위해 50자에서 5000자 사이의 파일만 유지했습니다.

#### 의존성 분석과 토폴로지 정렬

이전 연구들과 달리 DeepSeek-Coder는 프로젝트 수준의 코드 시나리오를 효과적으로 처리하기 위해 파일 간의 의존성을 고려합니다. 의존성 분석 알고리즘은 파일 간의 호출 관계를 파싱하고, 각 파일이 의존하는 컨텍스트가 입력 시퀀스에서 해당 파일 앞에 오도록 정렬합니다. Python의 "import", C#의 "using", C의 "include"와 같은 정규 표현식을 사용하여 파일 간의 호출 관계를 추출합니다.
#### 토폴로지 정렬 알고리즘의 구현

의존성 분석을 위한 토폴로지 정렬 알고리즘은 프로젝트 내 파일들의 의존 관계를 효과적으로 처리합니다. 알고리즘은 먼저 파일들 간의 의존성을 나타내는 인접 리스트 "graphs"와 각 파일의 진입 차수를 저장하는 "inDegree" 딕셔너리를 초기화합니다. 이후 모든 파일 쌍을 순회하며 의존성을 확인하고, 발견된 의존 관계에 따라 그래프와 진입 차수를 업데이트합니다.

알고리즘의 핵심적인 특징은 연결되지 않은 하위 그래프들을 식별하고, 각 하위 그래프에 대해 수정된 토폴로지 정렬을 수행한다는 점입니다. 일반적인 토폴로지 정렬과 달리 진입 차수가 0인 노드만을 선택하는 대신, 최소 진입 차수를 가진 노드를 선택함으로써 그래프 내의 순환을 처리할 수 있습니다. 선택된 노드는 결과 리스트에 추가되고, 해당 노드와 연결된 노드들의 진입 차수가 감소됩니다.

각 하위 그래프에 대한 정렬이 완료되면, 정렬된 시퀀스들이 하나의 학습 샘플을 형성하기 위해 연결됩니다. 파일 경로 정보를 보존하기 위해 각 파일의 시작 부분에 해당 파일의 경로를 주석으로 추가합니다. 이러한 방식으로 프로젝트의 구조적 정보를 학습 데이터에 효과적으로 반영할 수 있습니다.

#### 저장소 수준의 중복 제거

대규모 언어 모델의 학습 데이터셋에서 중복 제거의 중요성은 여러 연구를 통해 입증되었습니다. Lee와 연구진은 언어 모델 학습 말뭉치에 많은 근접 중복이 존재하며, 긴 반복 문자열을 제거함으로써 모델의 성능을 향상시킬 수 있다는 것을 보여주었습니다. Kocetkov와 연구진은 근접 중복 제거 방법을 적용하여 극적인 성능 향상을 달성했으며, 이는 코드 벤치마크 작업에서 경쟁력 있는 성능을 달성하기 위한 중요한 전처리 단계임을 강조했습니다.

DeepSeek-Coder의 데이터셋에서는 기존 연구들과 차별화된 접근 방식을 채택했습니다. 파일 수준이 아닌 저장소 수준에서 중복 제거를 수행함으로써 저장소 구조의 완전성을 보존합니다. 파일 수준의 중복 제거는 저장소 내 특정 파일들을 필터링하여 저장소의 구조를 손상시킬 수 있기 때문입니다. 구체적으로, 저장소 수준에서 연결된 코드를 하나의 샘플로 취급하고 동일한 근접 중복 제거 알고리즘을 적용하여 저장소 구조의 무결성을 유지합니다.
#### 데이터셋의 품질 관리와 오염 방지

DeepSeek-Coder 데이터셋의 품질을 더욱 향상시키기 위해 2.1절에서 언급한 필터링 규칙 외에도 컴파일러와 품질 모델, 그리고 휴리스틱 규칙을 추가로 적용했습니다. 이를 통해 구문 오류가 있는 코드, 가독성이 떨어지는 코드, 모듈성이 낮은 코드 등을 필터링했습니다.

최종적으로 구축된 데이터셋은 총 798GB 규모로, 87개 프로그래밍 언어에 걸쳐 6억 3백만 개의 파일을 포함합니다. Java가 18.63%로 가장 큰 비중을 차지하며, 그 뒤를 이어 Python이 15.12%, C++이 11.39%를 차지합니다. TypeScript(7.60%), PHP(7.38%), JavaScript(6.75%) 등도 상당한 비중을 차지하고 있어, 다양한 프로그래밍 언어에 대한 균형 잡힌 학습이 가능하도록 구성되었습니다.

테스트 셋의 정보가 학습 데이터에 포함되는 것을 방지하기 위해 n-gram 필터링 프로세스를 구현했습니다. 구체적으로, HumanEval, MBPP, GSM8K, MATH 등의 소스에서 나온 문서 문자열, 질문, 해답을 포함하는 파일들을 제거했습니다. 필터링 기준으로는 테스트 데이터와 동일한 10-gram 문자열을 포함하는 코드는 학습 데이터에서 제외했습니다. 테스트 데이터가 10-gram보다 짧지만 3-gram 이상인 경우에는 정확한 매칭 방식을 사용하여 필터링을 수행했습니다.

이러한 엄격한 데이터 품질 관리와 오염 방지 절차를 통해, DeepSeek-Coder는 높은 품질의 학습 데이터셋을 확보할 수 있었으며, 이는 모델의 성능과 신뢰성 향상에 크게 기여했습니다.

### 학습 정책과 모델 구조

#### 학습 목표 설정

DeepSeek-Coder의 학습은 두 가지 핵심적인 목표를 중심으로 설계되었습니다. 첫 번째는 다음 토큰 예측(Next Token Prediction)으로, 이는 고정 길이의 입력을 생성하기 위해 여러 파일들을 연결한 후, 주어진 컨텍스트를 기반으로 다음에 올 토큰을 예측하는 방식입니다.

두 번째 학습 목표는 중간 채우기(Fill-in-the-Middle, FIM)입니다. 프로그래밍 언어의 특정 의존성으로 인해 다음 토큰 예측만으로는 중간 삽입 능력을 학습하기에 충분하지 않다는 점에 착안하여, Bavarian과 연구진, Li와 연구진이 제안한 FIM 방식을 도입했습니다. 이 방법은 텍스트를 세 부분으로 무작위로 나누고, 이를 특수 문자로 연결하여 학습 과정에서 빈칸 채우기 작업을 수행합니다.

FIM 방식은 PSM(Prefix-Suffix-Middle)과 SPM(Suffix-Prefix-Middle)이라는 두 가지 모드로 구현됩니다. PSM 모드에서는 텍스트가 $$ Prefix,Suffix,Middle $$ 순서로 구성되어 중간 세그먼트가 접두사와 접미사 사이에 위치하게 됩니다. 반면 SPM 모드는 $$ Suffix,Prefix,Middle $$ 순서로 구성되어 다른 구조적 도전을 제시합니다.

![FIM 목표의 효과성](https://ar5iv.org//html/2401.14196/assets/x2.png)

위 그래프는 FIM 목표의 효과성을 보여주는 벤치마크 결과입니다. 다양한 정규화 강도(fm_0.1, fm_0.3, fm_1.0, mg_0.1)에 따른 모델 성능을 세 가지 벤치마크 작업(Human/Eval-Pass1, Human/RM-Pass1, MBPP-Pass1)에서 비교한 결과를 나타냅니다.

#### FIM 실험 분석

DeepSeek-Coder-Base 1.3B 모델을 사용하여 FIM 기법의 효과성을 평가하기 위한 실험을 진행했습니다. 학습 데이터셋의 Python 서브셋을 대상으로 하여, HumanEval-FIM 벤치마크를 통해 평가를 수행했습니다. 이 벤치마크는 HumanEval 솔루션에서 한 줄의 코드를 무작위로 가려두고 모델이 이를 예측하는 단일 라인 FIM 작업을 특징으로 합니다.

실험 결과, 100% FIM 비율에서 HumanEval-FIM에 대한 최고 성능을 보였지만, 이 구성에서는 코드 완성 능력이 가장 낮게 나타났습니다. 이는 FIM과 코드 완성 능력 사이의 트레이드오프를 보여줍니다. 또한 50% PSM 비율에서 MSP(Masked Span Prediction) 전략보다 우수한 성능을 보였습니다.
### 학습 정책과 모델 구조

#### FIM 구현 세부사항

이러한 실험 결과를 바탕으로 DeepSeek-Coder는 FIM과 코드 완성 능력 사이의 균형을 위해 50% PSM 비율을 최종 학습 정책으로 채택했습니다. 구현 과정에서는 세 개의 특수 토큰을 도입했으며, 각 코드 파일의 내용을 $$ f_{pre} $$, $$ f_{middle} $$, $$ f_{suf} $$ 세 부분으로 나눕니다. PSM 모드를 사용하여 다음과 같은 형식으로 학습 예제를 구성합니다.

$$ \texttt{<｜fim\_start｜>}f_{pre}\texttt{<｜fim\_hole｜>}f_{suf}\texttt{<｜fim\_end｜>}f_{middle}\texttt{<|eos\_token|>} $$

Bavarian과 연구진이 제안한 원래 작업에 따라, FIM 방식은 패킹 프로세스 이전에 문서 수준에서 구현되며, 0.5의 FIM 비율로 PSM 모드를 따릅니다.

#### 토크나이저 구현

토크나이저 구현을 위해 HuggingFace Tokenizer 라이브러리를 활용하여 Byte Pair Encoding(BPE) 토크나이저를 학습했습니다. Sennrich와 연구진이 제시한 방법론을 따라 학습 코퍼스의 일부를 사용했으며, 최종적으로 32,000 크기의 어휘 사전을 가진 토크나이저를 구축했습니다.

#### 모델 아키텍처 상세

DeepSeek-Coder는 1.3B, 6.7B, 33B 파라미터를 가진 다양한 규모의 모델을 개발했습니다. 이 모델들은 DeepSeek Large Language Model(LLM)과 동일한 프레임워크를 기반으로 하며, Su와 연구진이 제안한 Rotary Position Embedding(RoPE)을 통합한 디코더 전용 트랜스포머 구조를 채택했습니다. 특히 33B 모델의 경우, 학습과 추론 효율성을 높이기 위해 8의 그룹 크기를 가진 Grouped-Query-Attention(GQA)을 도입했으며, Dao가 제안한 FlashAttention v2를 활용하여 어텐션 메커니즘의 계산 속도를 향상시켰습니다.

#### 최적화 전략

DeepSeek LLM의 접근 방식을 따라, AdamW 옵티마이저를 사용하여 $$ \beta_{1} $$ 값을 0.9, $$ \beta_{2} $$ 값을 0.95로 설정했습니다. 배치 크기와 학습률은 DeepSeek LLM에서 제시된 스케일링 법칙에 따라 조정되었습니다. 학습률 스케줄링은 2000 웜업 스텝을 포함하는 3단계 정책을 구현했으며, 최종 학습률은 초기 학습률의 10%로 설정되었습니다. 각 단계에서의 학습률은 이전 단계 학습률의 $$ \sqrt{\frac{1}{10}} $$ 배로 감소됩니다.
### 학습 정책과 모델 구조

#### 학습 환경 구성

DeepSeek-Coder의 실험은 HAI-LLM 프레임워크를 기반으로 수행되었습니다. 이 프레임워크는 대규모 언어 모델 학습에 있어 효율성과 경량화된 접근 방식으로 잘 알려져 있습니다. 계산 효율성을 최적화하기 위해 다양한 병렬화 전략이 통합되었는데, Korthikanti와 연구진이 제안한 텐서 병렬화, Rajbhandari와 연구진의 ZeRO 데이터 병렬화, 그리고 Narayanan과 연구진이 개발한 PipeDream 파이프라인 병렬화가 포함됩니다.

실험 환경은 NVIDIA A100과 H800 GPU를 장착한 클러스터에서 구축되었습니다. A100 클러스터의 각 노드는 8개의 GPU로 구성되어 있으며, 이들은 NVLink 브리지를 통해 쌍으로 연결됩니다. H800 클러스터도 유사한 구성을 가지고 있으며, 각 노드는 8개의 GPU를 포함하고 있습니다. 이 GPU들은 NVLink와 NVSwitch 기술의 조합을 통해 상호 연결되어 노드 내 효율적인 데이터 전송을 보장합니다. 두 클러스터 모두에서 노드 간 원활한 통신을 위해 높은 처리량과 낮은 지연 시간으로 알려진 InfiniBand 인터커넥트를 사용합니다.

#### 긴 컨텍스트 처리 능력

DeepSeek-Coder의 저장소 수준 코드 처리와 같은 확장된 컨텍스트 처리 능력을 향상시키기 위해 RoPE 파라미터를 재구성했습니다. Chen과 연구진, kaiokendev의 이전 연구 사례를 따라 선형 스케일링 전략을 적용했는데, 스케일링 팩터를 $$ 1 $$에서 $$ 4 $$로 증가시키고 기본 주파수를 $$ 10000 $$에서 $$ 100000 $$으로 변경했습니다.

모델은 $$ 512 $$의 배치 크기와 $$ 16 $$K의 시퀀스 길이를 사용하여 추가로 $$ 1000 $$ 스텝의 학습을 진행했으며, 학습률은 최종 사전 학습 단계와 동일하게 유지했습니다. 이러한 수정을 통해 이론적으로는 최대 $$ 64 $$K 토큰의 컨텍스트를 처리할 수 있게 되었지만, 실제 관찰 결과 모델은 $$ 16 $$K 토큰 범위 내에서 가장 신뢰할 수 있는 출력을 생성하는 것으로 나타났습니다.

#### 명령어 튜닝 과정

DeepSeek-Coder-Instruct는 고품질 데이터를 사용한 명령어 기반 미세 조정을 통해 DeepSeek-Coder-Base를 개선한 버전입니다. 이 데이터는 Taori와 연구진이 제시한 Alpaca Instruction 형식으로 구조화된 도움이 되고 공정한 인간 지시사항들로 구성되어 있습니다. 각 대화 턴의 구분을 위해 <\|EOT\|> 토큰을 구분자로 사용했으며, 100 웜업 스텝과 1e-5의 초기 학습률을 가진 코사인 스케줄을 적용했습니다. 4M 토큰의 배치 크기로 총 2B 토큰을 학습했습니다.

![다중 턴 대화 예시](https://ar5iv.org//html/2401.14196/assets/x3.png)

위 그림은 DeepSeek-Coder-Instruct 33B를 사용한 다중 턴 대화 예시를 보여줍니다. 사용자가 pygame을 사용한 스네이크 게임 구현을 요청하자, 모델은 버그 없이 실행 가능한 기본 게임을 생성했습니다. 이후 왼쪽 상단에 점수 시스템 추가를 요청받았을 때, 모델은 "score" 변수와 "display_score" 함수를 도입하고 이러한 기능을 통합하는 방법을 설명했습니다.

### DeepSeek-Coder의 실험 결과 분석

DeepSeek-Coder의 성능을 평가하기 위해 코드 생성, FIM 코드 완성, 크로스 파일 코드 완성, 그리고 프로그램 기반 수학적 추론이라는 네 가지 주요 과제에서 실험을 진행했습니다. 이 평가에서는 CodeGeeX2, StarCoder, CodeLlama, code-cushman-001, GPT-3.5, GPT-4와 같은 최신 대규모 언어 모델들과 비교 분석이 이루어졌습니다.

#### 코드 생성 성능 평가

HumanEval과 MBPP 벤치마크에서의 평가 결과, DeepSeek-Coder-Base는 HumanEval에서 평균 50.3%, MBPP에서 66.0%의 정확도를 달성했습니다. 특히 주목할 만한 점은 6.7B 파라미터를 가진 더 작은 모델이 CodeLlama-Base 34B보다 우수한 성능을 보여주었다는 것입니다. 명령어 미세조정 후에는 DeepSeek-Coder-Instruct가 GPT-3.5-Turbo의 성능을 뛰어넘어 GPT-4와의 성능 격차를 크게 줄였습니다.

DS-1000 벤치마크 평가에서는 실제 데이터 과학 워크플로우에 대한 코드 생성 능력을 테스트했습니다. 이 벤치마크는 Matplotlib, NumPy, Pandas, SciPy, Scikit-Learn, PyTorch, TensorFlow와 같은 7개의 주요 라이브러리를 포함하고 있습니다. DeepSeek-Coder는 모든 라이브러리에서 높은 정확도를 보여주며, 실제 데이터 과학 워크플로우에서 라이브러리를 효과적으로 활용할 수 있는 능력을 입증했습니다.

LeetCode 대회 벤치마크에서는 2023년 7월부터 2024년 1월까지의 최신 문제들을 수집하여 평가를 진행했습니다. DeepSeek-Coder-Instruct 6.7B와 33B 모델은 각각 19.4%와 27.8%의 Pass@1 점수를 달성했으며, 특히 33B 모델은 GPT-3.5-Turbo를 능가하는 유일한 오픈소스 모델이 되었습니다. 

체인오브소트(Chain-of-Thought) 프롬프팅을 적용했을 때 DeepSeek-Coder-Instruct 모델의 성능이 더욱 향상되었습니다. "먼저 단계별 개요를 작성한 다음 코드를 작성하세요."라는 지시를 추가함으로써, 특히 복잡한 과제에서 성능 향상이 두드러졌습니다. 이는 코드 작성 전에 상세한 설명을 먼저 구성하는 것이 로직과 의존성을 더 효과적으로 이해하고 처리하는 데 도움이 된다는 것을 보여줍니다.
#### FIM 코드 완성 성능 평가

DeepSeek-Coder 모델은 사전 학습 단계에서 0.5의 FIM(Fill-In-the-Middle) 비율로 학습되었습니다. 이러한 특별한 학습 전략을 통해 모델은 주어진 코드 스니펫의 앞뒤 문맥을 기반으로 빈칸을 채우는 코드 생성 능력을 갖추게 되었습니다. 이는 코드 완성 도구에서 특히 유용한 기능입니다.

SantaCoder, StarCoder, CodeLlama와 같은 여러 오픈소스 모델들과의 비교 평가를 위해 Allal과 연구진이 제안한 단일 라인 채우기 벤치마크를 사용했습니다. 이 벤치마크는 세 가지 프로그래밍 언어를 대상으로 하며, 정확한 라인 매칭 정확도를 평가 지표로 사용합니다.

평가 결과에서 가장 주목할 만한 점은 1.3B 파라미터라는 가장 작은 용량의 DeepSeek-Coder가 StarCoder와 CodeLlama와 같은 더 큰 모델들보다 우수한 성능을 보여주었다는 것입니다. 이러한 뛰어난 성능은 DeepSeek-Coder가 사용한 고품질 사전 학습 데이터에 기인합니다. 또한 모델 크기가 증가할수록 성능이 향상되는 경향을 보였는데, 이는 코드 완성 작업에서 모델 용량의 중요성을 보여줍니다.

이러한 실험 결과를 바탕으로 연구진은 코드 완성 도구에 DeepSeek-Coder-Base 6.7B 모델을 배포하는 것을 권장합니다. 이 모델은 효율성과 정확성 사이에서 최적의 균형을 보여주었으며, 코딩 환경에 고급 연산 기능을 통합하는 데 이상적인 선택이 될 것으로 평가됩니다.
#### 크로스 파일 코드 완성 성능 평가

크로스 파일 코드 완성 작업에서는 기존 오픈소스 모델들의 성능을 CrossCodeEval을 사용하여 평가했습니다. 이 평가는 단순한 코드 생성과는 달리, 여러 파일에 걸친 의존성을 이해하고 처리해야 하는 복잡한 작업입니다. CrossCodeEval 데이터셋은 Python, Java, TypeScript, C#의 네 가지 주요 프로그래밍 언어에서 실제 오픈소스 프로젝트를 기반으로 구축되었으며, 크로스 파일 컨텍스트가 반드시 필요한 완성 작업으로 구성되어 있습니다.

특히 이 데이터셋은 2023년 3월에서 6월 사이에 생성된 저장소들로 구성되어 있으며, DeepSeek-Coder의 사전 학습 데이터는 2023년 2월 이전의 코드만을 포함하고 있어 데이터 유출 문제를 방지했습니다. 평가를 위해 최대 시퀀스 길이는 2048 토큰으로 설정되었고, 크로스 파일 컨텍스트는 512 토큰으로 제한되었습니다. 크로스 파일 컨텍스트를 위해서는 Ding과 연구진이 제공한 공식 BM25 검색 결과를 활용했습니다.

실험 결과는 DeepSeek-Coder가 크로스 파일 완성 작업에서 다른 모델들을 일관되게 능가하는 것을 보여줍니다. 특히 파일 수준의 코드 말뭉치만을 사용하여 사전 학습을 진행한 경우(w/o Repo Pre-training)와 비교했을 때, Java, TypeScript, C# 언어에서 성능 저하가 관찰되었습니다. 이는 저장소 수준의 사전 학습이 효과적이었음을 입증합니다.

#### 프로그램 기반 수학적 추론 평가

프로그램 기반 수학적 추론은 모델이 프로그래밍을 통해 수학 문제를 이해하고 해결하는 능력을 평가합니다. 이 평가는 데이터 분석과 과학적 컴퓨팅 분야에서 특히 중요한 의미를 가집니다. 평가를 위해 Gao와 연구진이 제안한 프로그램 지원 수학 추론(PAL) 방법을 사용했으며, GSM8K, MATH, GSM-Hard, SVAMP, TabMWP, ASDiv, MAWPS를 포함한 7개의 서로 다른 벤치마크에서 평가가 진행되었습니다.

각 벤치마크에서 모델은 자연어로 해결 단계를 설명한 후 해당 단계를 코드로 실행하는 방식으로 문제를 해결합니다. DeepSeek-Coder 모델들은 모든 벤치마크에서 주목할 만한 성능을 보여주었으며, 특히 33B 변형 모델은 복잡한 수학적 계산과 문제 해결이 필요한 응용 분야에서의 잠재력을 입증했습니다.

### DeepSeek-Coder-v1.5: 일반 언어 모델에서의 추가 사전 학습

DeepSeek-Coder 모델의 자연어 이해와 수학적 추론 능력을 더욱 향상시키기 위해, 연구진은 DeepSeek-LLM-7B Base 모델을 기반으로 2조 개의 토큰에 대한 추가 사전 학습을 진행했습니다. 이를 통해 DeepSeek-Coder-v1.5 7B가 개발되었습니다.

#### 데이터 구성과 학습 목표

사전 학습에 사용된 데이터는 다섯 가지 주요 카테고리로 구성되었습니다. 소스 코드가 70%로 가장 큰 비중을 차지하며, 마크다운과 StackExchange 데이터가 10%, 코드 관련 자연어가 7%, 수학 관련 자연어가 7%, 중국어-영어 이중 언어 데이터가 6%를 차지합니다. DeepSeek-Coder-v1.5는 이전 버전과 달리 4K 컨텍스트 길이를 사용하여 다음 토큰 예측이라는 단일 목표에 초점을 맞추었습니다.

#### 성능 평가 및 결과 분석

모델의 성능은 프로그래밍, 수학적 추론, 자연어 처리 세 가지 주요 영역에서 평가되었습니다. 프로그래밍 능력은 HumanEval과 MBPP 데이터셋을 통해 평가되었으며, 수학적 추론은 GSM8K와 MATH 벤치마크를 통해 측정되었습니다. 자연어 처리 능력은 MMLU, BBH, HellaSwag, Winogrande, ARC-Challenge 등 다양한 벤치마크를 통해 평가되었습니다.

평가 결과, DeepSeek-Coder-Base-v1.5는 코딩 성능에서 약간의 감소를 보였지만, 대부분의 과제에서 이전 모델보다 현저한 개선을 보여주었습니다. 특히 수학적 추론과 자연어 처리 분야에서 모든 벤치마크에서 큰 성능 향상을 달성했습니다. GSM8K에서는 62.4%의 정확도를 달성하여 이전 모델의 43.2%보다 크게 향상되었으며, MMLU에서도 49.1%를 기록하여 이전 모델의 36.6%를 크게 상회했습니다.

이러한 성능 향상은 다양한 데이터 소스를 활용한 추가 사전 학습의 효과를 입증합니다. 특히 코드, 수학, 자연어 데이터의 균형 잡힌 조합이 모델의 전반적인 능력 향상에 기여했음을 보여줍니다. DeepSeek-Coder-v1.5는 코드 생성 능력을 유지하면서도 더 넓은 범위의 과제에서 뛰어난 성능을 보여주는 균형 잡힌 모델로 발전했습니다.

## DeepSeek-Coder: 결론과 미래 전망

### 연구 성과 요약

DeepSeek-Coder는 코드 생성과 이해를 위한 특화된 대규모 언어 모델 시리즈를 성공적으로 개발했습니다. 1.3B, 6.7B, 33B 파라미터의 세 가지 규모로 구성된 이 모델들은 프로젝트 수준의 코드 데이터를 기반으로 학습되었으며, "fill-in-the-blank" 사전 학습 목표를 통해 코드 채우기 능력을 향상시켰습니다.

모델의 주요 혁신 중 하나는 16,384 토큰으로 확장된 컨텍스트 윈도우입니다. 이는 광범위한 코드 생성 작업을 더욱 효과적으로 처리할 수 있게 해주었습니다. 평가 결과에서 DeepSeek-Coder-Base 33B는 기존의 오픈소스 코드 모델들을 다양한 표준 테스트에서 능가했습니다. 특히 주목할 만한 점은 DeepSeek-Coder-Base 6.7B 모델이 34B 파라미터의 CodeLlama와 대등한 성능을 보여주었다는 것입니다. 이는 사전 학습 데이터의 높은 품질을 입증하는 결과입니다.

### 모델 개선과 발전

DeepSeek-Coder-Base 모델의 제로샷 명령어 처리 능력을 향상시키기 위해 고품질 명령어 데이터를 사용한 미세 조정이 진행되었습니다. 그 결과 DeepSeek-Coder-Instruct 33B 모델은 코드 생성과 이해 관련 다양한 작업에서 OpenAI의 GPT-3.5 Turbo를 능가하는 성능을 보여주었습니다.

더 나아가 DeepSeek-Coder-Base 모델의 자연어 이해 능력을 개선하기 위해 DeepSeek-LLM 7B 체크포인트를 기반으로 추가 사전 학습을 수행했습니다. 이 학습 과정에서는 자연어, 코드, 수학 데이터를 포함하는 20억 토큰 규모의 다양한 데이터셋이 활용되었습니다. 이를 통해 개발된 DeepSeek-Coder-v1.5는 이전 모델의 뛰어난 코딩 성능을 유지하면서도 자연어 이해 능력이 크게 향상되었습니다.

### 향후 연구 방향

연구진은 효과적인 코드 중심 대규모 언어 모델이 강력한 일반 언어 모델을 기반으로 구축되어야 한다고 강조합니다. 이는 코딩 작업을 효과적으로 수행하기 위해서는 다양한 형태의 자연어로 표현된 사용자 지시사항을 깊이 있게 이해해야 하기 때문입니다. 연구진은 앞으로 더 큰 규모의 일반 언어 모델을 기반으로 한 강력한 코드 중심 언어 모델을 개발하고 공개할 계획을 밝혔습니다.

### DeepSeek-Coder의 실제 활용 사례 분석

DeepSeek-Coder의 실용적 활용 가능성을 검증하기 위해 두 가지 대표적인 사례 연구가 진행되었습니다. 첫 번째는 데이터베이스 구축과 데이터 분석을 포함하는 다중 턴 대화 시나리오이며, 두 번째는 LeetCode의 최신 문제 해결 능력을 평가하는 시나리오입니다.

![데이터베이스 구축 및 분석 예시](https://ar5iv.org//html/2401.14196/assets/x4.png)

위 그림에서 볼 수 있듯이, 첫 번째 시나리오에서는 Python을 사용하여 학생 데이터베이스를 구축하고 무작위로 10개의 정보를 삽입하는 작업이 수행되었습니다. 이어진 대화에서는 학생들의 연령 분포를 분석하는 작업이 이루어졌습니다. 모델은 버그 없는 완성도 높은 코드를 생성했을 뿐만 아니라, 각 단계에 대한 상세한 설명도 함께 제공했습니다. 특히 SQLite 데이터베이스 생성, 데이터 삽입, matplotlib를 활용한 시각화 등 실제 데이터 과학 워크플로우에서 필요한 다양한 작업들을 성공적으로 수행했습니다.

![LeetCode 문제 해결 예시](https://ar5iv.org//html/2401.14196/assets/x5.png)

두 번째 시나리오에서는 모델의 일반화 능력을 평가하기 위해 2023년 11월에 공개된 LeetCode 대회 문제를 활용했습니다. 이 문제는 모델의 학습 데이터 수집 시점 이후에 출제된 것으로, 학습 데이터에 포함되지 않은 새로운 문제입니다. 토너먼트 스타일의 경쟁에서 우승 팀을 찾는 이 문제에서, 모델은 방향성 그래프 구성, 챔피언 팀 식별, 각 팀의 진입 차수 계산 등 복잡한 그래프 기반 알고리즘을 성공적으로 구현했습니다. 이는 DeepSeek-Coder가 학습 분포를 벗어난 새로운 문제에 대해서도 효과적인 해결 능력을 보유하고 있음을 입증합니다.

이러한 사례 연구들은 DeepSeek-Coder가 단순한 코드 생성을 넘어, 실제 개발 환경에서 마주하는 복잡한 문제들을 해결할 수 있는 실용적인 도구로 활용될 수 있음을 보여줍니다. 특히 다단계 문제 해결, 데이터 처리, 알고리즘 구현 등 다양한 프로그래밍 과제에서 높은 수준의 성능을 보여주었습니다.

### DeepSeek-Coder의 학습 과정 벤치마크 분석

DeepSeek-Coder-Base 모델의 학습 과정에서 성능 변화를 면밀히 분석하기 위해 연구진은 체계적인 벤치마크 평가를 수행했습니다. 이 평가를 위해 학습 데이터에서 신중하게 선별된 8,000개의 코드 파일로 구성된 검증 세트를 구축했습니다. 이 검증 세트는 모델의 다양한 능력을 정확하게 평가할 수 있도록 대표성 있는 샘플들로 구성되었습니다.

![벤치마크 곡선](https://ar5iv.org//html/2401.14196/assets/x6.png)

위 그래프는 DeepSeek-Coder-Base 모델의 학습 과정에서 관찰된 성능 지표들을 보여줍니다. 1.3B, 6.7B, 33B 파라미터를 가진 세 가지 모델 버전에 대해 HumanEval-Pass@1, HumanEval-cpp-Pass@1, HumanEval-java-Pass@1, MBPP-Pass@1, MeanHumanEval, Validation-Completion-EM, Validation-Completion-FIM-EM과 같은 다양한 평가 지표들의 변화를 추적했습니다.

평가 결과는 모델 크기가 증가할수록 전반적인 성능이 향상되는 경향을 명확하게 보여줍니다. 특히 33B 파라미터 모델은 코드 생성과 이해 능력에서 가장 우수한 성능을 보여주었습니다. 이는 대규모 언어 모델의 스케일업이 코드 관련 작업의 성능 향상에 실질적인 효과가 있음을 입증합니다.

벤치마크 곡선은 학습 과정에서 모델의 성능이 점진적으로 향상되는 패턴을 보여주며, 특히 초기 학습 단계에서 급격한 성능 향상이 이루어진 후 점차 안정화되는 것을 확인할 수 있습니다. 이러한 성능 추이는 모델의 학습이 효과적으로 이루어지고 있음을 보여주는 중요한 지표가 됩니다.

- - -
### References
* [DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence](http://arxiv.org/pdf/2401.14196v2)