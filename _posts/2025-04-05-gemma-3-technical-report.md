---
layout: post
title: "Gemma 3 Technical Report"
date: 2025-03-25 15:52:34
author: "Google DeepMind"
categories: "Multimodal-Learning"
tags: ["Alternating-Local-Global-Attention", "Pan-&-Scan-Image-Processing", "Long-Context-Adaptation", "Vision-Encoder-Token-Condensation", "Multimodal-Knowledge-Distillation", "Grouped-Query-Attention", "RoPE-Positional-Embedding-Extension", "Quantization-Aware-Training", "Flexible-Vision-Encoder-Architecture", "Multimodal-Safety-Evaluation-Framework"]
cover: /assets/images/default.jpg
use_math: true
---
### TL;DR
#### 이 연구를 시작하게 된 배경과 동기는 무엇입니까?

대규모 언어 모델의 발전은 인공지능 분야에서 가장 중요한 연구 주제 중 하나로 자리 잡았습니다. 기존 모델들은 대부분 텍스트 처리에만 집중했으며, 컴퓨팅 자원과 메모리 사용량 측면에서 심각한 제약이 있었습니다. 특히 긴 컨텍스트를 처리하거나 다국어 능력을 효과적으로 구현하는 데 어려움을 겪어왔습니다. 이러한 한계를 극복하기 위해 Google DeepMind 팀은 Gemma 모델 시리즈를 통해 경량이면서도 강력한 AI 모델을 개발하고자 했습니다.

연구팀은 기존 대규모 언어 모델의 세 가지 주요 한계점에 주목했습니다. 첫째, 대부분의 모델은 텍스트 처리에만 제한되어 있었고, 둘째, 긴 컨텍스트를 효율적으로 처리할 수 없었으며, 셋째, 다국어 능력이 제한적이었습니다. 이러한 문제들은 AI 모델의 실용성과 접근성을 크게 제한하고 있었기 때문에, 연구팀은 이를 해결할 수 있는 혁신적인 접근 방법을 모색하게 되었습니다.

#### 이 연구에서 제시하는 새로운 해결 방법은 무엇입니까?

Gemma 3는 멀티모달 처리, 긴 컨텍스트 이해, 그리고 효율적인 학습 방법론을 통합한 혁신적인 접근 방법을 제시합니다. 특히 SigLIP 비전 인코더를 통합하여 이미지를 256개의 고정 크기 벡터로 압축함으로써, 추론 비용을 크게 줄이면서도 이미지 처리 능력을 확보했습니다. 이는 경량 모델에서도 효과적인 시각 처리를 가능하게 하는 중요한 기술적 혁신입니다.

로컬 어텐션과 글로벌 어텐션 레이어의 비율을 5:1로 조정하고, 로컬 어텐션의 윈도우 크기를 제한하는 방식으로 긴 컨텍스트 처리 문제를 해결했습니다. 이 접근 방식은 KV 캐시 메모리 사용량을 크게 줄이면서도 128K 토큰까지의 컨텍스트를 효과적으로 처리할 수 있게 해줍니다. 또한 지식 증류(knowledge distillation) 기법을 적용하여 작은 모델이 더 큰 교사 모델의 지식을 효율적으로 학습할 수 있도록 했습니다.

#### 제안된 방법은 어떻게 구현되었습니까?

Gemma 3의 구현은 여러 혁신적인 기술적 접근 방법을 포함합니다. 비전 인코더는 SigLIP 모델의 400M 변형을 사용하여 이미지를 처리하며, Pan & Scan(P&S) 기법을 통해 다양한 해상도와 종횡비의 이미지를 효과적으로 처리할 수 있게 합니다. 모델의 아키텍처는 Grouped-Query Attention(GQA)을 사용하며, RMSNorm과 QK-norm 등의 기술을 통해 계산 효율성과 학습 안정성을 개선했습니다.

사전 학습 과정에서는 14T에서 2T 토큰 범위의 데이터를 사용하여 모델을 학습시켰으며, 다국어 데이터의 양을 증가시키고 언어 표현의 불균형을 처리했습니다. 명령어 튜닝(Instruction Tuning) 단계에서는 지식 증류, 강화학습, 그리고 데이터 필터링 기법을 통합하여 모델의 성능을 향상시켰습니다. 특히 수학, 추론, 채팅, 명령어 따르기, 다국어 능력 개선에 중점을 두었습니다.

#### 이 연구의 결과가 가지는 의미는 무엇입니까?

Gemma 3의 연구 결과는 대규모 언어 모델 분야에 중요한 의미를 가집니다. LMSYS 챗봇 아레나에서 1338점의 Elo 점수를 기록하며 상위 10위 안에 들었고, 다양한 벤치마크에서 이전 버전들보다 크게 향상된 성능을 보여주었습니다. 특히 수학적 추론, 다국어 처리, 코드 생성, 질문 응답 등의 영역에서 상당한 개선을 이루었습니다.

이 연구는 단순히 모델 크기를 늘리는 것보다 효율적인 아키텍처 설계와 학습 방법이 중요하다는 것을 입증했습니다. 경량 모델임에도 불구하고 다양한 작업에서 강력한 성능을 보여주는 Gemma 3는 AI 기술의 접근성과 실용성을 높이는 데 중요한 진전을 이루었습니다. 또한 개인정보 보호와 모델 성능 사이의 균형을 성공적으로 달성함으로써, 책임감 있는 AI 개발의 새로운 방향을 제시했습니다.
- - -
# Gemma 3 기술 보고서

## 소개

Gemma 3는 Google DeepMind에서 개발한 경량 오픈 모델 제품군의 최신 버전으로, 1억에서 270억 매개변수 규모의 다양한 모델을 제공합니다. 이번 버전은 Gemma 제품군에 멀티모달 기능을 추가하여 시각적 이해 능력을 도입했으며, 더 넓은 범위의 언어를 지원하고 최소 128K 토큰의 긴 컨텍스트를 처리할 수 있습니다.

Gemma 3의 주요 아키텍처 변경점은 긴 컨텍스트 처리 시 급증하는 KV-캐시 메모리 문제를 해결하는 데 초점을 맞추고 있습니다. 이를 위해 로컬 어텐션 레이어와 글로벌 어텐션 레이어의 비율을 조정하고, 로컬 어텐션의 범위를 짧게 유지하는 방식을 채택했습니다. Gemma 3 모델들은 지식 증류(knowledge distillation) 기법을 통해 학습되었으며, 사전 학습 버전과 명령어 미세 조정 버전 모두에서 Gemma 2보다 우수한 성능을 달성했습니다.

특히 주목할 만한 점은 새로운 후처리 학습 방식을 통해 수학, 채팅, 명령어 따르기, 다국어 능력을 크게 향상시켰다는 것입니다. 이로 인해 Gemma3-4B-IT는 Gemma2-27B-IT와 경쟁력 있는 성능을 보이며, Gemma3-27B-IT는 다양한 벤치마크에서 Gemini-1.5-Pro와 비슷한 수준의 성능을 보여줍니다. Google DeepMind는 이러한 모든 모델을 커뮤니티에 공개하고 있습니다.

### 멀티모달 기능과 아키텍처 개선

Gemma 3는 Gemma 제품군에 여러 가지 새로운 기능을 도입했습니다. 멀티모달 측면에서, 대부분의 Gemma 3 모델은 SigLIP 비전 인코더([Zhai 등](https://arxiv.org/pdf/2111.02358))의 맞춤형 버전과 호환됩니다. 언어 모델은 SigLIP에 의해 인코딩된 소프트 토큰 시퀀스로 이미지를 처리합니다. 이미지 처리의 추론 비용을 줄이기 위해 비전 임베딩을 256개의 고정 크기 벡터로 압축합니다. 이 인코더는 고정 해상도에서 작동하며, LLaVA([Liu 등](https://arxiv.org/pdf/2304.08485))에서 영감을 받아 Pan and Scan(P&S) 방법을 통해 유연한 해상도를 지원합니다.

두 번째 주요 아키텍처 개선 사항은 성능 저하 없이 컨텍스트 크기를 128K 토큰으로 확장한 것입니다. 긴 컨텍스트에서의 도전 과제는 추론 중 KV 캐시의 메모리 폭발입니다. 이 문제를 해결하기 위해, 각 글로벌 레이어 사이에 여러 로컬 레이어를 배치하고, 로컬 레이어에는 1024 토큰의 작은 범위만 할당했습니다. 따라서 글로벌 레이어만 긴 컨텍스트에 주의를 기울이고, 5개의 로컬 레이어마다 1개의 글로벌 레이어가 배치됩니다.

### 사전 학습 및 후처리 최적화

사전 학습 최적화 방식은 Gemma 2와 유사하지만, 아키텍처 설계에 몇 가지 수정이 있습니다. Gemini 2.0과 동일한 토크나이저를 사용하며, 이미지 이해 기능을 도입하면서 다국어 기능을 향상시키기 위해 데이터 혼합 방식을 재검토했습니다. 모든 Gemma 3 모델은 지식 증류([Hinton 등](https://arxiv.org/pdf/1503.02531))를 통해 학습되었습니다.

후처리 학습에서는 수학, 추론, 채팅 능력 향상과 함께 Gemma 3의 새로운 기능인 긴 컨텍스트와 이미지 입력 통합에 중점을 두었습니다. 연구팀은 수학, 코딩, 채팅, 명령어 따르기, 다국어 등 모든 기능에서 향상을 가져오는 새로운 후처리 학습 접근 방식을 사용했습니다. 그 결과, Gemma 3 명령어 조정 모델은 강력하고 다재다능하며, 이전 버전보다 훨씬 뛰어난 성능을 보여줍니다.

![그림 1: Gemma 3 27B IT 모델과의 시각적 상호작용 예시](https://arxiv.org/html/2503.19786/extracted/6308720/assets/zurich-receipt.jpg)

그림 1은 Gemma 3 27B IT 모델의 시각적 상호작용 예시를 보여줍니다. 이 이미지는 레스토랑 영수증으로, 주문한 항목과 해당 가격의 상세 내역을 제공합니다. 영수증에는 Wienerschnitzel, Zurcher Geschnetzeltes, Preiselbeerssauce 등의 음식 항목과 그 수량, 그리고 스위스 프랑(CHF)과 유로(EUR)로 계산된 총 비용이 표시되어 있습니다. 총 청구 금액은 CHF 88.40이며, 세금 및 서비스 요금의 내역도 포함되어 있습니다. 이 예시는 Gemma 3 모델이 일상적인 시각 자료를 이해하고 처리할 수 있는 능력을 보여줍니다.

### 기술적 의의

Gemma 3의 주요 기술적 혁신은 다음과 같은 측면에서 중요합니다.

1. **효율적인 멀티모달 처리**: SigLIP 비전 인코더를 통합하여 이미지를 256개의 고정 크기 벡터로 압축함으로써 추론 비용을 크게 줄였습니다. 이는 경량 모델에서도 효과적인 시각 처리 능력을 가능하게 합니다.

2. **메모리 효율적인 긴 컨텍스트 처리**: 로컬 어텐션과 글로벌 어텐션 레이어의 비율을 조정하고 로컬 어텐션의 범위를 제한함으로써, 긴 컨텍스트 처리 시 KV 캐시 메모리 폭발 문제를 해결했습니다. 이는 수학적으로 다음과 같이 표현될 수 있습니다.

   메모리 사용량 = \\( O(L_g \times N + L_l \times W) \\)

   여기서 \\(L_g\\)는 글로벌 레이어 수, \\(N\\)은 총 토큰 수, \\(L_l\\)은 로컬 레이어 수, \\(W\\)는 로컬 어텐션 윈도우 크기입니다. 기존 방식에서는 모든 레이어가 글로벌 어텐션을 사용하여 \\(O((L_g + L_l) \times N)\\)의 메모리를 사용했습니다.

3. **지식 증류를 통한 효율적 학습**: 모든 Gemma 3 모델은 지식 증류 기법을 통해 학습되었습니다. 이 방법은 큰 교사 모델의 지식을 작은 학생 모델로 전달하는 과정으로, 다음과 같은 목적 함수를 최소화합니다.

   \\[ \min_{P_S} \sum_x -P_T(x|x_c) \log P_S(x|x_c) \\]

   여기서 \\(P_T(x|x_c)\\)는 주어진 컨텍스트 \\(x_c\\)에서 다음 토큰 \\(x\\)에 대한 교사 모델의 확률 분포이고, \\(P_S(x|x_c)\\)는 학생 모델의 매개변수화된 확률입니다.

4. **혁신적인 후처리 학습 방식**: 수학, 추론, 채팅, 명령어 따르기, 다국어 능력을 향상시키기 위한 새로운 후처리 학습 접근 방식을 도입했습니다. 이를 통해 Gemma3-4B-IT는 Gemma2-27B-IT와 경쟁력 있는 성능을 보이며, Gemma3-27B-IT는 Gemini-1.5-Pro와 비슷한 수준의 성능을 달성했습니다.

Gemma 3는 이러한 기술적 혁신을 통해 경량 모델임에도 불구하고 강력한 성능을 제공하며, 특히 멀티모달 처리, 긴 컨텍스트 이해, 다국어 지원 측면에서 이전 버전보다 크게 향상된 능력을 보여줍니다. 이는 소비자급 하드웨어에서도 효과적으로 실행될 수 있는 강력한 AI 모델의 개발을 향한 중요한 진전을 나타냅니다.

## 모델 아키텍처

Gemma 3 모델은 이전 버전과 유사한 디코더 전용 트랜스포머 아키텍처를 기반으로 하지만, 몇 가지 중요한 차이점과 개선 사항을 포함하고 있습니다. 기본적으로 Vaswani와 연구진이 제안한 트랜스포머 아키텍처를 따르면서도, 최신 연구 결과를 반영한 여러 기술적 개선이 이루어졌습니다.

### 기본 아키텍처 구성

Gemma 3는 Grouped-Query Attention(GQA)을 사용하며, 이는 Ainslie와 연구진이 제안한 방식으로 구현되었습니다. GQA는 다중 쿼리 어텐션의 일반화된 형태로, 쿼리 헤드를 여러 그룹으로 나누고 각 그룹이 하나의 키-값 헤드를 공유하는 방식입니다. 이를 통해 메모리 효율성과 추론 속도를 개선하면서도 모델의 품질을 유지할 수 있습니다.

모델은 RMSNorm(Root Mean Square Layer Normalization)을 사용하여 post-norm과 pre-norm을 구현합니다. 이는 Zhang과 Sennrich가 제안한 방식으로, 기존의 LayerNorm보다 계산 효율성이 높고 학습 안정성을 개선합니다. 또한 Gemma 2에서 사용되던 소프트 캐핑(soft-capping) 대신 QK-norm을 도입했는데, 이는 Dehghani와 연구진, Wortsman과 연구진, 그리고 Chameleon Team의 연구에서 영감을 받은 것입니다.

### 로컬/글로벌 레이어 인터리빙

Gemma 3의 가장 주목할 만한 아키텍처적 특징 중 하나는 로컬 슬라이딩 윈도우 셀프 어텐션과 글로벌 셀프 어텐션 레이어를 5:1 비율로 인터리빙하는 방식입니다. 구체적으로, 모델의 첫 번째 레이어부터 시작하여 5개의 로컬 어텐션 레이어마다 1개의 글로벌 어텐션 레이어가 배치됩니다.

로컬 슬라이딩 윈도우 셀프 어텐션은 Beltagy와 연구진이 제안한 방식을 기반으로 하며, 각 토큰이 주변의 제한된 윈도우 내의 토큰들에만 주의를 기울이도록 합니다. 이는 계산 효율성을 크게 향상시키면서도 지역적 문맥 이해 능력을 유지합니다. 반면, 글로벌 셀프 어텐션은 Luong과 연구진이 제안한 방식을 따르며, 모든 토큰이 시퀀스 내의 모든 다른 토큰에 주의를 기울일 수 있게 합니다.

이러한 인터리빙 방식은 긴 컨텍스트 처리 시 메모리 효율성과 계산 효율성을 크게 개선하면서도, 모델이 지역적 패턴과 글로벌 의존성을 모두 효과적으로 포착할 수 있게 합니다.

### 모델 크기 및 매개변수

Gemma 3는 다양한 크기의 모델을 제공합니다. 다음 표는 각 모델 변형의 매개변수 수를 보여줍니다.

| 모델 | 비전 인코더 | 임베딩 매개변수 | 비임베딩 매개변수 |
|------|------------|--------------|----------------|
| 1B   | 0          | 302M         | 698M           |
| 4B   | 417M       | 675M         | 3,209M         |
| 12B  | 417M       | 1,012M       | 10,759M        |
| 27B  | 417M       | 1,416M       | 25,600M        |

Gemma 3의 어휘 크기는 256k 항목으로 구성되어 있습니다.

### 긴 컨텍스트 처리

Gemma 3 모델은 1B 모델(32K 토큰)을 제외한 모든 모델에서 128K 토큰의 컨텍스트 길이를 지원합니다. 이를 위해 글로벌 셀프 어텐션 레이어에서는 RoPE(Rotary Position Embedding) 기본 주파수를 10k에서 1M으로 증가시켰으며, 로컬 레이어의 주파수는 10k로 유지했습니다.

긴 컨텍스트 윈도우를 확장하기 위해 Chen과 연구진이 제안한 위치 보간(positional interpolation) 방식과 유사한 과정을 따릅니다. 이 방법은 글로벌 셀프 어텐션 레이어의 범위를 효과적으로 확장하여 더 긴 시퀀스를 처리할 수 있게 합니다.

### 비전 모달리티

#### 비전 인코더

Gemma 3는 SigLIP 인코더의 400M 변형을 사용하여 이미지를 처리합니다. 이는 Zhai와 연구진이 개발한 것으로, Dosovitskiy가 제안한 Vision Transformer(ViT) 아키텍처를 기반으로 하며 Radford와 연구진이 개발한 CLIP 손실 함수의 변형을 사용하여 학습됩니다.

Gemma 비전 인코더는 896 x 896 크기로 리사이즈된 정사각형 이미지를 입력으로 받으며, 시각적 어시스턴트 태스크의 데이터로 파인튜닝됩니다. 효율성을 위해 4B, 12B, 27B 모델 전반에 걸쳐 비전 인코더를 공유하며, 학습 중에는 이를 고정(frozen)된 상태로 유지합니다.

#### Pan & Scan (P&S)

Gemma 비전 인코더는 896 × 896의 고정 해상도에서 작동합니다. 이로 인해 비정사각형 종횡비나 고해상도 이미지를 처리할 때 아티팩트가 발생할 수 있으며, 읽을 수 없는 텍스트나 작은 객체가 사라지는 문제가 생길 수 있습니다.

이 문제를 해결하기 위해 추론 중에 적응형 윈도잉 알고리즘을 사용합니다. 이 알고리즘은 이미지를 동일한 크기의 겹치지 않는 크롭으로 분할하여 전체 이미지를 커버하고, 이를 896×896 픽셀로 리사이즈하여 인코더에 전달합니다. 이 윈도잉은 필요한 경우에만 적용되며, 최대 크롭 수를 제어할 수 있습니다. 이는 추론 시에만 적용되는 최적화이며 더 빠른 추론을 위해 비활성화할 수 있습니다.

### 사전 학습

#### 학습 데이터

Gemma 3는 Gemma 2보다 약간 더 큰 토큰 예산으로 사전 학습됩니다. Gemma 3 27B는 14T 토큰, 12B 버전은 12T, 4B는 4T, 1B는 2T 토큰으로 학습됩니다. 이러한 토큰 증가는 사전 학습 중 사용되는 이미지와 텍스트의 혼합을 고려한 것입니다.

또한 언어 커버리지를 개선하기 위해 다국어 데이터의 양을 증가시켰습니다. 단일 언어 및 병렬 데이터를 모두 추가하고, Chung과 연구진에서 영감을 받은 전략을 사용하여 언어 표현의 불균형을 처리합니다.

#### 토크나이저

Gemma 3는 Gemini 2.0과 동일한 토크나이저를 사용합니다. 분할된 숫자, 보존된 공백, 바이트 수준 인코딩을 갖춘 SentencePiece 토크나이저입니다(Kudo와 Richardson). 결과적으로 생성된 어휘는 262k 항목을 포함하며, 이 토크나이저는 비영어 언어에 대해 더 균형 잡힌 처리를 제공합니다.

#### 학습 인프라

다음 표는 Gemma 3 모델의 학습 인프라를 보여줍니다.

| 모델 | 유형 | 칩 수 | 데이터 샤딩 | 시퀀스 샤딩 | 레플리카 샤딩 |
|------|------|-------|------------|------------|-------------|
| 1B   | TPUv5e | 512  | 16         | 16         | 2           |
| 4B   | TPUv5e | 2048 | 16         | 16         | 8           |
| 12B  | TPUv4  | 1444 | 16         | 16         | 24          |
| 27B  | TPUv5p | 1444 | 24         | 8          | 32          |

학습은 데이터, 시퀀스, 레플리카에 따른 샤딩을 통해 이루어집니다.

#### 필터링

Gemma 3는 원치 않거나 안전하지 않은 발화의 위험을 줄이고 특정 개인 정보 및 기타 민감한 데이터를 제거하는 필터링 기술을 사용합니다. 사전 학습 데이터 혼합에서 평가 세트를 오염 제거하고, 민감한 출력의 확산을 최소화하여 암기 위험을 줄입니다.

또한 Sachdeva와 연구진에서 영감을 받은 품질 재가중치 단계를 적용하여 낮은 품질의 데이터 발생을 줄입니다.

#### 증류

Gemma 3는 토큰당 256개의 로짓을 샘플링하며, 이는 교사 모델의 확률에 따라 가중치가 부여됩니다. 학생 모델은 이러한 샘플 내에서 교차 엔트로피 손실을 통해 교사의 분포를 학습합니다. 샘플링되지 않은 로짓에 대해서는 교사의 목표 분포가 0 확률로 설정되고 재정규화됩니다.

이러한 증류 과정을 통해 작은 모델이 더 큰 교사 모델의 지식을 효율적으로 학습할 수 있으며, 이는 특히 제한된 계산 자원으로 고품질 모델을 개발하는 데 중요한 접근 방식입니다.

### 양자화 인식 학습

원본 체크포인트와 함께, 저희는 다양한 표준 형식으로 양자화된 모델 버전도 제공합니다. 이러한 버전들은 각 모델을 양자화 인식 학습(Quantization Aware Training, QAT)을 사용하여 소수의 단계, 일반적으로 5,000단계 동안 미세 조정하여 얻어집니다. [Jacob과 연구진](https://arxiv.org/pdf/1712.05877)이 제안한 QAT 방법론을 적용했습니다. 이 과정에서 비양자화된 체크포인트의 확률을 목표로 사용하고, 사전 학습 및 사후 학습 분포가 일치하도록 데이터를 조정합니다.

가장 인기 있는 오픈 소스 양자화 추론 엔진(예: llama.cpp)을 기반으로, 세 가지 가중치 표현 방식에 중점을 두었습니다. 채널별 int4, 블록별 int4, 그리고 스위치드 fp8입니다. 아래 표에서는 각 가중치 표현 방식에 대해 32k 토큰 시퀀스에 대한 KV-캐시 유무에 따른 원본 및 양자화된 모델의 메모리 사용량을 보고합니다.

| 모델 | 원본 (GB) | 양자화 (GB) |
|------|-----------|-------------|
|      | bf16 | Int4 | \\( \text{Int4}_{\text{blocks=32}} \\) | SFP8 |
| 1B   | 2.0  | 0.5  | 0.7  | 1.0  |
| +KV  | 2.9  | 1.4  | 1.6  | 1.9  |
| 4B   | 8.0  | 2.6  | 2.9  | 4.4  |
| +KV  | 12.7 | 7.3  | 7.6  | 9.1  |
| 12B  | 24.0 | 6.6  | 7.1  | 12.4 |
| +KV  | 38.9 | 21.5 | 22.0 | 27.3 |
| 27B  | 54.0 | 14.1 | 15.3 | 27.4 |
| +KV  | 72.7 | 32.8 | 34.0 | 46.1 |

표: 32,768 컨텍스트 크기에서 가중치와 KV 캐싱(+KV)에 대한 원본(bfloat16)과 양자화된 체크포인트 간의 메모리 사용량(GB) 비교, 8비트로 양자화됨.

양자화 인식 학습(QAT)은 모델 배포 시 중요한 최적화 기법입니다. 이 방법은 학습 과정에서 양자화의 효과를 시뮬레이션하여 모델이 양자화로 인한 정확도 손실을 최소화하도록 조정됩니다. [Jacob과 연구진](https://arxiv.org/pdf/1712.05877)이 제안한 QAT 방법은 "가짜 양자화(fake quantization)" 노드를 학습 계산 그래프에 삽입하여 양자화의 효과를 시뮬레이션합니다. 이를 통해 역전파 과정에서 양자화된 모델을 직접 최적화할 수 있어, 단순한 사후 학습 양자화에서 발생하는 정확도 저하를 방지할 수 있습니다.

Gemma 3에서 사용된 세 가지 양자화 방식은 각각 다른 특성을 가집니다.

1. **채널별 int4 (per-channel int4)**: 각 출력 채널마다 별도의 스케일 파라미터를 사용하여 가중치를 4비트 정수로 양자화합니다. 이 방식은 채널 간 가중치 분포의 차이를 고려하여 더 정확한 양자화를 가능하게 합니다.

2. **블록별 int4 (per-block int4)**: 가중치 행렬을 작은 블록(여기서는 32개 요소)으로 나누고 각 블록마다 별도의 스케일 파라미터를 사용합니다. 이 방식은 가중치 분포의 지역적 변화를 더 잘 포착할 수 있습니다.

3. **스위치드 fp8 (switched fp8)**: 8비트 부동 소수점 형식을 사용하는 방식으로, 정수 양자화보다 더 넓은 동적 범위를 제공합니다. 이는 특히 극단적인 값이 중요한 경우에 유용합니다.

표에서 볼 수 있듯이, 양자화는 모델 크기를 크게 줄일 수 있습니다. 예를 들어, 27B 모델의 경우 원본 54GB에서 int4 양자화를 통해 14.1GB로 약 74% 감소시킬 수 있습니다. 그러나 KV-캐시를 포함하면 메모리 사용량이 증가하며, 이는 긴 컨텍스트 처리 시 중요한 고려사항입니다.

### 컴퓨팅 인프라

저희는 표 2에 설명된 대로 TPUv4, TPUv5e, TPUv5p를 사용하여 모델을 학습시켰습니다. 각 모델 구성은 학습 단계 시간을 최소화하도록 최적화되었습니다. 비전 인코더의 경우, 각 이미지에 대한 임베딩을 미리 계산하고 이 임베딩으로 직접 학습함으로써 언어 모델 학습에 추가 비용이 발생하지 않도록 했습니다.

옵티마이저 상태는 [Ren과 연구진](https://arxiv.org/pdf/2104.07857)이 제안한 ZeRO-3 구현을 사용하여 샤딩됩니다. 멀티 포드 학습의 경우, [Barham과 연구진](https://arxiv.org/pdf/2203.00222)의 Pathways 접근 방식을 사용하여 데이터 센터 네트워크를 통해 데이터 복제본 축소를 수행합니다. 저희는 Jax([Roberts와 연구진](https://arxiv.org/pdf/2211.09085))와 Pathways([Barham과 연구진](https://arxiv.org/pdf/2203.00222))의 '단일 컨트롤러' 프로그래밍 패러다임과 함께 GSPMD 파티셔너([Xu와 연구진](https://arxiv.org/pdf/2105.04663))와 MegaScale XLA 컴파일러([XLA, 2019](https://arxiv.org/pdf/1802.04799))를 사용합니다.

컴퓨팅 인프라 구축에 있어 GSPMD는 특히 중요한 역할을 합니다. [Xu와 연구진](https://arxiv.org/pdf/2105.04663)이 개발한 GSPMD는 ML 계산 그래프를 위한 일반적이고 확장 가능한 병렬화 시스템으로, 데이터 병렬성, 레이어 내 모델 병렬성, 공간 분할 등 다양한 병렬화 패턴을 표현할 수 있는 간단하면서도 강력한 텐서 샤딩 표현을 정의합니다. 이 시스템은 사용자가 제공한 샤딩 주석을 전체 계산 그래프로 자동으로 전파하여 XLA 연산자의 의미론을 활용해 호환 가능한 샤딩을 추론합니다. 이를 통해 사용자는 몇 개의 핵심 텐서에만 주석을 달고 나머지는 GSPMD가 처리하도록 할 수 있어, 기존의 단일 장치 프로그램을 확장하기 편리합니다.

### 컨텍스트 포맷팅

| 컨텍스트 요소 | 포맷 |
|------------|------|
| 사용자 턴 | <start_of_turn>user |
| 모델 턴 | <start_of_turn>model |
| 턴 종료 | <end_of_turn> |

대화 예시:
사용자: 당신은 누구인가요?
모델: 제 이름은 Gemma입니다!
사용자: 2+2는 얼마인가요?
모델: 2+2=4입니다.

모델 입력:
[BOS] <start_of_turn>user 당신은 누구인가요? <end_of_turn> <start_of_turn>model 제 이름은 Gemma입니다! <end_of_turn> <start_of_turn>user 2+2는 얼마인가요? <end_of_turn> <start_of_turn>model

모델 출력:
2+2=4입니다. <end_of_turn>

표: Gemma IT 모델을 위한 포맷팅. 토큰화 후 [BOS] 토큰을 명시적으로 추가하거나 토크나이저에서 add_bos=True 옵션을 사용하세요. "[BOS]" 텍스트를 토큰화하지 마세요.

이러한 컨텍스트 포맷팅은 모델이 대화 흐름을 이해하고 적절하게 응답하는 데 중요합니다. 특히 [BOS](Beginning of Sequence) 토큰의 올바른 추가는 모델이 시퀀스의 시작을 인식하는 데 필수적입니다. 이 포맷팅 방식은 사용자와 모델 간의 턴을 명확하게 구분하여 대화의 구조를 유지합니다.

### Gemma 3 27B IT 모델 평가

다음 표는 [Chiang과 연구진](https://arxiv.org/pdf/2306.05685)의 Chatbot Arena에서 Gemma 3 27B IT 모델의 평가 결과를 보여줍니다. 모든 모델은 인간 평가자들의 블라인드 사이드바이사이드 평가를 통해 서로 비교됩니다. 각 모델은 Elo 평가 시스템을 기반으로 점수가 부여됩니다.

| 순위 | 모델 | Elo | 95% CI | 오픈타입 | #params/#activated |
|-----|------|-----|--------|---------|-------------------|
| 1 | Grok-3-Preview-02-24 | 1412 | +8/-10 | - | - |
| 1 | GPT-4.5-Preview | 1411 | +11/-11 | - | - |
| 3 | Gemini-2.0-Flash-Thinking-Exp-01-21 | 1384 | +6/-5 | - | - |
| 3 | Gemini-2.0-Pro-Exp-02-05 | 1380 | +5/-6 | - | - |
| 3 | ChatGPT-4o-latest (2025-01-29) | 1377 | +5/-4 | - | - |
| 6 | DeepSeek-R1 | 1363 | +8/-6 | yes | MoE 671B/37B |
| 6 | Gemini-2.0-Flash-001 | 1357 | +6/-5 | - | - |
| 8 | o1-2024-12-17 | 1352 | +4/-6 | - | - |
| 9 | Gemma-3-27B-IT | 1338 | +8/-9 | yes | Dense 27B |
| 9 | Qwen2.5-Max | 1336 | +7/-5 | - | - |
| 9 | o1-preview | 1335 | +4/-3 | - | - |
| 9 | o3-mini-high | 1329 | +8/-6 | - | - |
| 13 | DeepSeek-V3 | 1318 | +8/-6 | yes | MoE 671B/37B |
| 14 | GLM-4-Plus-0111 | 1311 | +8/-8 | - | - |
| 14 | Qwen-Plus-0125 | 1310 | +7/-5 | - | - |
| 14 | Claude 3.7 Sonnet | 1309 | +9/-11 | - | - |
| 14 | Gemini-2.0-Flash-Lite | 1308 | +5/-5 | - | - |
| 18 | Step-2-16K-Exp | 1305 | +7/-6 | - | - |
| 18 | o3-mini | 1304 | +5/-4 | - | - |
| 18 | o1-mini | 1304 | +4/-3 | - | - |
| 18 | Gemini-1.5-Pro-002 | 1302 | +3/-3 | - | - |
| ... | ... | ... | ... | ... | ... |
| 28 | Meta-Llama-3.1-405B-Instruct-bf16 | 1269 | +4/-3 | yes | Dense 405B |
| ... | ... | ... | ... | ... | ... |
| 38 | Llama-3.3-70B-Instruct | 1257 | +5/-3 | yes | Dense 70B |
| ... | ... | ... | ... | ... | ... |
| 39 | Qwen2.5-72B-Instruct | 1257 | +3/-3 | yes | Dense 72B |
| ... | ... | ... | ... | ... | ... |
| 59 | Gemma-2-27B-it | 1220 | +3/-2 | yes | Dense 27B |

표: Chatbot Arena에서의 Gemma 3 27B IT 모델 평가. 모든 모델은 인간 평가자들의 블라인드 사이드바이사이드 평가를 통해 서로 비교됩니다. 각 모델은 Elo 평가 시스템을 기반으로 점수가 부여됩니다. Gemma-3-27B-IT 수치는 2025년 3월 8일에 받은 예비 결과입니다.

이 평가 결과에서 주목할 만한 점은 Gemma-3-27B-IT 모델이 1338의 Elo 점수를 기록하며 9위에 랭크되었다는 것입니다. 이는 이전 버전인 Gemma-2-27B-it(1220 Elo, 59위)보다 상당히 향상된 성능을 보여줍니다. 특히 Gemma-3-27B-IT는 파라미터 수가 훨씬 많은 일부 모델들(예: Meta-Llama-3.1-405B-Instruct-bf16, Llama-3.3-70B-Instruct, Qwen2.5-72B-Instruct)보다 더 높은 성능을 보여주고 있습니다. 이는 Gemma 3의 아키텍처 개선과 학습 방법론의 효과를 입증합니다.

또한 Gemma-3-27B-IT는 Dense 아키텍처를 사용하면서도 MoE(Mixture of Experts) 모델인 DeepSeek-R1(MoE 671B/37B)과 경쟁력 있는 성능을 보여주고 있습니다. 이는 효율적인 모델 설계와 학습 방법을 통해 더 적은 파라미터로도 높은 성능을 달성할 수 있음을 시사합니다.

### 명령어 튜닝

사전 학습된 모델은 이전 방식보다 개선된 후처리 학습 접근법을 통해 명령어 튜닝 모델로 변환됩니다. 이 섹션에서는 Gemma 3의 명령어 튜닝 과정에서 사용된 기술적 방법론과 접근 방식에 대해 자세히 살펴보겠습니다.

#### 기술적 접근법

Gemma 3의 후처리 학습 접근법은 [Hinton과 연구진](https://arxiv.org/pdf/1503.02531)이 제안한 지식 증류(knowledge distillation)의 개선된 버전을 기반으로 합니다. 이 방법은 큰 규모의 명령어 튜닝(IT) 교사 모델로부터 지식을 전달받는 과정을 포함합니다. 또한 [Sessa와 연구진](https://arxiv.org/pdf/2111.02358)의 BOND, [Ramé와 연구진](https://arxiv.org/pdf/2203.00222)의 WARM 및 WARP 기법을 개선한 강화학습(RL) 미세 조정 단계를 포함합니다.

지식 증류 과정에서는 큰 교사 모델의 출력 확률 분포를 작은 학생 모델이 모방하도록 학습합니다. 이는 수학적으로 다음과 같이 표현할 수 있습니다.

\\[ \min_{P_S} \sum_x -P_T(x|x_c) \log P_S(x|x_c) \\]

여기서 \\(P_T(x|x_c)\\)는 주어진 컨텍스트 \\(x_c\\)에서 다음 토큰 \\(x\\)에 대한 교사 모델의 확률 분포이고, \\(P_S(x|x_c)\\)는 학생 모델의 매개변수화된 확률입니다. 이 방법은 [Anil과 연구진](https://arxiv.org/pdf/1804.03235)이 제안한 코디스틸레이션(codistillation) 기법과도 관련이 있으며, 이는 동일한 모델 아키텍처의 여러 복사본을 병렬로 학습시키는 방식입니다.

Gemma 3에서는 이러한 지식 증류 과정을 통해 작은 모델이 더 큰 교사 모델의 지식을 효율적으로 학습할 수 있게 하며, 특히 제한된 계산 자원으로도 고품질 모델을 개발할 수 있도록 합니다.

#### 강화학습 목표

Gemma 3의 명령어 튜닝 과정에서는 다양한 보상 함수를 사용하여 모델의 여러 능력을 향상시킵니다. 구체적으로는 유용성(helpfulness), 수학, 코딩, 추론, 명령어 따르기, 다국어 능력을 개선하면서 모델의 유해성을 최소화하는 데 중점을 둡니다.

이를 위해 [Ramé와 연구진](https://arxiv.org/pdf/2203.00222)이 제안한 가중치 평균 보상 모델(weight averaged reward models)을 사용합니다. 이 모델은 인간 피드백 데이터로 학습되며, 모델의 출력이 얼마나 유용하고 안전한지 평가하는 데 사용됩니다. 또한 [Gehring과 연구진](https://arxiv.org/pdf/2410.02089)이 제안한 코드 실행 피드백(code execution feedback)을 활용합니다. 이 방법은 코드 생성 과정을 마르코프 결정 과정(MDP)으로 모델링하고, 언어 모델이 정책 역할을 하며 관찰과 행동이 토큰화된 텍스트 시퀀스인 환경에서 근접 정책 최적화(PPO)를 사용합니다.

수학 문제 해결을 위해서는 [Lambert와 연구진](https://arxiv.org/pdf/2410.05229)과 [DeepSeek-AI](https://arxiv.org/pdf/2411.15124)가 제안한 접근법을 기반으로 한 실제 정답 보상(ground-truth rewards)을 사용합니다. 이는 모델이 수학 문제를 정확하게 해결했을 때 보상을 제공하는 방식으로, 모델의 수학적 추론 능력을 향상시키는 데 효과적입니다.

이러한 강화학습 목표는 다음과 같은 보상 함수 형태로 구현될 수 있습니다.

\\[R(s_t, a_t) = r(s_t, a_t) - \beta \log \frac{\pi(a_t|c_t)}{\rho(a_t|c_t)}\\]

여기서 \\(r(s_t, a_t)\\)는 기본 보상 함수(예: 수학 문제를 맞추면 1, 틀리면 -1)이고, KL 페널티 항은 정책 \\(\pi\\)가 초기 정책 \\(\rho\\)에 가깝게 유지되도록 합니다. 이는 모델이 지나치게 보상에 최적화되어 원래의 언어 능력을 잃는 것을 방지합니다.

#### 데이터 필터링

모델 성능을 최대화하기 위해 후처리 학습에 사용되는 데이터를 신중하게 최적화합니다. 특히 다음과 같은 필터링 과정을 거칩니다.

1. 개인 정보가 포함된 예시 제거
2. 안전하지 않거나 유해한 모델 출력 필터링
3. 잘못된 자기 식별 데이터 제거
4. 중복된 예시 제거

또한 더 나은 인컨텍스트 귀속(in-context attribution), 불확실성 표현(hedging), 환각(hallucination) 최소화를 위한 거부(refusals) 능력을 장려하는 데이터 하위 집합을 포함합니다. 이러한 접근법은 사실성(factuality) 지표에서의 성능을 향상시키면서도 다른 지표에서의 모델 성능을 저하시키지 않습니다.

[Tulu 3](https://arxiv.org/pdf/2411.15124) 연구에서 영감을 받은 이러한 데이터 필터링 접근법은 모델이 다양한 능력에서 균형 잡힌 성능을 보이도록 하는 데 중요한 역할을 합니다. 특히 추론, 수학, 코딩, 안전성, 정확한 명령어 따르기, 지식 회상과 같은 핵심 기술을 목표로 하는 훈련 데이터셋을 신중하게 선별합니다.

#### [BOS] 토큰

사전 학습(PT) 모델과 명령어 튜닝(IT) 모델 모두에서 텍스트는 [BOS](Beginning of Sequence) 토큰으로 시작합니다. 이 토큰은 "[BOS]" 텍스트가 [BOS] 토큰으로 매핑되지 않기 때문에 명시적으로 추가해야 합니다. 예를 들어, Flax에는 토큰화할 때 이 토큰을 자동으로 추가하는 `add_bos=True` 옵션이 있습니다.

명령어 튜닝 모델을 위한 포맷팅 예시는 다음과 같습니다.

| 컨텍스트 요소 | 포맷 |
|------------|------|
| 사용자 턴 | <start_of_turn>user |
| 모델 턴 | <start_of_turn>model |
| 턴 종료 | <end_of_turn> |

대화 예시:
사용자: 당신은 누구인가요?
모델: 제 이름은 Gemma입니다!
사용자: 2+2는 얼마인가요?
모델: 2+2=4입니다.

이를 모델 입력으로 변환하면 다음과 같습니다.
```
[BOS] <start_of_turn>user 당신은 누구인가요? <end_of_turn> <start_of_turn>model 제 이름은 Gemma입니다! <end_of_turn> <start_of_turn>user 2+2는 얼마인가요? <end_of_turn> <start_of_turn>model
```

모델 출력:
```
2+2=4입니다. <end_of_turn>
```

#### PT와 IT 포맷팅 비교

모든 모델은 동일한 토크나이저를 공유하며, 일부 제어 토큰은 IT 포맷팅 전용입니다. 사전 학습(PT) 모델과 명령어 튜닝(IT) 모델 간의 주요 차이점은 생성 종료 시 출력하는 토큰입니다. PT 모델은 생성 끝에 `<eos>` 토큰을 출력하는 반면, IT 모델은 생성 끝에 `<end_of_turn>` 토큰을 출력합니다. 따라서 두 모델 유형 중 하나를 미세 조정할 때는 각각의 종료 토큰을 추가해야 합니다.

이러한 포맷팅 차이는 모델이 대화 흐름을 이해하고 적절하게 응답하는 데 중요합니다. 특히 [BOS] 토큰의 올바른 추가는 모델이 시퀀스의 시작을 인식하는 데 필수적입니다. 이 포맷팅 방식은 사용자와 모델 간의 턴을 명확하게 구분하여 대화의 구조를 유지합니다.

명령어 튜닝 과정에서 이러한 포맷팅을 일관되게 유지하는 것은 모델이 대화 맥락을 정확히 이해하고 적절한 응답을 생성하는 데 필수적입니다. 특히 다중 턴 대화에서 이전 대화 내용을 고려하여 일관된 응답을 생성하는 능력은 대화형 AI 시스템의 핵심 요소입니다.

이러한 명령어 튜닝 접근법을 통해 Gemma 3 모델은 다양한 작업에서 뛰어난 성능을 보이며, 특히 수학, 코딩, 추론, 다국어 능력 등에서 이전 버전보다 크게 향상된 결과를 보여줍니다. 이는 지식 증류, 강화학습, 신중한 데이터 필터링의 조합을 통해 달성되었으며, 이러한 기술적 혁신은 Gemma 3를 경량 모델임에도 불구하고 강력한 성능을 제공하는 모델로 만들었습니다.

# 최종 모델 평가

이 섹션에서는 IT(Instruction Tuned) 모델들을 다양한 자동화된 벤치마크와 인간 평가를 통해 여러 도메인에서 평가하고, MMLU와 같은 정적 벤치마크에서의 성능도 함께 살펴봅니다.

### LMSYS 챗봇 아레나 평가

LMSYS 챗봇 아레나([Chiang과 연구진](https://arxiv.org/pdf/2306.05685))는 인간 평가자들이 블라인드 방식으로 모델들을 일대일로 비교하는 평가 플랫폼입니다. 표 5에서 볼 수 있듯이, Gemma 3 27B IT 모델은 1338점의 Elo 점수를 기록하며 상위 10위 안에 들었습니다. 이는 DeepSeek-V3(1318점), LLaMA 3 405B(1257점), Qwen2.5-70B(1257점)와 같은 훨씬 더 큰 규모의 비사고형(non-thinking) 오픈 모델들보다 높은 점수입니다.

특히 주목할 만한 점은 Gemma 3의 Elo 점수가 이전 버전인 Gemma 2의 1220점보다 크게 향상되었다는 것입니다. 이러한 성능 향상은 Gemma 3에 도입된 아키텍처 개선과 학습 방법론의 효과를 입증합니다. 또한 이 Elo 점수는 시각적 능력을 고려하지 않은 것으로, 앞서 언급된 모델들 중 어느 것도 시각적 처리 능력을 갖추고 있지 않다는 점을 감안해야 합니다.

챗봇 아레나에서의 평가 결과는 Gemma 3 27B IT 모델이 파라미터 수가 훨씬 많은 일부 모델들보다 더 효과적인 성능을 보여준다는 것을 시사합니다. 이는 단순히 모델 크기를 늘리는 것보다 효율적인 아키텍처 설계와 학습 방법이 중요하다는 것을 보여줍니다.

### 표준 벤치마크 평가

표 6에서는 다양한 벤치마크에서 최종 모델들의 성능을 Gemini 1.5, Gemini 2.0, Gemma 2와 비교하여 보여줍니다. 외부 모델들은 종종 자체적인 평가 설정을 보고하기 때문에 직접적인 비교는 하지 않았습니다. 이는 동일한 설정에서 실행하더라도 공정한 비교를 보장할 수 없기 때문입니다. 따라서 모델 간의 더 공정한 비교를 위해서는 제3자의 정적 리더보드를 참조하는 것이 좋습니다.

표 6의 결과를 살펴보면, Gemma 3 모델들이 다양한 능력을 측정하는 벤치마크에서 이전 모델 버전들과 비교하여 상당한 성능 향상을 보여주고 있습니다.

| 모델 | Gemini 1.5 | Gemini 2.0 | Gemma 2 | Gemma 3 | FlashPro | FlashPro2 |
|------|------------|------------|---------|---------|----------|-----------|
| 크기 | - | - | - | 1B | 4B | 12B | 27B | 9B | 27B |
| MMLU-Pro | 67.3 | 75.8 | 77.6 | 79.1 | 15.6 | 46.8 | 56.9 | 14.7 | 43.6 | 60.6 | 67.5 |
| LiveCodeBench | 30.7 | 34.2 | 34.5 | 36.0 | 1.2 | 10.8 | 20.4 | 1.9 | 12.6 | 24.6 | 29.7 |
| Bird-SQL (dev) | 45.6 | 54.4 | 58.7 | 59.3 | 12.2 | 33.8 | 46.7 | 6.4 | 36.3 | 47.9 | 54.4 |
| GPQA Diamond | 51.0 | 59.1 | 60.1 | 64.7 | 24.7 | 28.8 | 34.3 | 19.2 | 30.8 | 40.9 | 42.4 |
| SimpleQA | 8.6 | 24.9 | 29.9 | 44.3 | 2.8 | 5.3 | 9.2 | 2.2 | 4.0 | 6.3 | 10.0 |
| FACTS Grounding | 82.9 | 80.0 | 84.6 | 82.8 | 43.8 | 62.0 | 62.4 | 36.4 | 70.1 | 75.8 | 74.9 |
| Global MMLU-Lite | 73.7 | 80.8 | 83.4 | 86.5 | 41.9 | 64.8 | 68.6 | 34.2 | 54.5 | 69.5 | 75.1 |
| MATH | 77.9 | 86.5 | 90.9 | 91.8 | 27.2 | 49.4 | 55.6 | 48.0 | 75.6 | 83.8 | 89.0 |
| HiddenMath | 47.2 | 52.0 | 63.5 | 65.2 | 1.8 | 10.4 | 14.8 | 15.8 | 43.0 | 54.5 | 60.3 |
| MMMU (val) | 62.3 | 65.9 | 71.7 | 72.7 | - | - | - | - | 48.8 | 59.6 | 64.9 |

이 결과에서 몇 가지 주목할 만한 점을 살펴보면:

1. **MMLU-Pro**: Gemma 3 27B 모델은 79.1점으로 Gemma 2(77.6점)보다 향상된 성능을 보여주며, Gemini 2.0(75.8점)보다도 높은 점수를 기록했습니다. 이는 Gemma 3의 지식 표현과 추론 능력이 크게 향상되었음을 시사합니다.

2. **MATH**: 수학적 추론 능력을 측정하는 MATH 벤치마크에서 Gemma 3 27B는 91.8점으로 Gemma 2(90.9점)와 Gemini 2.0(86.5점)보다 우수한 성능을 보여줍니다. 이는 Gemma 3의 수학적 추론 능력이 크게 향상되었음을 나타냅니다.

3. **Global MMLU-Lite**: 다국어 능력을 측정하는 이 벤치마크에서 Gemma 3 27B는 86.5점으로 Gemma 2(83.4점)와 Gemini 2.0(80.8점)보다 높은 점수를 기록했습니다. 이는 Gemma 3의 다국어 처리 능력이 크게 향상되었음을 보여줍니다.

4. **LiveCodeBench**: 코딩 능력을 측정하는 이 벤치마크에서 Gemma 3 27B는 36.0점으로 Gemma 2(34.5점)와 Gemini 2.0(34.2점)보다 약간 높은 점수를 기록했습니다. 이는 Gemma 3의 코드 생성 및 이해 능력이 향상되었음을 나타냅니다.

5. **SimpleQA**: 이 벤치마크에서 Gemma 3 27B는 44.3점으로 Gemma 2(29.9점)와 Gemini 2.0(24.9점)보다 크게 향상된 성능을 보여줍니다. 이는 Gemma 3의 질문 응답 능력이 크게 개선되었음을 시사합니다.

특히 주목할 만한 점은 Gemma 3의 작은 모델들도 상당히 강력한 성능을 보여준다는 것입니다. 예를 들어, Gemma 3 4B 모델은 Global MMLU-Lite에서 64.8점을 기록하여 상당히 경쟁력 있는 성능을 보여줍니다. 이는 [Hinton과 연구진](https://arxiv.org/pdf/1503.02531)이 제안한 지식 증류 기법의 효과를 입증하는 것으로, 작은 모델이 더 큰 교사 모델의 지식을 효과적으로 학습할 수 있음을 보여줍니다.

또한 FlashPro와 FlashPro2 모델들도 상당히 강력한 성능을 보여주고 있습니다. 특히 FlashPro2 27B 모델은 MATH 벤치마크에서 89.0점을 기록하여 Gemma 3 27B(91.8점)에 근접한 성능을 보여줍니다. 이는 이러한 모델들이 효율적인 아키텍처 설계와 학습 방법을 통해 높은 성능을 달성할 수 있음을 시사합니다.

부록에는 다른 벤치마크에서의 모델 평가 결과도 포함되어 있습니다. 이러한 추가 평가는 모델의 다양한 능력을 더 포괄적으로 이해하는 데 도움이 됩니다.

이러한 평가 결과는 Gemma 3 모델이 다양한 능력에서 이전 버전들보다 크게 향상된 성능을 보여준다는 것을 입증합니다. 특히 수학적 추론, 다국어 처리, 코드 생성, 질문 응답 등의 영역에서 상당한 개선이 이루어졌습니다. 이는 Gemma 3에 도입된 아키텍처 개선, 효율적인 학습 방법, 그리고 다양한 데이터 소스를 활용한 학습 과정의 효과를 보여줍니다.

또한 이러한 결과는 단순히 모델 크기를 늘리는 것보다 효율적인 아키텍처 설계와 학습 방법이 중요하다는 것을 시사합니다. Gemma 3 27B 모델이 훨씬 더 큰 규모의 모델들과 경쟁력 있는 성능을 보여주는 것은 이러한 접근 방식의 효과를 입증하는 것입니다.

결론적으로, Gemma 3 모델은 다양한 벤치마크에서 강력한 성능을 보여주며, 특히 수학적 추론, 다국어 처리, 코드 생성, 질문 응답 등의 영역에서 이전 버전들보다 크게 향상된 성능을 달성했습니다. 이는 Gemma 3가 경량 모델임에도 불구하고 다양한 작업에서 효과적으로 활용될 수 있는 강력한 모델임을 보여줍니다.

# 5. 애블레이션 연구

이 섹션에서는 Gemma 3 모델의 아키텍처 변경 사항과 새롭게 추가된 시각적 능력에 대한 영향을 중점적으로 분석합니다.

## 5.1 사전 학습 능력 탐색

![그림 2: Gemma 2와 Gemma 3 사전 학습 모델의 일반적 능력 비교 요약](https://arxiv.org/html/2503.19786/x1.png)

그림 2는 Gemma 2와 Gemma 3 사전 학습 모델의 다양한 일반 능력에 대한 성능을 비교한 레이더 차트입니다. 이 차트는 코드, 시각, 다국어, 과학, 추론과 같은 다양한 능력을 축으로 표현하고 있으며, 두 모델 버전의 성능 점수를 연결하는 선으로 구성되어 있습니다. 주목할 만한 발견은 Gemma 3가 대부분의 능력에서 Gemma 2를 능가하며, 특히 코드, 시각, 추론 영역에서 상당한 개선을 보여준다는 점입니다.

사전 학습 중에 모델이 일반적인 능력을 얼마나 잘 습득하는지 확인하기 위해 여러 표준 벤치마크를 프로브로 사용합니다. 그림 2에서는 Gemma 2와 Gemma 3의 사전 학습 모델을 과학, 코드, 사실성, 다국어, 추론, 시각과 같은 일반 능력에 걸쳐 비교하고 있습니다. 이러한 플롯에 사용된 다양한 공개 벤치마크에서의 성능 세부 사항은 부록에 요약되어 있습니다.

전반적으로, 시각 능력이 추가되었음에도 불구하고 새로운 버전이 대부분의 카테고리에서 개선된 것을 확인할 수 있습니다. 특히 이번 버전에서는 다국어 능력에 중점을 두었으며, 이는 모델의 품질에 직접적인 영향을 미칩니다. 그러나 오염 제거 기술을 사용했음에도 불구하고, 이러한 프로브의 오염 위험이 항상 존재하기 때문에([Mirzadeh와 연구진](https://arxiv.org/pdf/2402.18391)) 더 확정적인 결론을 내리기는 어렵습니다.

## 5.2 로컬:글로벌 어텐션 레이어

![그림 3: 검증 세트에서 로컬:글로벌 비율이 퍼플렉시티에 미치는 영향](https://arxiv.org/html/2503.19786/x6.png)

그림 3은 로컬 대 글로벌 비율이 검증 세트의 퍼플렉시티에 미치는 영향을 보여줍니다. 7:1의 로컬 대 글로벌 비율까지도 영향이 미미한 것으로 나타납니다. 이 애블레이션은 텍스트 전용 모델로 실행되었습니다.

추론 중 메모리 소비와 성능에 대한 로컬 및 글로벌 셀프 어텐션 레이어의 변경 영향을 측정했습니다.

### 로컬:글로벌 비율

그림 3에서는 로컬 대 글로벌 어텐션 레이어의 다양한 비율을 비교합니다. Gemma 2 모델에서는 1:1 비율이 사용되었고, Gemma 3에서는 5:1 비율이 사용됩니다. 이 비율을 변경해도 퍼플렉시티에 미치는 영향은 미미한 것으로 관찰됩니다.

### 슬라이딩 윈도우 크기

![그림 4: 슬라이딩 윈도우 크기가 검증 세트의 퍼플렉시티에 미치는 영향](https://arxiv.org/html/2503.19786/x7.png)

그림 4는 다양한 글로벌:로컬 비율 구성에서 로컬 어텐션 레이어의 슬라이딩 윈도우 크기를 비교합니다. 1:1과 1:3 로컬 대 글로벌 레이어 비율을 가진 두 개의 2B 모델을 고려합니다. 슬라이딩 윈도우는 퍼플렉시티에 영향을 미치지 않고 상당히 줄일 수 있습니다. 이 애블레이션도 텍스트 전용 모델로 실행되었습니다.

### KV 캐시 메모리에 미치는 영향

![그림 5: 32k 크기의 사전 채워진 KV 캐시로 추론 중 모델 대 KV 캐시 메모리](https://arxiv.org/html/2503.19786/x8.png)

그림 5는 32k 토큰의 컨텍스트로 추론 중 모델과 KV 캐시에 사용되는 메모리 간의 균형을 보여줍니다. "글로벌 전용" 구성은 대부분의 밀집 모델에서 사용되는 표준 구성입니다. "1:1, sw=4096"은 Gemma 2에서 사용됩니다. "글로벌 전용" 구성은 60%의 메모리 오버헤드를 초래하는 반면, 1:3 비율과 1024의 슬라이딩 윈도우("sw=1024")를 사용하면 이는 15% 미만으로 감소합니다. 이 애블레이션은 텍스트 전용 모델로 실행되었습니다.

![그림 6: 컨텍스트 길이에 따른 KV 캐시 메모리](https://arxiv.org/html/2503.19786/x9.png)

그림 6에서는 2B 아키텍처(L:G=5:1, sw=1024)와 "글로벌 전용" 2B 모델(LLaMa나 Gemma 1에서 사용된 것과 같은)의 컨텍스트 길이에 따른 KV 캐시에 사용되는 메모리를 계산합니다.

## 5.3 긴 컨텍스트 활성화

![그림 7: RoPE 재조정 전후 사전 학습 모델의 긴 컨텍스트 성능](https://arxiv.org/html/2503.19786/x9.png)

그림 7은 RoPE 재조정 전후 사전 학습 모델의 긴 컨텍스트 성능을 보여줍니다. 이 그래프는 다양한 컨텍스트 길이에 대한 평균 퍼플렉시티를 나타내며, 세 가지 모델 크기(4B, 12B, 27B)에 대해 긴 컨텍스트 설정 적용 전후를 비교합니다. RoPE 재조정이 모델의 긴 컨텍스트 처리 능력을 크게 향상시킬 수 있음을 보여주며, 이는 긴 형식의 텍스트 생성과 같은 작업에 중요합니다.

처음부터 128K 시퀀스로 학습하는 대신, 32K 시퀀스로 모델을 사전 학습한 다음 사전 학습 마지막에 4B, 12B, 27B 모델을 128K 토큰으로 확장하면서 RoPE([Chen과 연구진](https://arxiv.org/pdf/2306.15595))를 재조정합니다. 실제로 8의 스케일링 팩터가 잘 작동하는 것을 발견했습니다. Gemma 2와 비교하여, 글로벌 셀프 어텐션 레이어의 RoPE 기본 주파수를 10k에서 1M으로 증가시켰으며, 로컬 셀프 어텐션 레이어는 10k로 유지했습니다.

그림 7에서는 다양한 컨텍스트 길이에 대한 퍼플렉시티에 미치는 영향을 보여줍니다. 모델들은 128K까지 일반화되지만, 계속 확장하면 빠르게 성능이 저하됩니다.

## 5.4 작은 교사 대 큰 교사

![그림 8: 작은 교사와 큰 교사 비교](https://arxiv.org/html/2503.19786/x1.png)

그림 8은 학습 토큰 크기에 따른 작은 교사와 큰 교사를 사용할 때의 퍼플렉시티 상대적 차이를 보여줍니다. 숫자가 작을수록 더 큰 교사로부터 증류하는 것이 더 좋다는 것을 의미합니다.

작은 모델을 학습시키기 위해서는 더 작은 교사로부터 증류하는 것이 바람직하다는 것이 일반적인 발견입니다. 이는 이러한 연구들이 종종 더 나쁜 교사를 사용하는 정규화 효과가 더 좋은 교사를 사용하는 이점을 능가하는 설정에서 수행되기 때문이라고 생각합니다.

다른 크기의 두 교사, 하나는 크고 하나는 작은 교사로부터 학생을 학습시키고, 이를 다양한 학습 기간에 대해 수행했습니다. 그림 8에서는 짧은 학습 기간에는 더 작은 교사가 더 좋지만, 더 긴 학습에서는 이 경향이 역전되는 것을 관찰할 수 있습니다.

## 5.5 비전 인코더

### 이미지 해상도의 영향

| 해상도 | DocVQA | InfoVQA | TextVQA |
|--------|--------|---------|---------|
| 256    | 31.9   | 23.1    | 44.1    |
| 448    | 45.4   | 31.6    | 53.5    |
| 896    | 59.8   | 33.7    | 58.0    |

표 7: 이미지 인코더 입력 해상도의 영향. 짧은 일정으로 2B Gemma 모델을 사용하여 비전 인코더 사전 학습에 대한 입력 이미지 해상도의 효과를 관찰하기 위해 몇 가지 평가 벤치마크에서 성능을 측정합니다.

SigLIP([Zhai와 연구진](https://arxiv.org/pdf/2111.02358))을 기반으로 한 비전 인코더를 사용합니다. 비전 인코더는 고정되어 있으며, 언어 모델만 학습됩니다. 이 멀티모달 데이터의 각 이미지는 해당 비전 인코더에서 256개의 이미지 토큰으로 표현됩니다. 따라서 더 높은 해상도 인코더는 출력을 256 토큰으로 줄이기 위해 평균 풀링을 사용합니다. 예를 들어, 896 해상도 인코더는 출력에 4x4 평균 풀링을 적용합니다.

표 7에서 볼 수 있듯이, 더 높은 해상도 인코더가 더 작은 인코더보다 성능이 우수합니다.

### Pan & Scan

| 모델 | DocVQA | InfoVQA | TextVQA |
|------|--------|---------|---------|
| 4B   | 72.8   | 44.1    | 58.9    |
| 4B w/ P&S | 81.0 | 57.0 | 60.8 |
| \\( \Delta \\) | (+8.2) | (+12.9) | (+1.9) |
| 27B  | 85.6   | 59.4    | 68.6    |
| 27B w/ P&S | 90.4 | 76.4 | 70.2 |
| \\( \Delta \\) | (+4.8) | (+17.0) | (+1.6) |

표 8: P&S의 영향. 사전 학습된 체크포인트에 P&S를 적용한 경우와 적용하지 않은 경우의 유효 세트에 대한 4-샷 평가 결과입니다. 다양한 종횡비의 이미지나 이미지에 있는 텍스트를 읽는 것과 관련된 작업에서 성능이 향상됩니다.

P&S(Pan & Scan)는 이미지를 원래의 종횡비와 이미지 해상도에 가깝게 캡처할 수 있게 합니다. 표 8에서는 P&S를 적용한 경우와 적용하지 않은 경우의 27B IT 모델을 비교합니다. 예상대로, 이미지를 원래 해상도에 가깝게 처리할 수 있는 능력은 이미지에서 텍스트를 읽는 형태의 작업에 크게 도움이 되며, 이는 시각적 언어 모델에 특히 중요합니다.

# 6 기억과 개인정보 보호

대규모 언어 모델은 학습 과정에서 사용된 텍스트의 일부를 거의 그대로 복제하여 출력할 수 있습니다([Carlini 등](https://arxiv.org/pdf/2202.07646), [2022](https://arxiv.org/pdf/2311.17035); [Ippolito 등](https://arxiv.org/pdf/2210.17546); [Biderman 등](https://arxiv.org/pdf/2202.07646); [Nasr 등](https://arxiv.org/pdf/2311.17035)). 여러 이전 보고서들은 기억률(memorization rate)을 측정하여 이러한 위험을 정량화하는 감사 결과를 발표했습니다([Gemini Team](https://arxiv.org/pdf/2202.07646), [2024](https://arxiv.org/pdf/2311.17035); [Gemma Team](https://arxiv.org/pdf/2210.17546), [b](https://arxiv.org/pdf/2202.07646); [Anil 등](https://arxiv.org/pdf/2311.17035); [Chowdhery 등](https://arxiv.org/pdf/2210.17546); [LLaMa Team](https://arxiv.org/pdf/2311.17035)).

이 "기억률"은 모델이 학습 데이터와 일치하는 생성물의 비율로 정의됩니다. 여기서 "모델이 학습 데이터를 '포함'한다는 의미는 모델 내에 해당 데이터의 복사본이 있다는 뜻이 아닙니다. 오히려 모델은 학습 데이터의 속성을 기억하여 특정 경우에 통계적으로 그러한 학습 데이터를 생성할 수 있습니다. 이는 모델이 실제로 포함하고 있는 학습 데이터의 특징에 대한 정보와 규칙을 따르는 방식으로 이루어집니다."

기억률을 측정하기 위해 [Gemma Team](https://arxiv.org/pdf/2202.07646)에서 설명한 방법론을 따릅니다. 구체적으로, 다양한 코퍼스에 걸쳐 균일하게 분포된 학습 데이터의 상당 부분을 샘플링하고, 길이 50의 접두사와 길이 50의 접미사를 사용하여 발견 가능한 추출([Nasr 등](https://arxiv.org/pdf/2311.17035))을 테스트합니다. 텍스트는 연속에서 모든 토큰이 소스 접미사와 일치하면 "정확히 기억됨(exactly memorized)"으로, 편집 거리 10% 이내로 일치하면 "대략 기억됨(approximately memorized)"으로 분류합니다.

![그림 9: 정확 및 대략적 기억에 대한 총 기억률. Gemma 3 모델은 이전의 모든 모델보다 훨씬 적게 기억합니다. *이 모델들에 대한 대략적 기억 결과는 없습니다.](https://arxiv.org/html/2503.19786/x2.png)

그림 9는 Gemma와 Gemini 모델 간의 기억률을 비교합니다. 이 모델들은 역시간 순서로 배열되어 있으며, 가장 최신 Gemma 3 모델이 왼쪽에 있습니다. Gemma 3 모델이 이전 모델들보다 장문 텍스트를 훨씬 낮은 비율로 기억한다는 것을 발견했습니다(로그 y축에 주목). 4B, 12B, 27B 모델 간의 기억률 차이는 미미하며, 1B 모델은 이러한 더 큰 모델들보다 기억률이 낮습니다. 또한 텍스트의 더 큰 비율이 대략적으로 기억된 것으로 특징지어지며, 정확한 기억에 비해 대략적인 기억의 상대적 증가는 평균적으로 약 24배입니다.

또한 생성물이 개인 정보를 포함할 수 있는 비율도 연구했습니다. 잠재적인 개인 정보를 식별하기 위해 Google Cloud Sensitive Data Protection(SDP) 서비스를 사용했습니다. SDP는 개인 정보를 포함할 수 있는 텍스트를 식별하기 위해 광범위한 탐지 규칙을 사용합니다. SDP는 높은 재현율(recall)을 목표로 설계되었으며 정보가 나타날 수 있는 맥락을 고려하지 않기 때문에 많은 거짓 양성(false positive)을 초래합니다. 따라서 기억된 것으로 분류된 출력에 포함된 잠재적 개인 정보의 실제 양을 과대평가할 가능성이 높습니다. SDP는 또한 낮음, 중간, 높음의 광범위한 심각도 수준을 제공합니다. 텍스트는 SDP가 어떤 심각도 수준에서든 개인 정보로 분류하면 개인 정보로 분류됩니다.

모든 Gemma 3 모델에서 기억으로 특징지어진 출력에서 개인 정보가 관찰되지 않았습니다. 이는 기억으로 분류된 출력에서 개인 데이터의 비율이 낮아 탐지 임계값 이하임을 나타냅니다.

## 기억률 측정 방법론의 기술적 세부사항

Gemma 3 모델의 기억률을 측정하기 위해 사용된 방법론은 [Nasr 등](https://arxiv.org/pdf/2311.17035)이 제안한 발견 가능한 추출(discoverable extraction) 개념을 기반으로 합니다. 이 방법은 모델이 학습 데이터의 일부를 얼마나 쉽게 재생산할 수 있는지 측정합니다.

발견 가능한 추출은 다음과 같이 정의됩니다. 시퀀스 \\(s\\)가 모델 \\(f\\)로부터 "추출 가능"하다는 것은 접두사 \\(p\\)가 존재하여 연결 \\([p||s]\\)가 학습 데이터에 포함되어 있고, \\(f\\)가 \\(p\\)로 프롬프트되었을 때 탐욕적 디코딩(greedy decoding)을 사용하여 \\(s\\)를 생성한다는 것을 의미합니다.

구체적인 측정 과정은 다음과 같습니다.

1. 학습 데이터에서 다양한 코퍼스에 걸쳐 균일하게 분포된 상당한 양의 텍스트를 샘플링합니다.
2. 각 샘플에 대해 길이 50의 접두사를 추출하고 이를 모델에 입력으로 제공합니다.
3. 모델이 생성한 출력을 원래 텍스트의 접미사(길이 50)와 비교합니다.
4. 두 가지 유형의 기억을 측정합니다.
   - **정확한 기억(Exact memorization)**: 모델이 생성한 모든 토큰이 원본 접미사와 정확히 일치하는 경우
   - **대략적인 기억(Approximate memorization)**: 모델이 생성한 토큰이 원본 접미사와 10% 이내의 편집 거리로 일치하는 경우

편집 거리(edit distance)는 한 문자열을 다른 문자열로 변환하는 데 필요한 최소 편집 작업(삽입, 삭제, 대체)의 수를 측정합니다. 10%의 임계값은 약간의 변형을 허용하면서도 의미적으로 동일한 콘텐츠를 포착하기 위해 선택되었습니다.

### 기억률과 모델 크기의 관계

[Carlini 등](https://arxiv.org/pdf/2202.07646)의 연구에 따르면, 일반적으로 모델 크기와 기억률 사이에는 로그 선형 관계가 있습니다.

\\[ \text{기억률} \propto \log(\text{모델 크기}) \\]

그러나 Gemma 3 모델에서는 4B, 12B, 27B 모델 간의 기억률 차이가 미미한 것으로 나타났습니다. 이는 Gemma 3 아키텍처와 학습 방법이 모델 크기가 증가함에도 불구하고 기억률을 효과적으로 제한한다는 것을 시사합니다. 특히 1B 모델이 더 큰 모델들보다 기억률이 낮은 것은 모델 용량과 기억 능력 사이의 관계를 보여줍니다.

### 대략적 기억과 정확한 기억의 비교

Gemma 3 모델에서 대략적 기억의 비율이 정확한 기억보다 평균적으로 24배 높다는 발견은 중요한 의미를 갖습니다. 이는 모델이 학습 데이터를 정확히 복제하기보다는 의미적으로 유사한 콘텐츠를 생성하는 경향이 있음을 시사합니다. [Ippolito 등](https://arxiv.org/pdf/2210.17546)의 연구에서 논의된 바와 같이, 이러한 "대략적 기억"은 단순한 텍스트 매칭 기반 방어 메커니즘을 우회할 수 있어 개인정보 보호 관점에서 중요한 고려사항입니다.

대략적 기억은 다음과 같은 수학적 관계로 표현될 수 있습니다.

\\[ R_{approx} \approx 24 \times R_{exact} \\]

여기서 \\(R_{approx}\\)는 대략적 기억률이고 \\(R_{exact}\\)는 정확한 기억률입니다.

### 개인정보 탐지 방법론

잠재적 개인정보를 탐지하기 위해 사용된 Google Cloud Sensitive Data Protection(SDP) 서비스는 다양한 유형의 개인 식별 정보(PII)를 탐지하도록 설계되었습니다. 이 서비스는 다음과 같은 특성을 가집니다.

1. **높은 재현율 설계**: 가능한 한 많은 잠재적 개인정보를 포착하기 위해 설계되었습니다.
2. **맥락 무시**: 텍스트가 나타나는 맥락을 고려하지 않아 거짓 양성이 발생할 수 있습니다.
3. **심각도 수준 분류**: 탐지된 정보를 낮음, 중간, 높음의 심각도 수준으로 분류합니다.

SDP의 높은 재현율 설계로 인해, 실제 개인정보의 양은 보고된 것보다 적을 가능성이 높습니다. 그럼에도 불구하고, Gemma 3 모델에서 기억으로 분류된 출력에서 개인정보가 전혀 탐지되지 않았다는 사실은 이러한 모델들이 개인정보 보호 측면에서 강력하다는 것을 시사합니다.

## 기억률 감소의 의의

Gemma 3 모델이 이전 모델들보다 현저히 낮은 기억률을 보이는 것은 여러 가지 중요한 의미를 갖습니다.

1. **개인정보 보호 강화**: 낮은 기억률은 모델이 학습 데이터에서 개인정보를 노출할 위험이 감소했음을 의미합니다.

2. **일반화 능력 향상**: 모델이 특정 학습 데이터를 단순히 기억하는 대신 더 일반화된 패턴을 학습했을 가능성이 있습니다.

3. **학습 방법론의 개선**: 이는 Gemma 3의 학습 과정에서 사용된 필터링 기술과 데이터 처리 방법이 효과적이었음을 시사합니다.

4. **모델 크기와 기억률의 분리**: 4B, 12B, 27B 모델 간의 기억률 차이가 미미하다는 것은 모델 크기 증가가 반드시 기억률 증가로 이어지지 않는다는 것을 보여줍니다.

이러한 발견은 대규모 언어 모델의 개발에서 개인정보 보호와 모델 성능 사이의 균형을 맞추는 데 중요한 통찰력을 제공합니다. Gemma 3 모델은 이전 모델들보다 낮은 기억률을 유지하면서도 다양한 벤치마크에서 강력한 성능을 보여주고 있어, 개인정보 보호와 모델 성능이 반드시 상충 관계에 있지 않다는 것을 시사합니다.

## 기억률 감소를 위한 기술적 접근법

Gemma 3 모델에서 관찰된 낮은 기억률은 여러 기술적 접근법의 결과일 수 있습니다.

1. **데이터 필터링**: 학습 데이터에서 개인정보가 포함된 텍스트를 식별하고 제거하는 강화된 필터링 기술이 적용되었을 가능성이 있습니다.

2. **정규화 기법**: 모델이 특정 학습 예제를 과도하게 기억하는 것을 방지하는 정규화 기법이 사용되었을 수 있습니다.

3. **학습 알고리즘 개선**: 모델이 일반적인 패턴을 학습하도록 장려하고 특정 예제의 기억을 억제하는 학습 알고리즘의 수정이 있었을 수 있습니다.

4. **데이터 중복 제어**: 학습 데이터에서 동일하거나 매우 유사한 예제의 반복을 제한하는 기술이 적용되었을 수 있습니다. [Carlini 등](https://arxiv.org/pdf/2202.07646)의 연구에 따르면 데이터 중복과 기억률 사이에는 로그 선형 관계가 있습니다.

   \\[ \text{기억률} \propto \log(\text{데이터 중복}) \\]

이러한 접근법들은 모델의 성능을 유지하면서도 개인정보 보호를 강화하는 데 기여했을 것입니다. 특히 Gemma 3 모델에서 기억으로 분류된 출력에서 개인정보가 전혀 탐지되지 않았다는 사실은 이러한 기술들이 효과적으로 작동했음을 시사합니다.

## 결론

Gemma 3 모델은 이전 모델들보다 현저히 낮은 기억률을 보여주며, 특히 기억으로 분류된 출력에서 개인정보가 전혀 탐지되지 않았습니다. 이는 모델의 개인정보 보호 측면에서 중요한 진전을 나타냅니다. 4B, 12B, 27B 모델 간의 기억률 차이가 미미하다는 것은 모델 크기 증가가 반드시 기억률 증가로 이어지지 않는다는 것을 시사하며, 이는 기존의 연구 결과와는 다소 차이가 있습니다.

대략적 기억의 비율이 정확한 기억보다 평균적으로 24배 높다는 발견은 모델이 학습 데이터를 정확히 복제하기보다는 의미적으로 유사한 콘텐츠를 생성하는 경향이 있음을 보여줍니다. 이는 단순한 텍스트 매칭 기반 방어 메커니즘의 한계를 강조하며, 더 정교한 개인정보 보호 접근법의 필요성을 시사합니다.

Gemma 3 모델의 낮은 기억률과 개인정보 보호 특성은 대규모 언어 모델의 개발에서 개인정보 보호와 모델 성능 사이의 균형을 맞추는 데 중요한 진전을 나타냅니다. 이러한 발견은 향후 대규모 언어 모델의 개발에서 개인정보 보호를 강화하기 위한 기술적 접근법에 대한 중요한 통찰력을 제공합니다.

# 책임, 안전성, 보안

Gemma 모델 개발에 있어 책임, 안전성, 보안은 가장 중요한 요소입니다. Gemma 3 사용자들의 위험을 줄이기 위해, 개발 워크플로우 전반에 걸쳐 향상된 내부 안전 프로세스를 지속적으로 통합해왔으며, 이는 최근 Google AI 모델들과 같은 방향성을 가집니다([Gemini Team](https://arxiv.org/pdf/2503.19786)). 이러한 접근법은 학습 시점의 안전성 완화에 초점을 맞추고 있으며, 새롭게 도입된 이미지-텍스트 변환 기능에 대한 강력하고 투명한 모델 평가를 포함합니다.

## 거버넌스 및 평가

Gemma의 이점과 위험을 평가하는 접근 방식은 Gemma 1에 대해 설명된 것과 유사하며([Gemma Team](https://arxiv.org/pdf/2503.19786)), 지원되는 모달리티의 변화를 고려합니다. AI의 개방성이 이러한 기술의 혜택을 사회 전반에 확산시킬 수 있다는 믿음을 계속 유지하고 있지만, 개인과 기관 수준 모두에서 해를 끼칠 수 있는 악의적인 사용의 위험에 대해서도 평가해야 합니다([Weidinger 등](https://arxiv.org/pdf/2202.07646)).

Gemma 출시 이후, 이러한 모델들이 다양한 사회적으로 유익한 애플리케이션을 주도하는 것을 확인했습니다. 예를 들어, Gemma 3로 구축된 4B 이미지 안전성 분류기인 ShieldGemma 2는 이미지 안전성을 위한 즉시 사용 가능한 솔루션을 제공하며, 위험한 콘텐츠, 성적으로 노골적인 내용, 폭력 카테고리에 걸쳐 안전성 라벨을 출력합니다.

Gemma 3 모델 출시에는 모델 기능의 변화에 대한 특별한 주의와 기존 멀티모달 LLM의 진화하는 위험에 대한 면밀한 모니터링이 필요했으며([Lin 등](https://arxiv.org/pdf/2202.07646)), 모델이 실제 환경에서 어떻게 사용되고 있는지에 대한 이해도 필요했습니다. Gemma에 대한 악의적인 사용 보고를 아직 받지 않았지만, 그러한 보고를 조사하는 데 계속 전념하고 있으며, 학계 및 개발자 커뮤니티와 협력하고 자체 모니터링을 수행하여 그러한 사례를 식별하고 있습니다.

기능이 향상되었음에도 불구하고, 더 크고 강력한 오픈 모델이 이미 많이 사용 가능한 상황에서 이번 출시가 전반적인 위험 환경에 미치는 영향은 미미할 것으로 판단됩니다.

## 안전성 정책 및 학습 시점 완화 조치

Gemma의 안전성 접근법의 핵심 기둥은 Gemini 모델과 마찬가지로([Gemini Team](https://arxiv.org/pdf/2503.19786)) 미세 조정된 모델을 Google의 안전성 정책과 일치시키는 것입니다. 이러한 정책들은 모델이 다음과 같은 유해한 콘텐츠를 생성하는 것을 방지하도록 설계되었습니다.

* 아동 성적 학대 및 착취
* 해를 끼칠 수 있는 개인 식별 정보 공개(예: 사회보장번호)
* 혐오 발언 및 괴롭힘
* 위험하거나 악의적인 콘텐츠(자해 촉진 또는 유해한 활동 지시 포함)
* 성적으로 노골적인 콘텐츠
* 과학적 또는 의학적 합의에 반하는 의학적 조언

사전 학습된 체크포인트와 미세 조정된 체크포인트가 유해한 콘텐츠를 생성할 가능성을 줄이기 위해 사전 학습 데이터에 대한 상당한 안전성 필터링을 수행했습니다. 미세 조정된 모델의 경우, SFT(Supervised Fine-Tuning)와 RLHF(Reinforcement Learning from Human Feedback)를 모두 사용하여 모델이 바람직하지 않은 행동을 피하도록 유도합니다.

## 보증 평가

또한 IT(Instruction Tuned) 모델을 일련의 기본 보증 평가를 통해 실행하여 모델이 초래할 수 있는 잠재적 해악을 이해합니다. 오픈 모델을 지지하면서도, 가중치 공개의 비가역적 특성이 엄격한 위험 평가를 필요로 한다는 점을 인식하고 있습니다. 내부 안전성 프로세스는 이에 따라 설계되었으며, 이전 Gemma 모델에 대해서도 극단적 위험과 관련된 능력에 대한 평가를 수행했습니다([Shevlane 등](https://arxiv.org/pdf/2202.07646); [Phuong 등](https://arxiv.org/pdf/2202.07646)).

오픈 모델을 계속 개발하고 공유함에 따라, 더 능력 있는 모델을 철저히 평가하는 것이 덜 능력 있는 모델에 대한 충분한 보증을 제공한다는 휴리스틱을 따를 것입니다. 따라서 Gemma 3에 대해서는 간소화된 평가 세트를 우선시하고, 특정 모델이 잠재적으로 높은 위험을 제시할 수 있는 경우(아래에서 설명하는 CBRN 평가와 같은)에 대해서만 심층적인 위험 능력 평가를 예약했습니다. 개발 속도와 표적화된 안전성 테스트 사이의 균형을 맞추어, 평가가 잘 집중되고 효율적이면서도 프론티어 안전성 프레임워크에 명시된 약속을 유지하도록 합니다.

### 기본 평가

기본 보증은 다수의 합성 적대적 사용자 쿼리를 사용하여 안전성 정책에 대한 모델 위반율을 포착하고, 인간 평가자가 답변을 정책 위반 여부로 라벨링합니다. 전반적으로, Gemma 3의 위반율은 이러한 안전성 정책에서 전체적으로 상당히 낮습니다.

### 화학, 생물학, 방사선 및 핵(CBRN) 지식

STEM 관련 작업에서의 성능 향상으로 인해, 내부 데이터셋의 폐쇄형 지식 기반 객관식 질문을 사용하여 생물학적, 방사선 및 핵 위험과 관련된 지식을 평가했습니다. 화학 지식 평가의 경우, [Macknight 등](https://arxiv.org/pdf/2202.07646)이 개발한 화학적 위험에 대한 폐쇄형 지식 기반 접근법을 사용했습니다. 평가 결과, Gemma 3 모델의 이러한 영역에서의 지식은 낮은 것으로 나타났습니다.

## 책임 있는 오픈 모델에 대한 접근 방식

안전하고, 보안이 유지되며, 책임감 있는 애플리케이션을 설계하기 위해서는 시스템 수준의 접근 방식이 필요하며, 각 특정 사용 사례와 환경에 관련된 위험을 완화하기 위해 노력해야 합니다. 모델에서 발생할 수 있는 잠재적 위험에 비례하는 평가와 안전성 완화 조치를 계속 채택할 것이며, 예측 가능한 위험보다 이점이 크게 상회한다고 확신할 때만 이러한 모델을 커뮤니티와 공유할 것입니다.

## 안전성 평가 방법론의 기술적 세부사항

Gemma 3 모델의 안전성 평가에 사용된 방법론은 다양한 기술적 접근법을 포함합니다. 기본 보증 평가에서는 합성 적대적 사용자 쿼리를 사용하여 모델의 안전성 정책 준수 여부를 테스트합니다. 이러한 쿼리는 모델이 유해한 콘텐츠를 생성하도록 의도적으로 설계되었으며, 다양한 안전성 정책 영역(예: 혐오 발언, 개인 정보, 위험한 지시 등)을 포괄합니다.

평가 과정은 다음과 같은 단계로 구성됩니다.

1. 다양한 안전성 정책 영역에 걸쳐 적대적 쿼리 세트 생성
2. 모델에 이러한 쿼리 제공
3. 인간 평가자가 모델 응답을 정책 위반 여부로 분류
4. 각 정책 영역별 위반율 계산

위반율은 다음과 같이 수학적으로 표현될 수 있습니다.

\\[ \text{위반율} = \frac{\text{정책 위반으로 분류된 응답 수}}{\text{총 쿼리 수}} \\]

CBRN 지식 평가의 경우, 더 구조화된 접근법이 사용됩니다. 이는 폐쇄형 객관식 질문을 통해 모델의 특정 위험 영역에 대한 지식을 측정합니다. 이러한 평가는 모델이 잠재적으로 위험한 정보를 얼마나 보유하고 있는지 이해하는 데 중요합니다.

CBRN 평가 점수는 다음과 같이 계산될 수 있습니다.

\\[ \text{CBRN 지식 점수} = \frac{\text{올바르게 답변한 CBRN 관련 질문 수}}{\text{총 CBRN 관련 질문 수}} \\]

이러한 평가는 모델이 위험한 지식을 보유하고 있는지 여부뿐만 아니라, 그러한 지식을 어떻게 적용하는지도 평가합니다. 예를 들어, 모델이 특정 위험한 화학 물질에 대한 지식을 가지고 있더라도, 그러한 지식을 유해한 방식으로 적용하는 것을 거부하는지 여부를 테스트합니다.

## 안전성과 책임성의 균형

Gemma 3 모델의 개발에서 중요한 과제 중 하나는 모델의 유용성과 안전성 사이의 균형을 맞추는 것입니다. 모델이 너무 제한적이면 유용성이 감소할 수 있으며, 너무 자유롭게 응답하면 잠재적으로 유해한 콘텐츠를 생성할 위험이 있습니다.

이러한 균형을 맞추기 위해, Gemma 팀은 다단계 접근법을 채택했습니다.

1. **사전 학습 데이터 필터링**: 유해한 콘텐츠가 포함된 데이터를 제거하여 모델이 그러한 패턴을 학습할 가능성을 줄입니다.

2. **지도 미세 조정(SFT)**: 모델이 안전하고 유용한 응답을 생성하도록 지도합니다.

3. **인간 피드백을 통한 강화 학습(RLHF)**: 인간 평가자의 피드백을 기반으로 모델의 응답을 더욱 개선합니다.

4. **포괄적인 평가**: 다양한 안전성 벤치마크와 적대적 테스트를 통해 모델의 안전성을 지속적으로 평가합니다.

이러한 접근법은 모델이 유용한 기능을 유지하면서도 안전성 위험을 최소화하는 데 도움이 됩니다. 특히 멀티모달 기능이 추가됨에 따라, 이미지 관련 안전성 문제(예: 유해한 이미지 생성 지시, 이미지에서 개인 정보 추출 등)에 대한 추가적인 고려가 필요했습니다.

## 프론티어 안전성 프레임워크

Gemma 팀이 언급한 "프론티어 안전성 프레임워크"는 최첨단 AI 모델의 개발과 배포에 대한 구조화된 접근법을 제공합니다. 이 프레임워크는 다음과 같은 핵심 원칙을 포함합니다.

1. **위험에 비례한 평가**: 모델의 능력과 잠재적 위험에 비례하는 평가 수준 적용

2. **단계적 개발**: 더 작고 덜 능력 있는 모델에서 시작하여 점진적으로 확장

3. **지속적인 모니터링**: 모델 배포 후 사용 패턴과 잠재적 오용 사례 모니터링

4. **투명성**: 안전성 평가 결과와 완화 전략에 대한 투명한 커뮤니케이션

5. **커뮤니티 참여**: 학계, 산업계, 시민 사회와의 협력을 통한 안전성 접근법 개선

이 프레임워크는 특히 Gemma 3와 같은 멀티모달 모델에서 중요합니다. 이미지 처리 능력이 추가됨에 따라 새로운 유형의 위험이 발생할 수 있으며, 이러한 위험을 식별하고 완화하기 위한 체계적인 접근법이 필요합니다.

## 안전성 평가의 기술적 도전과제

멀티모달 모델의 안전성을 평가하는 데는 여러 기술적 도전과제가 있습니다.

1. **다양한 입력 모달리티**: 텍스트와 이미지의 조합은 평가해야 할 가능한 입력 공간을 크게 확장합니다.

2. **복잡한 상호작용**: 텍스트와 이미지 간의 상호작용은 단일 모달리티만 고려할 때는 나타나지 않는 새로운 안전성 문제를 야기할 수 있습니다.

3. **문화적 맥락**: 이미지의 해석은 문화적 맥락에 따라 크게 달라질 수 있으며, 이는 글로벌 사용자 기반을 위한 안전성 평가를 복잡하게 만듭니다.

4. **암묵적 편향**: 이미지는 텍스트보다 더 미묘하고 암묵적인 편향을 포함할 수 있으며, 이를 탐지하고 완화하는 것은 더 어려울 수 있습니다.

이러한 도전과제를 해결하기 위해, Gemma 팀은 다양한 문화적 맥락과 사용 사례를 고려한 포괄적인 평가 프레임워크를 개발했습니다. 또한 ShieldGemma 2와 같은 특수 안전성 모델을 개발하여 이미지 콘텐츠의 안전성을 평가하고 필터링하는 데 도움을 줍니다.

## 결론

Gemma 3 모델의 책임, 안전성, 보안에 대한 접근법은 포괄적이고 다층적입니다. 사전 학습 데이터 필터링부터 지도 미세 조정, RLHF, 그리고 철저한 평가에 이르기까지, 모델의 개발 주기 전반에 걸쳐 안전성 고려사항이 통합되어 있습니다.

멀티모달 기능의 도입은 새로운 안전성 도전과제를 가져왔지만, Gemma 팀은 이러한 도전과제를 해결하기 위한 강력한 프레임워크를 개발했습니다. 특히 ShieldGemma 2와 같은 특수 안전성 모델의 개발은 이미지 안전성을 위한 실용적인 솔루션을 제공합니다.

궁극적으로, Gemma 3의 안전성 접근법은 모델의 유용성을 유지하면서도 잠재적 위험을 최소화하는 것을 목표로 합니다. 지속적인 평가와 모니터링을 통해, Gemma 팀은 모델이 책임감 있게 사용되고 사회에 긍정적인 영향을 미칠 수 있도록 노력하고 있습니다.

# 8 논의 및 결론

본 연구에서는 텍스트, 이미지, 코드를 위한 오픈 언어 모델 제품군인 Gemma의 최신 버전인 Gemma 3를 소개했습니다. 이번 버전에서는 이미지 이해 능력과 긴 컨텍스트 처리 기능을 추가하는 동시에 다국어 지원과 STEM 관련 능력을 향상시키는 데 중점을 두었습니다. 모델의 크기와 아키텍처는 표준 하드웨어와 호환되도록 설계되었으며, 대부분의 아키텍처 개선 사항은 성능을 유지하면서도 이러한 하드웨어에 맞게 조정되었습니다.

Gemma 3는 이전 버전인 Gemma 2를 기반으로 하되, 여러 가지 중요한 개선 사항을 도입했습니다. 특히 멀티모달 기능의 추가는 모델이 텍스트뿐만 아니라 이미지도 처리할 수 있게 해주었습니다. 이를 위해 SigLIP 비전 인코더의 맞춤형 버전을 통합하여 이미지를 처리하고, 이를 언어 모델이 이해할 수 있는 토큰 시퀀스로 변환합니다. 또한 Pan & Scan 기법을 도입하여 다양한 해상도와 종횡비의 이미지를 효과적으로 처리할 수 있게 했습니다.

긴 컨텍스트 처리 능력은 로컬 어텐션과 글로벌 어텐션 레이어의 비율을 최적화하고, 로컬 어텐션의 윈도우 크기를 조정함으로써 크게 향상되었습니다. 이러한 접근 방식은 [Beltagy와 연구진](https://arxiv.org/pdf/2004.05150)이 제안한 로컬 슬라이딩 윈도우 어텐션과 [Luong과 연구진](https://arxiv.org/pdf/1508.04025)의 글로벌 어텐션 메커니즘을 결합한 것입니다. 이를 통해 KV 캐시 메모리 사용량을 크게 줄이면서도 128K 토큰까지의 컨텍스트를 효과적으로 처리할 수 있게 되었습니다.

모델 학습에 있어서는 [Hinton과 연구진](https://arxiv.org/pdf/1503.02531)이 제안한 지식 증류 기법을 적용하여 작은 모델이 더 큰 교사 모델의 지식을 효과적으로 학습할 수 있도록 했습니다. 이 과정에서 교사 모델의 확률 분포를 학생 모델이 모방하도록 학습시키는 방식을 사용했으며, 이는 수학적으로 다음과 같이 표현됩니다.

\\[ \min_{P_S} \sum_x -P_T(x|x_c) \log P_S(x|x_c) \\]

여기서 \\(P_T(x|x_c)\\)는 주어진 컨텍스트 \\(x_c\\)에서 다음 토큰 \\(x\\)에 대한 교사 모델의 확률 분포이고, \\(P_S(x|x_c)\\)는 학생 모델의 매개변수화된 확률입니다.

또한 후처리 학습 과정에서는 수학, 추론, 채팅, 명령어 따르기, 다국어 능력을 향상시키기 위한 새로운 접근 방식을 도입했습니다. 이를 통해 Gemma3-4B-IT는 Gemma2-27B-IT와 경쟁력 있는 성능을 보이며, Gemma3-27B-IT는 다양한 벤치마크에서 Gemini-1.5-Pro와 비슷한 수준의 성능을 달성했습니다.

평가 결과에 따르면, Gemma 3 모델은 LMSYS 챗봇 아레나에서 1338점의 Elo 점수를 기록하며 상위 10위 안에 들었습니다. 이는 DeepSeek-V3(1318점), LLaMA 3 405B(1257점), Qwen2.5-70B(1257점)와 같은 훨씬 더 큰 규모의 모델들보다 높은 점수입니다. 특히 Gemma 3의 Elo 점수는 이전 버전인 Gemma 2의 1220점보다 크게 향상되었습니다.

또한 MMLU-Pro, MATH, Global MMLU-Lite, LiveCodeBench와 같은 다양한 벤치마크에서도 Gemma 3 모델은 이전 버전들보다 크게 향상된 성능을 보여주었습니다. 특히 수학적 추론, 다국어 처리, 코드 생성, 질문 응답 등의 영역에서 상당한 개선이 이루어졌습니다.

기억률(memorization rate) 측정 결과, Gemma 3 모델은 이전 모델들보다 현저히 낮은 기억률을 보여주었으며, 특히 기억으로 분류된 출력에서 개인정보가 전혀 탐지되지 않았습니다. 이는 모델의 개인정보 보호 측면에서 중요한 진전을 나타냅니다.

안전성 측면에서는 Gemma 3 모델이 유해한 콘텐츠를 생성하는 것을 방지하기 위한 다양한 안전성 정책과 완화 조치가 적용되었습니다. 사전 학습 데이터에 대한 안전성 필터링, 지도 미세 조정(SFT), 인간 피드백을 통한 강화 학습(RLHF) 등의 방법을 통해 모델이 안전하고 유용한 응답을 생성하도록 유도했습니다.

결론적으로, Gemma 3는 경량 모델임에도 불구하고 멀티모달 처리, 긴 컨텍스트 이해, 다국어 지원 등 다양한 능력에서 뛰어난 성능을 보여주는 모델입니다. 특히 효율적인 아키텍처 설계와 학습 방법을 통해 더 큰 규모의 모델들과 경쟁할 수 있는 성능을 달성했으며, 이는 소비자급 하드웨어에서도 효과적으로 실행될 수 있는 강력한 AI 모델의 개발을 향한 중요한 진전을 나타냅니다.

이러한 성과는 로컬 어텐션과 글로벌 어텐션의 효과적인 조합, 지식 증류를 통한 효율적인 학습, 그리고 다양한 데이터 소스를 활용한 학습 과정의 결과입니다. Gemma 3는 이러한 기술적 혁신을 통해 경량 모델임에도 불구하고 다양한 작업에서 강력한 성능을 제공하며, 특히 멀티모달 처리, 긴 컨텍스트 이해, 다국어 지원 측면에서 이전 버전보다 크게 향상된 능력을 보여줍니다.

Google DeepMind는 이러한 모든 모델을 커뮤니티에 공개함으로써, AI 연구와 응용 분야의 발전에 기여하고 있습니다. 이는 오픈 모델의 중요성과 가치를 강조하며, 더 많은 연구자와 개발자들이 이러한 모델을 활용하여 다양한 응용 프로그램을 개발할 수 있는 기회를 제공합니다.

# 부록: 사전 학습 성능 세부 사항

### 사실성 및 상식 능력

표 9는 이전 버전과 비교하여 새로운 사전 학습 벤치마크의 성능을 보여줍니다. 여러 표준 벤치마크를 고려했는데, 이는 HellaSwag([Zellers와 연구진](https://arxiv.org/pdf/1905.07830)), BoolQ([Clark와 연구진](https://arxiv.org/pdf/1905.10044)), PIQA([Bisk와 연구진](https://arxiv.org/pdf/1911.11641)), SIQA([Sap와 연구진](https://arxiv.org/pdf/1904.09728)), TriviaQA([Joshi와 연구진](https://arxiv.org/pdf/1705.03551)), Natural Questions([Kwiatkowski와 연구진](https://arxiv.org/pdf/1901.08634)), ARC-C와 ARC-E([Chollet](https://arxiv.org/pdf/1911.01547)), WinoGrande([Sakaguchi와 연구진](https://arxiv.org/pdf/1907.10641)), BBH([Suzgun와 연구진](https://arxiv.org/pdf/2210.09261)), DROP([Dua와 연구진](https://arxiv.org/pdf/1903.00161))을 포함합니다. 평가 세부 사항은 표 19에 설명되어 있습니다.

| 모델 | Gemma 2 | Gemma 3 |
|------|---------|---------|
| 크기 | 2B | 9B | 27B | 1B | 4B | 12B | 27B |
| HellaS | 72.9 | 81.9 | 86.4 | 62.3 | 77.2 | 84.2 | 85.6 |
| BoolQ | 75.6 | 77.5 | 76.2 | 63.2 | 72.3 | 78.8 | 82.4 |
| PIQA | 78.1 | 81.9 | 83.5 | 73.8 | 79.6 | 81.8 | 83.3 |
| SIQA | 51.8 | 53.3 | 53.8 | 48.9 | 51.9 | 53.4 | 54.9 |
| TQA | 60.2 | 76.5 | 83.8 | 39.8 | 65.8 | 78.2 | 85.5 |
| NQ | 17.2 | 29.2 | 34.7 | 9.48 | 20.0 | 31.4 | 36.1 |
| ARC-C | 55.8 | 69.1 | 71.4 | 38.4 | 56.2 | 68.9 | 70.6 |
| ARC-E | 80.6 | 88.3 | 88.6 | 73.0 | 82.4 | 88.3 | 89.0 |
| WinoG | 65.4 | 73.9 | 79.4 | 58.2 | 64.7 | 74.3 | 78.8 |
| BBH | 42.4 | 69.4 | 74.8 | 28.4 | 50.9 | 72.6 | 77.7 |
| Drop | 53.2 | 71.5 | 75.2 | 42.4 | 60.1 | 72.2 | 77.2 |

표 9: 사전 학습 단계 이후의 사실성, 상식 성능 및 추론 능력

전반적으로, 이번 버전에서 중점을 두지 않은 능력임에도 불구하고 모델들이 Gemma 2와 비슷한 수준의 성능을 보여주는 것은 고무적입니다.

### STEM 및 코드 성능

표 10은 STEM 및 코드 관련 성능에 대한 세부 정보를 보여줍니다. 여러 표준 벤치마크를 고려했는데, 이는 MMLU([Hendrycks와 연구진](https://arxiv.org/pdf/2009.03300)), MMLU-Pro([Wang와 연구진](https://arxiv.org/pdf/2403.03864)), AGIEval([Zhong와 연구진](https://arxiv.org/pdf/2304.06364)), MATH([Hendrycks와 연구진](https://arxiv.org/pdf/2103.03874)), GSM8K([Cobbe와 연구진](https://arxiv.org/pdf/2110.14168)), GPQA([Rein와 연구진](https://arxiv.org/pdf/2311.12022)), MBPP([Austin와 연구진](https://arxiv.org/pdf/2108.07732)), HumanEval([Chen와 연구진](https://arxiv.org/pdf/2107.03374))을 포함합니다. 평가 세부 사항은 표 19에 설명되어 있습니다.

| 모델 | Gemma 2 | Gemma 3 |
|------|---------|---------|
| 크기 | 2B | 9B | 27B | 1B | 4B | 12B | 27B |
| MMLU | 52.2 | 71.2 | 75.2 | 59.6 | 74.5 | 78.6 |
| MMLUpro | 22.2 | 43.7 | 49.4 | 29.2 | 45.3 | 52.2 |
| AGIE | 31.6 | 53.1 | 55.1 | 42.1 | 57.4 | 66.2 |
| MATH | 16.4 | 36.4 | 42.1 | 24.2 | 43.3 | 50.0 |
| GSM8K | 25.0 | 70.2 | 74.6 | 38.4 | 71.0 | 82.6 |
| GPQA Diamond | 12.5 | 24.8 | 26.3 | 15.0 | 25.4 | 24.3 |
| MBPP | 31.0 | 51.2 | 60.8 | 46.0 | 60.4 | 65.6 |
| HumanE | 19.5 | 40.2 | 51.2 | 36.0 | 45.7 | 48.8 |

표 10: 사전 학습 단계 이후의 STEM 및 코드 성능

전반적으로 사전 학습된 모델들이 STEM 능력에서 일관된 향상을 보여주고 있습니다. 코드 관련 성능에서는 4B와 12B 모델에서 유사한 향상이 보이지만, 27B 모델에서는 그렇지 않습니다.

### 멀티모달 성능

표 11은 사전 학습 단계 이후 다양한 시각적 질문 응답 벤치마크에서의 성능을 보여줍니다. 이는 비전 인코더로 학습된 다양한 모델에 대한 결과입니다. 벤치마크로는 COCO Caption([Chen와 연구진](https://arxiv.org/pdf/1504.00325)), DocVQA([Mathew와 연구진](https://arxiv.org/pdf/2003.06770)), InfographicVQA([Mathew와 연구진](https://arxiv.org/pdf/2104.12756)), MMMU([Yue와 연구진](https://arxiv.org/pdf/2311.16502)), TextVQA([Singh와 연구진](https://arxiv.org/pdf/1904.08920)), RealWorldQA(Rea), ReMI([Kazemi와 연구진](https://arxiv.org/pdf/2401.08217)), AI2D([Kembhavi와 연구진](https://arxiv.org/pdf/1603.09382)), ChartQA([Masry와 연구진](https://arxiv.org/pdf/2203.10244)), VQA v2([Goyal와 연구진](https://arxiv.org/pdf/1612.00837)), BLINK([Fu와 연구진](https://arxiv.org/pdf/2401.08574)), OK-VQA([Marino와 연구진](https://arxiv.org/pdf/1906.00067)), TallyQA([Acharya와 연구진](https://arxiv.org/pdf/1810.12440)), SpatialSense VQA([Yang와 연구진](https://arxiv.org/pdf/1908.05660)), CountBench VQA([Paiss와 연구진](https://arxiv.org/pdf/2306.04391))가 포함됩니다. 평가 세부 사항은 표 20에 설명되어 있습니다.

| 모델 | 4B | 12B | 27B |
|------|-----|------|------|
| COCO caption | 102 | 111 | 116 |
| DocVQA | 72.8 | 82.3 | 85.6 |
| InfoVQA | 44.1 | 54.8 | 59.4 |
| MMMU | 39.2 | 50.3 | 56.1 |
| TextVQA | 58.9 | 66.5 | 68.6 |
| RealWorldQA | 45.5 | 52.2 | 53.9 |
| ReMI | 27.3 | 38.5 | 44.8 |
| AI2D | 63.2 | 75.2 | 79.0 |
| ChartQA | 63.6 | 74.7 | 76.3 |
| VQAv2 | 63.9 | 71.2 | 72.9 |
| BLINK | 38.0 | 35.9 | 39.6 |
| OK-VQA | 51.0 | 58.7 | 60.2 |
| TallyQA | 42.5 | 51.8 | 54.3 |
| SpatialSense VQA | 50.9 | 60.0 | 59.4 |
| CountBench VQA | 26.1 | 17.8 | 68.0 |

표 11: 사전 학습 단계 이후의 멀티모달 성능. 점수는 P&S(Pan & Scan)를 적용하지 않은 각 데이터셋의 검증 분할에 대한 것입니다.

### PaliGemma 2와의 비교

[Steiner와 연구진](https://arxiv.org/pdf/2412.03555)의 프로토콜을 따라 멀티모달 Gemma 3 사전 학습 체크포인트를 파인튜닝했습니다. 학습률만 조정했으며, 그 외에는 동일한 전이 설정을 사용했습니다. 표 12의 결과는 Gemma 3가 문서 이해와 관련된 벤치마크에서 뛰어난 성능을 보이며, 더 큰 PaliGemma 2 변형보다도 우수한 성능을 보여준다는 것을 보여줍니다. 주목할 점은 비전 인코더에서 평균 풀링을 사용하기 때문에 Gemma 3 4B와 12B 모델은 동일한 896 x 896 해상도에서 PaliGemma 2 9B 및 27B 모델에 비해 약 10배 더 저렴하게 전이 학습할 수 있다는 것입니다. Gemma 3는 AI2D와 OKVQA에서도 더 나은 성능을 보이지만, PaliGemma 2는 VQAv2와 COCO caption에서 약간 더 나은 성능을 보입니다.

| 모델 | PaliGemma 2 | Gemma 3 |
|------|-------------|---------|
| 크기 | 2B | 9B | 27B | 4B | 12B | 27B |
| DocVQA | 81.6 | 86.3 | 85.1 | 86.1 | 89.0 | 89.5 |
| InfoVQA | 41.4 | 53.1 | 50.2 | 55.6 | 61.6 | 64.6 |
| TextVQA | 76.3 | 76.3 | 75.1 | 79.1 | 81.6 | 83.2 |
| ChartQA | 70.7 | 79.1 | 71.3 | 79.8 | 83.5 | 83.4 |
| AI2D | 76.0 | 84.4 | 84.6 | 80.9 | 85.6 | 86.5 |
| OKVQA | 64.1 | 68.6 | 70.6 | 65.2 | 69.3 | 71.1 |
| CountBenchQA | 82.0 | 85.3 | 87.4 | 79.4 | 83.5 | 87.8 |
| COCO caption | 143.1 | 45.1 | 45.1 | 43.1 | 43.1 | 44.1 |
| VQAv2 | 84.8 | 85.8 | 85.8 | 84.1 | 84.9 | 85.1 |
| Tally QA | 80.6 | 82.4 | 82.1 | 79.0 | 81.3 | 81.7 |

표 12: P&S를 적용하지 않은 멀티모달 벤치마크에서 사전 학습된 체크포인트의 파인튜닝 후 성능. PaliGemma 2는 처음 네 개의 벤치마크에 대해 896x896 해상도로, 나머지는 448x448 해상도로 전이되었습니다.

### 다국어 성능

표 13에서는 사전 학습된 모델의 다국어 작업에 대한 성능을 보고합니다. 멀티샷 프롬프팅을 통한 인컨텍스트 학습을 적용하고 다음 벤치마크에 대한 결과를 제시합니다. MGSM([Shi와 연구진](https://arxiv.org/pdf/2110.14168)), Global-MMLU-Lite([Singh와 연구진](https://arxiv.org/pdf/2403.19472)), WMT24++([Deutsch와 연구진](https://arxiv.org/pdf/2501.04622)), FLoRes([Goyal와 연구진](https://arxiv.org/pdf/2204.03311)), XQuAD([Artetxe와 연구진](https://arxiv.org/pdf/1910.11856)), ECLeKTic([Goldman와 연구진](https://arxiv.org/pdf/2501.04434)), IndicGenBench([Singh와 연구진](https://arxiv.org/pdf/2402.03028)), XOR QA([Asai와 연구진](https://arxiv.org/pdf/2010.11856)). 평가 세부 사항은 표 19에 설명되어 있습니다.

| 모델 | Gemma 2 | Gemma 3 |
|------|---------|---------|
| 크기 | 2B | 9B | 27B | 1B | 4B | 12B | 27B |
| MGSM | 18.7 | 57.3 | 68.0 | 2.04 | 34.7 | 64.3 | 74.3 |
| GMMLU | 43.3 | 64.0 | 69.4 | 24.9 | 57.0 | 69.4 | 75.7 |
| WMT24++ | 38.8 | 50.3 | 53.0 | 36.7 | 48.4 | 53.9 | 55.7 |
| Flores | 30.2 | 41.3 | 44.3 | 29.5 | 39.2 | 46.0 | 48.8 |
| XQuAD | 53.7 | 72.2 | 73.9 | 43.9 | 68.0 | 74.5 | 76.8 |
| ECLeKTic | 8.29 | 14.0 | 17.1 | 4.69 | 11.0 | 17.2 | 24.4 |
| IndicGB | 47.4 | 59.3 | 62.1 | 41.4 | 57.2 | 61.7 | 63.4 |

표 13: 사전 학습 단계 이후의 다국어 성능. IndicGenBench는 표 14에 보고된 벤치마크의 평균입니다.

### 인도어 벤치마크 세부 성능

표 14는 사전 학습 단계 이후의 상세한 IndicGenBench 성능을 보여줍니다.

| 모델 | Gemma 2 | Gemma 3 |
|------|---------|---------|
| 크기 | 2B | 9B | 27B | 1B | 4B | 12B | 27B |
| XQuAD Indic | 54.3 | 73.1 | 74.9 | 43.1 | 68.3 | 75.2 | 77.8 |
| XORQA in-en | 66.2 | 69.3 | 72.5 | 56.3 | 68.3 | 69.8 | 70.4 |
| XORQA in-xx | 31.2 | 40.8 | 44.3 | 27.1 | 39.8 | 43.8 | 46.0 |
| Flores Indic | 38.1 | 54.0 | 56.9 | 39.0 | 52.3 | 58.0 | 59.5 |

표 14: 사전 학습 단계 이후의 상세한 IndicGenBench 성능.

### 긴 컨텍스트 성능

표 15에서는 32K 및 128K 시퀀스 길이에서 평가한 RULER([Hsieh와 연구진](https://arxiv.org/pdf/2404.06654)) 및 MRCR([Vodrahalli와 연구진](https://arxiv.org/pdf/2409.12640)) 벤치마크를 포함하여 긴 컨텍스트 벤치마크에서의 사전 학습된(PT) 모델과 명령어 튜닝된(IT) 모델의 성능을 보고합니다.

| 컨텍스트 | Gemma 3 PT | Gemma 3 IT |
|---------|------------|------------|
| 모델 | 4B | 12B | 27B | 4B | 12B | 27B |
| RULER32K | 67.1 | 90.6 | 85.9 | 61.4 | 80.3 | 91.1 |
| RULER128K | 51.7 | 80.7 | 72.9 | 46.8 | 57.1 | 66.0 |
| MRCR32K | 44.7 | 59.8 | 63.2 | 49.8 | 53.7 | 63.2 |
| MRCR128K | 40.6 | 56.9 | 60.0 | 44.6 | 49.8 | 59.3 |

표 15: 다양한 컨텍스트 길이에서의 긴 컨텍스트 벤치마크에 대한 사전 학습된(PT) 및 명령어 튜닝된(IT) 모델의 성능.

## 8.1 IT 모델의 성능

표 16은 멀티모달 벤치마크에서의 명령어 튜닝된(IT) 모델의 성능을 보여줍니다. 별도로 언급되지 않은 경우, 이 결과는 P&S가 적용된 각 데이터셋의 최종 테스트 세트에 대한 것입니다.

| 모델 | 4B | 12B | 27B |
|------|-----|------|------|
| MMMU (val) | 48.8 | 59.6 | 64.9 |
| DocVQA | 75.8 | 87.1 | 86.6 |
| InfoVQA | 50.0 | 64.9 | 70.6 |
| TextVQA | 57.8 | 67.7 | 65.1 |
| AI2D | 74.8 | 84.2 | 84.5 |
| ChartQA | 68.8 | 75.7 | 78.0 |
| VQAv2 (val) | 62.4 | 71.6 | 71.0 |
| MathVista (testmini) | 50.0 | 62.9 | 67.6 |

표 16: 멀티모달 벤치마크에서의 명령어 튜닝된(IT) 모델의 성능.

표 18에서는 IT 모델에 대한 추가 벤치마크를 보고합니다. N2C는 Gemini 1.0 내부 보류 데이터셋인 Natural2Code를 의미하며, 웹 기반 정보 대신 저자가 생성한 소스를 사용합니다. BBEH는 BIG-Bench Extra Hard([Kazemi와 연구진](https://arxiv.org/pdf/2501.04434))를 의미하며, 이는 여러 추론 작업을 집계하는 도전적인 LLM 추론 벤치마크입니다([Kazemi와 연구진](https://arxiv.org/pdf/2401.08217); [Nie와 연구진](https://arxiv.org/pdf/2402.18179); [Kıcıman와 연구진](https://arxiv.org/pdf/2305.20050); [Tyen와 연구진](https://arxiv.org/pdf/2310.12397); [Kazemi와 연구진](https://arxiv.org/pdf/2305.20050); [Sánchez와 연구진](https://arxiv.org/pdf/2402.18179); [Hessel와 연구진](https://arxiv.org/pdf/2212.10559); [Zhang와 연구진](https://arxiv.org/pdf/2402.18179); [Yamada와 연구진](https://arxiv.org/pdf/2305.20050); [Fatemi와 연구진](https://arxiv.org/pdf/2402.18179); [White와 연구진](https://arxiv.org/pdf/2402.18179); [Shah와 연구진](https://arxiv.org/pdf/2402.18179)). ECLeKTic은 [Goldman와 연구진](https://arxiv.org/pdf/2501.04434)을 참조합니다. 마이크로 평균 점수를 보고합니다. 더 많은 평가 세부 사항은 표 21에 설명되어 있습니다.

## 8.2 비디오 이해에 대한 IT 모델의 성능

표 17은 16개의 프레임 선형 공간을 사용한 0샷 방식으로 비전 이해 벤치마크에서의 명령어 튜닝된(IT) 모델의 성능을 보여줍니다. Perception Test는 지각적으로 흥미로운 상황을 보여주는 실제 비디오로 구성되어 있으며, 다중 선택 비디오 QA 벤치마크에서의 결과를 상위 1 정확도 측면에서 보고합니다. ActivityNet-QA는 표준 gpt-평가를 보고합니다.

| 모델 | 4B | 12B | 27B |
|------|-----|------|------|
| Perception Test MCVQA | 50.6 | 54.9 | 58.1 |
| ActivityNet-QA | 46.3 | 50.4 | 52.8 |

표 17: 비전 이해 벤치마크에서의 명령어 튜닝된(IT) 모델의 성능.

다음 표는 다양한 크기의 명령어 튜닝된(IT) 모델의 더 많은 내부 및 외부 벤치마크에서의 성능을 보여줍니다.

| 모델 | Gemma 2 | Gemma 3 |
|------|---------|---------|
| 크기 | 2B | 9B | 27B | 1B | 4B | 12B | 27B |
| MMLU | 56.1 | 71.3 | 76.2 | 38.8 | 58.1 | 71.9 | 76.9 |
| MBPP | 36.6 | 59.2 | 67.4 | 35.2 | 63.2 | 73.0 | 74.4 |
| HumanEval | 20.1 | 40.2 | 51.8 | 41.5 | 71.3 | 85.4 | 87.8 |
| N2C | 46.8 | 68.3 | 77.3 | 56.0 | 70.3 | 80.7 | 84.5 |
| LiveCodeBench | 7.0 | 20.0 | 29.0 | 5.0 | 23.0 | 32.0 | 39.0 |
| GSM8K | 62.6 | 88.1 | 91.1 | 62.8 | 89.2 | 94.4 | 95.9 |
| MATH | 27.2 | 49.4 | 55.6 | 48.0 | 75.6 | 83.8 | 89.0 |
| HiddenMath | 2.0 | 8.0 | 12.0 | 15.0 | 42.0 | 51.0 | 56.0 |
| BBH | 41.4 | 69.0 | 74.9 | 39.1 | 72.2 | 85.7 | 87.6 |
| BBEH | 5.9 | 9.8 | 14.8 | 7.2 | 11.0 | 16.3 | 19.3 |
| IFEval | 80.4 | 88.4 | 91.1 | 80.2 | 90.2 | 88.9 | 90.4 |
| GMMLU-Lite | 41.9 | 64.8 | 68.6 | 34.2 | 54.5 | 69.5 | 75.1 |
| ECLeKTic | 5.3 | 11.8 | 17.6 | 1.4 | 4.6 | 10.3 | 16.7 |
| WMT24++ | 37.4 | 48.7 | 51.7 | 35.9 | 46.8 | 51.6 | 53.4 |

표 18: 다양한 크기의 명령어 튜닝된(IT) 모델의 더 많은 내부 및 외부 벤치마크에서의 성능.

### 추가 멀티모달 평가

Gemma 3 IT 모델은 Gemini 1.5([Gemini Team, 2024](https://arxiv.org/pdf/2403.05530))의 평가 프로토콜을 따라 일반적인 비전 벤치마크에서 평가되었습니다. 결과는 P&S가 활성화된 경우 표 16에 제시되어 있습니다.

다음 표는 텍스트 벤치마크에 대한 세부 사항을 보여줍니다. Char-Len은 문자 길이 정규화를 의미하고 COT는 체인 오브 소트 프롬프팅을 의미합니다.

| 평가 | 메트릭 | 유형 | n-shot | COT | 정규화 |
|------|-------|------|--------|-----|-------|
| MBPP | pass@1 | 샘플링 | 3-shot | | |
| HumanEval | pass@1 | 샘플링 | 0-shot | | |
| HellaSwag | 정확도 | 점수 | 10-shot | | Char-Len |
| BoolQ | 정확도 | 점수 | 0-shot | | Char-Len |
| PIQA | 정확도 | 점수 | 0-shot | | Char-Len |
| SIQA | 정확도 | 점수 | 0-shot | | Char-Len |
| TriviaQA | 정확도 | 샘플링 | 5-shot | | |
| Natural Questions | 정확도 | 샘플링 | 5-shot | | |
| ARC-C | 정확도 | 점수 | 25-shot | | Char-Len |
| ARC-E | 정확도 | 점수 | 0-shot | | Char-Len |
| WinoGrande | 정확도 | 점수 | 5-shot | | Char-Len |
| BBH | 정확도 | 샘플링 | few-shot | 예 | |
| DROP | 토큰 F1 점수 | 샘플링 | 1-shot | | |
| AGIEval | 정확도 | 샘플링 | 3-5-shot | | |
| MMLU | 정확도 | 점수 | 5-shot | | Char-Len |
| MATH | 정확도 | 샘플링 | 4-shot | 예 | |
| GSM8K | 정확도 | 샘플링 | 8-shot | 예 | |
| GPQA Diamond | 정확도 | 샘플링 | 5-shot | 예 | |
| MMLU-Pro | 정확도 | 샘플링 | 5-shot | 예 | |
| MGSM | 정확도 | 샘플링 | 8-shot | | |
| FLoRes | CHaRacter-level F-score | 샘플링 | 1-shot | | |
| Global-MMLU-Lite | 정확도 | 점수 | 5-shot | | Char-Len |
| XQuAD | CHaRacter-level F-score | 샘플링 | 5-shot | | |
| WMT24++ | CHaRacter-level F-score | 샘플링 | 5-shot | | |
| ECLeKTic | ECLeKTic 점수 | 샘플링 | 2-shot | | First-line/strip |
| XQuAD Indic | CHaRacter-level F-score | 샘플링 | 5-shot | | |
| XOR QA IN-EN | CHaRacter-level F-score | 샘플링 | 5-shot | | |
| XOR QA IN-XX | CHaRacter-level F-score | 샘플링 | 5-shot | | |
| FLoRes Indic | CHaRacter-level F-score | 샘플링 | 5-shot | | |
| RULER | 정확도 | 샘플링 | 0-shot | | |
| MRCR | MRCR 점수 | 샘플링 | few-shot | | |

표 19: 텍스트 벤치마크에 대한 세부 사항. Char-Len은 문자 길이 정규화를 의미하고 COT는 체인 오브 소트 프롬프팅을 의미합니다.

다음 표는 비전 벤치마크에 대한 세부 사항을 보여줍니다. 체인 오브 소트 프롬프팅이나 정규화는 사용되지 않았습니다.

| 평가 | 메트릭 | 유형 | n-shot |
|------|-------|------|--------|
| COCO Caption | Cider 점수 | 샘플링 | 4-shot |
| DocVQA | ANLS 점수 | 샘플링 | 4-shot |
| InfographicVQA | ANLS 점수 | 샘플링 | 4-shot |
| MMMU | 정확도 | 샘플링 | 3-shot 텍스트만 |
| TextVQA | 정확도 | 샘플링 | 4-shot |
| RealWorldQA | 정확도 | 샘플링 | 4-shot 텍스트만 |
| ReMI | 정확도 | 샘플링 | 4-shot |
| AI2D | 정확도 | 샘플링 | 4-shot |
| ChartQA | 정확도 | 샘플링 | 4-shot |
| VQA v2 | 정확도 | 샘플링 | 4-shot |
| BLINK | 정확도 | 샘플링 | 0-shot |
| OK-VQA | 정확도 | 샘플링 | 4-shot |
| TallyQA | 정확도 | 샘플링 | 4-shot |
| SpatialSense VQA | 정확도 | 샘플링 | 4-shot |
| CountBench VQA | 정확도 | 샘플링 | 0-shot |

표 20: 비전 벤치마크에 대한 세부 사항. 체인 오브 소트 프롬프팅이나 정규화는 사용되지 않았습니다.

다음 표는 명령어 튜닝된(IT) 벤치마크에 대한 세부 사항을 보여줍니다. 정규화는 사용되지 않았습니다.

| 평가 | 메트릭 | 유형 | n-shot | COT |
|------|-------|------|--------|-----|
| MMLU | 정확도 | 샘플링 | 0-shot | |
| MBPP | pass@1 | 샘플링 | 3-shot | |
| HumanEval | pass@1 | 샘플링 | 0-shot | |
| N2C | pass@1 | 샘플링 | 0-shot | |
| LiveCodeBench | 8개 샘플의 평균 | 샘플링 | 0-shot | 예 |
| GSM8K | 정확도 | 샘플링 | 0-shot | 예 |
| GPQA Diamond | 정확도 | 샘플링 | 0-shot | 예 |
| MATH | 정확도 | 샘플링 | 0-shot | |
| HiddenMath | 정확도 | 샘플링 | 0-shot | |
| BBH | 정확도 | 샘플링 | 0-shot | |
| BBEH | 정확도 | 샘플링 | 0-shot | |
| IFEval | 정확도 | 샘플링 | 0-shot | |
| Global-MMLU-lite | 정확도 | 샘플링 | 0-shot | 예 |
| ECLeKTic | ECLeKTic 점수 | 샘플링 | 0-shot | |
| WMT24++ | CHaRacter-level F-score | 샘플링 | 0-shot | |

표 21: 명령어 튜닝된(IT) 벤치마크에 대한 세부 사항. 정규화는 사용되지 않았습니다.

2025년 3월 25일 15:30:29에 LaTeXML에 의해 생성됨

![Mascot Sammy](https://arxiv.org/html/2503.19786/x3.png)

- - -
### References
* [Gemma 3 Technical Report](http://arxiv.org/pdf/2503.19786v1)