---
layout: post
title: "DeepSeek LLM: Scaling Open-Source Language Models with Longtermism"
date: 2024-01-05 18:59:13
author: "DeepSeek-AI"
categories: "Language-Models"
tags: ["Scaling-Laws-for-Large-Language-Models", "Optimal-Model/Data-Scaling-Up-Allocation", "Multi-Step-Learning-Rate-Scheduler", "Grouped-Query-Attention", "Reinforcement-Learning-with-Human-Feedback", "Direct-Preference-Optimization", "Responsible-AI-Evaluation"]
use_math: true
cover: /assets/images/language-models.webp
---
### TL;DR
#### 이 연구를 시작하게 된 배경과 동기는 무엇입니까?
오픈소스 대규모 언어 모델(LLMs)의 발전이 가속화되고 있지만, 기존 연구에서 제시된 스케일링 법칙들이 서로 상충되는 결론을 보여주어 LLM의 확장 방향에 대한 불확실성이 존재했습니다. 특히 오픈소스 커뮤니티가 주로 고정된 크기(7B, 13B, 34B, 70B)의 모델 학습에만 집중하면서, LLM 스케일링 법칙에 대한 체계적인 연구가 부족했습니다. 이는 AGI 개발의 초기 단계에서 매우 중요한 연구 과제였으며, 특히 컴퓨팅 예산 증가에 따른 모델과 데이터의 최적 스케일링 방식에 대한 명확한 이해가 필요했습니다.

#### 이 연구에서 제시하는 새로운 해결 방법은 무엇입니까?
DeepSeek LLM 프로젝트는 장기적 관점에서 오픈소스 언어 모델을 발전시키기 위한 포괄적인 접근 방식을 제시합니다. 주요 혁신점으로는 1) 2조 개의 토큰으로 구성된 고품질 다국어 데이터셋 구축, 2) 데이터셋별 스케일링 법칙의 차이를 고려한 최적화된 학습 전략 수립, 3) 7B와 67B 파라미터 모델에서의 하이퍼파라미터 스케일링 법칙 연구, 4) 다단계 학습률 스케줄러 도입을 통한 학습 효율성 개선이 있습니다.

#### 제안된 방법은 어떻게 구현되었습니까?
구현은 크게 세 단계로 이루어졌습니다. 첫째, 데이터 처리 단계에서는 중복제거, 필터링, 리믹싱을 통해 데이터셋의 품질을 향상시켰습니다. 둘째, 모델 아키텍처에서는 LLaMA의 기본 구조를 따르되 코사인 학습률 스케줄러를 다단계 학습률 스케줄러로 대체했으며, 67B 모델에서는 Grouped-Query Attention을 도입했습니다. 셋째, 모델 정렬 단계에서는 지도 학습 파인튜닝(SFT)과 직접 선호도 최적화(DPO)를 순차적으로 적용했으며, 특히 안전성 보장을 위해 전문가 팀이 구성한 2,400개의 안전성 테스트셋을 활용했습니다.

#### 이 연구의 결과가 가지는 의미는 무엇입니까?
이 연구의 결과는 오픈소스 LLM 개발에 있어 몇 가지 중요한 시사점을 제공합니다. 첫째, DeepSeek LLM 67B가 코드, 수학, 추론 영역에서 LLaMA-2 70B를 능가하고 GPT-3.5보다 우수한 성능을 보여준 것은 제안된 스케일링 접근방식의 유효성을 입증합니다. 둘째, 데이터셋의 품질이 스케일링 법칙에 미치는 영향을 밝힘으로써, 향후 LLM 개발에서 데이터 품질의 중요성을 강조했습니다. 셋째, 다국어 모델의 효과적인 학습 방법을 제시함으로써, 언어 간 지식 전이와 다국어 LLM 개발의 새로운 가능성을 보여주었습니다.
- - -
## DeepSeek LLM: 장기적 관점의 오픈소스 언어 모델 확장

### 서론

오픈소스 대규모 언어 모델(Large Language Models, LLMs)의 발전은 놀라운 속도로 이루어지고 있습니다. 그러나 기존 연구에서 제시된 스케일링 법칙들은 서로 다른 결론을 보여주며, 이는 LLM의 확장에 대한 불확실성을 야기합니다. DeepSeek LLM 프로젝트는 이러한 스케일링 법칙을 심도 있게 연구하고, 7B와 67B 파라미터라는 두 가지 널리 사용되는 오픈소스 모델 구성에서의 독특한 발견을 제시합니다.

스케일링 법칙에 기반하여, 저자들은 장기적 관점에서 오픈소스 언어 모델을 발전시키기 위한 DeepSeek LLM 프로젝트를 소개합니다. 사전 학습을 위해 현재 2조 개의 토큰으로 구성되어 있으며 지속적으로 확장되고 있는 데이터셋을 구축했습니다. DeepSeek LLM Base 모델에 지도 학습 파인튜닝(Supervised Fine-tuning, SFT)과 직접 선호도 최적화(Direct Preference Optimization, DPO)를 적용하여 DeepSeek Chat 모델을 개발했습니다.

평가 결과는 DeepSeek LLM 67B가 코드, 수학, 추론 영역에서 특히 우수한 성능을 보이며 LLaMA-2 70B를 다양한 벤치마크에서 능가함을 보여줍니다. 더불어 개방형 평가에서 DeepSeek LLM 67B Chat은 GPT-3.5보다 우수한 성능을 보여주었습니다. 이러한 결과는 Kaplan과 연구진이 제시한 스케일링 법칙과 Hoffmann과 연구진이 발견한 컴퓨팅 최적 스케일링 원칙을 실제 대규모 언어 모델 개발에 성공적으로 적용할 수 있음을 입증합니다.

### 대규모 언어 모델의 발전과 현황

최근 몇 년간 디코더 전용 트랜스포머 기반의 대규모 언어 모델(Large Language Models, LLMs)은 인공일반지능(Artificial General Intelligence, AGI) 달성을 위한 핵심 기술로 자리잡았습니다. 이러한 모델들은 연속적인 텍스트에서 다음 단어를 예측하는 방식으로 대규모 데이터셋에서 자기지도 학습을 수행하며, 이를 통해 창작, 텍스트 요약, 코드 완성 등 다양한 능력을 갖추게 되었습니다.

지도 학습 파인튜닝과 보상 모델링의 발전으로 LLM은 사용자의 의도와 지시를 더 잘 따르게 되었고, 이는 모델의 대화 능력을 크게 향상시켰습니다. ChatGPT, Claude, Bard와 같은 상용 제품들은 막대한 컴퓨팅 자원과 주석 비용을 투자하여 개발되었으며, 이는 오픈소스 LLM에 대한 커뮤니티의 기대치를 크게 높였습니다.

이러한 흐름 속에서 LLaMA 시리즈 모델은 특히 주목할 만한 성과를 보여주었습니다. LLaMA는 효율적이고 안정적인 아키텍처를 구축하여 7B에서 70B 파라미터에 이르는 우수한 성능의 모델을 개발했으며, 이는 오픈소스 모델들의 아키텍처와 성능의 기준이 되었습니다.

그러나 오픈소스 커뮤니티는 주로 고정된 크기(7B, 13B, 34B, 70B)의 고품질 모델 학습에 집중하면서, LLM 스케일링 법칙에 대한 연구는 상대적으로 소홀히 했습니다. 스케일링 법칙 연구는 현재의 오픈소스 모델들이 AGI 개발의 초기 단계에 있다는 점을 고려할 때 매우 중요합니다. 특히 초기 연구들은 컴퓨팅 예산 증가에 따른 모델과 데이터의 스케일링에 대해 서로 다른 결론을 도출했으며, 하이퍼파라미터에 대한 논의도 충분하지 않았습니다.

본 논문에서는 언어 모델의 스케일링 동작을 광범위하게 조사하고, 이를 7B와 67B라는 두 가지 널리 사용되는 대규모 모델 구성에 적용했습니다. 이 연구는 오픈소스 LLM의 향후 스케일링을 위한 기반을 마련하는 것을 목표로 합니다. 특히 배치 크기와 학습률의 스케일링 법칙을 조사하여 모델 크기에 따른 경향을 발견했으며, 이를 바탕으로 데이터와 모델 규모의 스케일링 법칙에 대한 포괄적인 연구를 수행했습니다.
### 스케일링 법칙과 데이터셋의 영향

연구 과정에서 저자들은 서로 다른 데이터셋에서 도출된 스케일링 법칙이 상당한 차이를 보인다는 중요한 발견을 했습니다. 이는 스케일링 법칙을 데이터셋 간에 일반화할 때 신중한 접근이 필요함을 시사합니다. 이러한 통찰을 바탕으로, 저자들은 사전 학습을 위해 중국어와 영어를 중심으로 2조 개의 토큰을 수집했습니다.

모델 아키텍처 측면에서는 LLaMA의 기본 구조를 따르되, 코사인 학습률 스케줄러를 다단계 학습률 스케줄러로 대체했습니다. 이러한 변경은 모델의 성능을 유지하면서도 지속적인 학습을 용이하게 만들었습니다. 또한 다양한 출처에서 100만 개 이상의 지도 학습 파인튜닝 데이터를 수집하여 모델의 성능을 향상시켰습니다.

저자들은 기본 모델과 채팅 모델에 대해 광범위한 평가를 수행했습니다. 평가 결과는 DeepSeek LLM이 코드, 수학, 추론 분야에서 특히 우수한 성능을 보이며 LLaMA-2 70B를 다양한 벤치마크에서 능가함을 보여줍니다. 지도 학습 파인튜닝과 직접 선호도 최적화를 거친 DeepSeek 67B 채팅 모델은 중국어와 영어 모두에서 GPT-3.5를 능가하는 성능을 보여주었습니다. 이는 DeepSeek 67B가 두 언어 모두에서 고품질 응답을 생성하고 의미 있는 대화를 수행하는 능력이 우수함을 입증합니다. 안전성 평가에서도 DeepSeek 67B 채팅 모델은 실제 사용에서 해가 없는 응답을 제공할 수 있음을 보여주었습니다.

이러한 연구 결과는 향후 오픈소스 대규모 언어 모델의 발전 방향을 제시하며, 특히 스케일링 법칙과 데이터셋 선택의 중요성을 강조합니다. 저자들의 발견은 AGI 개발을 위한 오픈소스 LLM의 지속적인 발전에 중요한 통찰을 제공합니다.

### 데이터셋 구축 방법론

DeepSeek LLM 프로젝트에서는 데이터셋의 풍부성과 다양성을 포괄적으로 향상시키는 것을 주요 목표로 삼았습니다. 이를 위해 데이터 처리 과정을 중복제거(deduplication), 필터링(filtering), 리믹싱(remixing)이라는 세 가지 핵심 단계로 구성했습니다.

중복제거 단계에서는 적극적인 전략을 채택했습니다. Common Crawl 전체 코퍼스에 대한 중복제거를 수행한 결과, 단일 덤프 내에서의 중복제거보다 훨씬 더 효과적인 결과를 얻을 수 있었습니다. 실제로 91개의 덤프에 걸친 중복제거는 단일 덤프 방식에 비해 4배 더 많은 문서를 제거할 수 있었습니다. 덤프 수가 증가함에 따라 중복제거율도 지속적으로 상승하여, 1개 덤프에서 22.2%였던 중복제거율이 191개 덤프에서는 89.8%까지 증가했습니다.

필터링 단계에서는 문서 품질 평가를 위한 강건한 기준을 개발했습니다. 언어적 평가와 의미론적 평가를 모두 포함하는 다면적 분석을 통해 개별 문서 수준과 전체 데이터셋 수준에서 품질을 평가했습니다. 이러한 종합적인 접근 방식은 데이터셋의 정보 밀도를 효과적으로 향상시켰습니다.

리믹싱 단계에서는 데이터 불균형 문제를 해결하기 위해 접근 방식을 조정했습니다. 특히 과소대표된 도메인의 비중을 증가시키는 데 중점을 두어, 데이터셋이 더욱 균형 잡히고 포용적인 특성을 갖도록 했습니다.

토크나이저 구현에 있어서는 Huggingface Team이 개발한 tokenizers 라이브러리를 기반으로 바이트 수준 바이트-페어 인코딩(BBPE) 알고리즘을 채택했습니다. GPT-2의 접근 방식을 따라 개행문자, 문장부호, 한중일(CJK) 기호와 같은 서로 다른 문자 범주 간의 토큰 병합을 방지하기 위해 사전 토크나이징을 적용했습니다. 또한 LLaMA 모델들의 방식을 따라 숫자를 개별 자릿수로 분할했습니다.

일반 토큰의 어휘 크기는 100,000개로 설정했으며, 약 24GB 규모의 다국어 코퍼스로 토크나이저를 학습했습니다. 여기에 15개의 특수 토큰을 추가하여 최종 어휘 크기는 100,015개가 되었습니다. 학습 시 계산 효율성을 고려하고 향후 추가될 수 있는 특수 토큰을 위한 여유 공간을 확보하기 위해 모델의 어휘 크기를 102,400으로 설정했습니다.

### DeepSeek LLM의 마이크로 아키텍처 설계

DeepSeek LLM의 마이크로 아키텍처는 LLaMA 모델의 설계 원칙을 기반으로 하되, 몇 가지 중요한 최적화를 도입했습니다. 기본적으로 Pre-Norm 구조를 채택하여 RMSNorm 정규화 함수를 사용합니다. RMSNorm은 기존의 Layer Normalization과 달리 평균 중심화 작업을 제거하고 제곱평균 통계량만을 사용하여 계산 효율성을 높였습니다.

피드 포워드 네트워크(FFN)에서는 SwiGLU 활성화 함수를 채택했습니다. SwiGLU는 기존의 ReLU나 GELU보다 더 나은 성능을 제공하며, 중간 레이어의 차원을 \\( \frac{8}{3}d_{model} \\)로 설정했습니다. 여기서 \\(d_{model}\\)은 모델의 은닉 차원을 나타냅니다. 위치 정보 인코딩을 위해서는 Rotary Embedding을 사용했는데, 이는 상대적 위치 정보를 효과적으로 처리할 수 있게 해줍니다.

67B 모델의 경우, 추론 비용을 최적화하기 위해 전통적인 Multi-Head Attention(MHA) 대신 Grouped-Query Attention(GQA)을 도입했습니다. GQA는 쿼리 헤드들을 그룹으로 나누고 각 그룹이 키와 값 프로젝션을 공유하도록 함으로써, MHA의 품질을 유지하면서도 MQA(Multi-Query Attention)에 근접한 속도를 달성할 수 있게 합니다.

DeepSeek LLM의 거시적 설계에서는 기존 모델들과 차별화된 접근을 보여줍니다. 7B 모델은 30개의 레이어로 구성되어 있으며, 67B 모델은 95개의 레이어를 가집니다. 이러한 레이어 구성은 다른 오픈소스 모델들과의 파라미터 일관성을 유지하면서도 모델 파이프라인 분할을 최적화할 수 있게 해줍니다. 특히 주목할 만한 점은, 대부분의 GQA 사용 사례에서 FFN 레이어의 중간 너비를 확장하는 일반적인 방식과 달리, 67B 모델에서는 네트워크 깊이를 확장하는 전략을 채택했다는 것입니다. 이는 더 나은 성능을 달성하기 위한 전략적 선택이었습니다.

### DeepSeek LLM의 학습 구성과 최적화

DeepSeek LLM은 표준편차 0.006으로 초기화되었으며, AdamW 옵티마이저를 사용하여 학습되었습니다. 주요 하이퍼파라미터로는 \\(\beta_1=0.9\\), \\(\beta_2=0.95\\), 그리고 \\(\text{weight\_decay}=0.1\\)이 설정되었습니다.

사전 학습 과정에서는 일반적인 코사인 스케줄러 대신 다단계 학습률 스케줄러를 채택했습니다. 구체적으로, 모델의 학습률은 2000번의 웜업 스텝 후 최대값에 도달하고, 전체 학습 토큰의 80%를 처리한 후에는 최대값의 31.6%로 감소하며, 90%를 처리한 후에는 최대값의 10%로 더욱 감소합니다. 학습 단계에서의 그래디언트 클리핑은 1.0으로 설정되었습니다.

![학습률 스케줄러 비교](https://ar5iv.org//html/2401.02954/assets/figures/loss_step_cosine.png)

위 그래프는 다단계 학습률 스케줄러와 코사인 스케줄러의 성능을 비교한 것입니다. 실험 결과에 따르면, 학습 중 손실 감소 추세에는 차이가 있지만 최종 성능은 두 스케줄러가 본질적으로 동일한 수준을 보여줍니다. 다단계 학습률 스케줄러를 선택한 주요 이유는 학습 규모를 조정할 때 첫 번째 단계의 학습을 재사용할 수 있다는 독특한 이점 때문입니다.

![다단계 비율 비교](https://ar5iv.org//html/2401.02954/assets/figures/loss_diff_step.png)

위 그래프는 다단계 학습률 스케줄러의 각 단계 비율을 조정했을 때의 영향을 보여줍니다. 실험 결과, 단계별 비율을 조정하면 약간 더 나은 성능을 얻을 수 있음을 확인했습니다. 그러나 지속적 학습에서의 재사용 비율과 모델 성능 사이의 균형을 고려하여, 최종적으로 세 단계의 비율을 80%, 10%, 10%로 설정했습니다.

### 인프라스트럭처 구성

DeepSeek LLM의 학습과 평가를 위해 HAI-LLM이라는 경량화된 효율적인 학습 프레임워크를 사용했습니다. 이 프레임워크는 Megatron에서 구현된 것과 같이 데이터 병렬화, 텐서 병렬화, 시퀀스 병렬화, 그리고 1F1B 파이프라인 병렬화를 통합했습니다. 하드웨어 활용도를 높이기 위해 플래시 어텐션 기법을 적용했으며, ZeRO-1을 활용하여 데이터 병렬 랭크에 걸쳐 옵티마이저 상태를 분할했습니다.

추가적인 대기 오버헤드를 최소화하기 위해 계산과 통신을 중첩시키는 노력도 기울였습니다. 여기에는 마지막 마이크로 배치의 역전파 과정과 ZeRO-1의 reduce-scatter 연산, 그리고 시퀀스 병렬에서의 GEMM 계산과 all-gather/reduce-scatter가 포함됩니다. 학습 속도를 높이기 위해 LayerNorm, 가능한 경우의 GEMM, 그리고 Adam 업데이트와 같은 일부 레이어와 연산자들을 융합했습니다.

모델 학습의 안정성을 높이기 위해 bf16 정밀도로 학습을 진행하되, 그래디언트는 fp32 정밀도로 누적했습니다. 메모리 사용량을 줄이기 위해 in-place 교차 엔트로피를 수행했는데, 이는 교차 엔트로피 CUDA 커널에서 bf16 로짓을 fp32 정밀도로 즉시 변환하고 해당하는 bf16 그래디언트를 계산한 후 로짓을 그래디언트로 덮어쓰는 방식입니다.

모델 가중치와 옵티마이저 상태는 5분마다 비동기적으로 저장되어, 하드웨어나 네트워크 장애가 발생하더라도 최대 5분의 학습 시간만 손실됩니다. 이러한 임시 모델 체크포인트는 저장 공간을 과도하게 소비하지 않도록 정기적으로 정리됩니다. 또한 컴퓨팅 클러스터 부하의 동적 변화에 대응하기 위해 다른 3D 병렬 구성에서도 학습을 재개할 수 있도록 지원합니다.

평가 단계에서는 생성 태스크에는 vLLM을, 비생성 태스크에는 연속 배칭을 사용하여 수동 배치 크기 조정을 피하고 토큰 패딩을 줄였습니다.
### 스케일링 법칙의 발전과 연구

대규모 언어 모델이 등장하기 이전부터 스케일링 법칙에 대한 연구는 진행되어 왔습니다. 스케일링 법칙은 컴퓨팅 예산 \\(C\\), 모델 규모 \\(N\\), 그리고 데이터 규모 \\(D\\)가 증가함에 따라 모델의 성능이 예측 가능한 방식으로 향상될 수 있음을 제시합니다. 모델 규모 \\(N\\)을 모델 파라미터로, 데이터 규모 \\(D\\)를 토큰 수로 표현할 때, \\(C\\)는 \\(C=6ND\\)로 근사할 수 있습니다. 따라서 컴퓨팅 예산을 증가시킬 때 모델과 데이터 규모 사이의 할당을 최적화하는 것도 스케일링 법칙 연구의 중요한 목표가 되었습니다.

대규모 언어 모델의 발전은 더 큰 모델이 예상치 못한 상당한 성능 향상을 보여주면서 스케일링 법칙 연구를 새로운 정점으로 이끌었습니다. 스케일링 법칙의 연구 결과들은 컴퓨팅 예산을 확장하는 것이 계속해서 상당한 이점을 가져온다는 것을 보여주었고, 이는 모델 규모의 증가를 더욱 촉진했습니다.

그러나 초기 연구들에서 제시된 최적의 모델/데이터 스케일링 할당 전략은 서로 다른 결론을 보여주었고, 이는 스케일링 법칙의 일반적 적용 가능성에 대한 의문을 제기했습니다. 또한 이러한 연구들은 하이퍼파라미터 설정에 대한 완전한 설명이 부족했기 때문에, 서로 다른 컴퓨팅 예산에서 모델들이 최적의 성능에 도달했는지 확실하지 않았습니다.

이러한 불확실성을 해결하고 효율적인 컴퓨팅 스케일업을 위한 올바른 방향을 확인하기 위해, 저자들은 이 섹션에서 스케일링 법칙을 재검토했습니다. 서로 다른 컴퓨팅 예산에서 모델들이 최적의 성능을 달성할 수 있도록 하기 위해, 먼저 하이퍼파라미터의 스케일링 법칙을 연구했습니다. 경험적으로 대부분의 파라미터들의 최적값은 컴퓨팅 예산이 변화해도 일정하게 유지되는 것으로 관찰되었습니다. 따라서 이러한 파라미터들은 앞서 설명한 값들과 동일하게 유지되었습니다.

그러나 성능에 가장 큰 영향을 미치는 하이퍼파라미터인 배치 크기와 학습률은 재검토되었습니다. 초기 연구들은 배치 크기와 학습률 설정에 대한 경험적 관찰을 제공했지만, 예비 실험에서 이러한 관찰들의 적용 가능성이 제한적임을 발견했습니다. 광범위한 실험을 통해 컴퓨팅 예산 \\(C\\)와 최적의 배치 크기 및 학습률 사이의 멱법칙 관계를 모델링했습니다. 이 관계를 하이퍼파라미터의 스케일링 법칙이라고 부르며, 이는 최적의 하이퍼파라미터를 결정하기 위한 경험적 프레임워크를 제공합니다.
### 모델과 데이터 스케일링 법칙 연구

실험 비용과 피팅의 어려움을 줄이기 위해 Chinchilla에서 사용된 IsoFLOP 프로파일 접근 방식을 채택하여 스케일링 곡선을 피팅했습니다. 모델 규모를 더 정확하게 표현하기 위해 기존에 사용되던 모델 파라미터 \\(N\\) 대신 비임베딩 FLOPs/토큰 \\(M\\)이라는 새로운 모델 규모 표현을 도입했고, 근사적인 컴퓨팅 예산 공식 \\(C=6ND\\)를 더 정확한 \\(C=MD\\)로 대체했습니다.

비임베딩 FLOPs/토큰 \\(M\\)은 다음과 같이 정의됩니다.

\\[M = 72\,n_{\mathrm{layer}}\,d_{\mathrm{model}}^{2}+12\,n_{\mathrm{layer}}\,d_{\mathrm{model}}\,l_{\mathrm{seq}}\\]

여기서 \\(n_{\mathrm{layer}}\\)는 레이어 수, \\(d_{\mathrm{model}}\\)은 모델 너비, \\(l_{\mathrm{seq}}\\)는 시퀀스 길이를 나타냅니다. 이는 기존의 비임베딩 파라미터 \\(N_1\\)과 전체 파라미터 \\(N_2\\)보다 더 정확한 계산 비용을 반영합니다.

\\[6N_1 = 72\,n_{\mathrm{layer}}\,d_{\mathrm{model}}^{2}\\]
\\[6N_2 = 72\,n_{\mathrm{layer}}\,d_{\mathrm{model}}^{2}+6\,n_{\mathrm{vocab}}\,d_{\mathrm{model}}\\]

실험 결과는 최적의 모델/데이터 스케일링 할당 전략과 성능 예측에 대한 통찰을 제공했으며, DeepSeek LLM 7B와 67B 모델의 예상 성능을 정확하게 예측했습니다. 또한 스케일링 법칙을 탐구하는 과정에서 사용된 데이터는 여러 차례 반복적으로 품질이 개선되었습니다. 다양한 데이터셋에서 스케일링 곡선을 피팅한 결과, 데이터 품질이 최적의 모델/데이터 스케일링 할당 전략에 상당한 영향을 미친다는 것을 발견했습니다.

데이터 품질이 높을수록 컴퓨팅 예산 증가분을 더 많이 모델 스케일링에 할당해야 합니다. 이는 고품질 데이터가 동일한 데이터 규모에서도 더 큰 모델의 학습을 가능하게 한다는 것을 의미합니다. 최적의 모델/데이터 스케일링 할당 전략의 차이는 데이터 품질을 평가하는 간접적인 방법으로도 활용될 수 있습니다.

### 하이퍼파라미터 스케일링 법칙

컴퓨팅 예산 1e17에서 작은 규모의 실험으로 배치 크기와 학습률에 대한 그리드 서치를 수행했습니다. 특정 모델 크기(177M FLOPs/토큰)에서의 결과는 배치 크기와 학습률의 선택에 있어 상당히 넓은 범위에서 일반화 오차가 안정적으로 유지됨을 보여줍니다. 이는 비교적 넓은 파라미터 공간에서 최적에 가까운 성능을 달성할 수 있다는 것을 의미합니다.
### 하이퍼파라미터 최적화 실험과 스케일링 법칙

앞서 설명한 다단계 학습률 스케줄러를 활용하여 1e17에서 2e19 범위의 다양한 컴퓨팅 예산에서 서로 다른 배치 크기와 학습률로 여러 모델을 효과적으로 학습했습니다. 파라미터 공간의 중복성을 고려하여, 일반화 오차가 최소값보다 0.25% 이상 초과하지 않는 모델들의 파라미터를 최적에 가까운 하이퍼파라미터로 간주했습니다.

이후 컴퓨팅 예산 \\(C\\)에 대한 배치 크기 \\(B\\)와 학습률 \\(\\eta\\)를 피팅했습니다. 피팅 결과는 다음과 같은 수식으로 표현됩니다.

\\[\\eta_{\\mathrm{opt}} = 0.3118\\cdot C^{-0.1250}\\]
\\[B_{\\mathrm{opt}} = 0.2920\\cdot C^{0.3271}\\]

![배치 크기 스케일링 곡선](https://ar5iv.org//html/2401.02954/assets/figures/flops_bsz_fitting.png)

위 그래프는 비임베딩 학습 FLOPs에 따른 최적의 배치 크기를 보여줍니다. 7B MHA 2T 토큰과 67B GQA 2T 토큰 모델에서 모델 크기가 증가함에 따라 최적의 배치 크기도 증가하는 것을 확인할 수 있습니다.

![학습률 스케일링 곡선](https://ar5iv.org//html/2401.02954/assets/figures/flops_lr_fitting.png)

위 그래프는 비임베딩 학습 FLOPs에 따른 최적의 학습률을 보여줍니다. 모델 복잡도가 증가함에 따라 최적의 학습률이 감소하는 경향을 보입니다.

피팅된 공식의 유효성을 검증하기 위해 1e20 컴퓨팅 예산을 가진 일련의 모델들에 대해 실험을 수행했습니다. 특정 모델 크기(2.94B FLOPs/토큰)에서의 결과는 피팅된 파라미터가 최적의 파라미터 공간의 중심에 위치함을 보여줍니다. DeepSeek LLM 7B와 67B 모델에 대해 피팅된 파라미터들도 마찬가지로 우수한 성능을 달성했습니다.

그러나 컴퓨팅 예산 \\(C\\) 이외의 요인들이 최적의 하이퍼파라미터에 미치는 영향은 아직 고려하지 않았습니다. 이는 최적의 배치 크기가 일반화 오차 \\(L\\)에만 관련되어 있다고 제안한 일부 초기 연구들과는 일치하지 않습니다. 또한 동일한 컴퓨팅 예산을 가진 모델들이라도 모델/데이터 할당이 다르면 최적의 파라미터 공간이 약간씩 달라지는 것을 관찰했습니다. 이는 하이퍼파라미터 선택과 학습 동역학을 이해하기 위한 추가 연구가 필요함을 시사합니다.

### 모델 정렬 파이프라인과 학습 데이터 구성

DeepSeek LLM의 모델 정렬 파이프라인은 유용성과 안전성을 모두 고려한 포괄적인 데이터셋을 기반으로 구축되었습니다. 영어와 중국어로 구성된 약 150만 개의 지시 데이터 인스턴스를 수집했으며, 이는 유용성과 안전성 관련 주제를 광범위하게 다룹니다.

유용성 데이터는 120만 개의 인스턴스로 구성되어 있으며, 일반 언어 태스크(31.2%), 수학 문제(46.6%), 코딩 연습(22.2%)의 세 가지 주요 카테고리로 분류됩니다. 이러한 분포는 모델이 다양한 실용적 태스크를 수행할 수 있도록 설계되었습니다. 안전성 데이터는 30만 개의 인스턴스로 구성되어 있으며, 다양한 민감한 주제들을 포함합니다.

모델 정렬 파이프라인은 지도 학습 파인튜닝(Supervised Fine-Tuning, SFT)과 직접 선호도 최적화(Direct Preference Optimization, DPO)의 두 단계로 구성됩니다. 7B 모델은 4 에포크, 67B 모델은 2 에포크로 파인튜닝을 수행했는데, 이는 67B 모델에서 과적합 문제가 더 심각하게 나타났기 때문입니다. 학습률은 7B 모델의 경우 1e-5, 67B 모델의 경우 5e-6로 설정되었습니다.

파인튜닝 과정에서는 벤치마크 정확도 모니터링과 함께 채팅 모델의 반복 비율도 평가했습니다. 3,868개의 중국어와 영어 프롬프트를 수집하여 생성된 응답이 종료되지 않고 텍스트 시퀀스를 무한히 반복하는 비율을 측정했습니다. 위 그래프는 수학 SFT 데이터가 증가함에 따라 반복 비율이 증가하는 경향을 보여줍니다. 이는 수학 SFT 데이터가 때때로 유사한 추론 패턴을 포함하기 때문입니다. 성능이 약한 모델들은 이러한 추론 패턴을 제대로 이해하지 못해 반복적인 응답을 생성하게 됩니다.

이 문제를 해결하기 위해 2단계 파인튜닝과 DPO를 시도했으며, 두 방법 모두 벤치마크 점수를 거의 유지하면서 반복을 크게 줄일 수 있었습니다. DPO 단계에서는 유용성과 안전성 측면에서 선호도 데이터를 구성했습니다. 유용성 데이터를 위해 창의적 글쓰기, 질문 답변, 지시 따르기 등의 카테고리를 포함하는 다국어 프롬프트를 수집했고, DeepSeek Chat 모델을 사용하여 응답 후보를 생성했습니다. 안전성 선호도 데이터 구성에도 유사한 방식을 적용했습니다.

DPO 학습은 1 에포크 동안 진행되었으며, 학습률 5e-6와 배치 크기 512를 사용했습니다. 학습률 웜업과 코사인 학습률 스케줄러를 적용했습니다. DPO는 표준 벤치마크에서의 성능 차이는 거의 없으면서도 모델의 개방형 생성 능력을 강화할 수 있음을 확인했습니다.

### 벤치마크 평가 결과

DeepSeek LLM의 성능을 평가하기 위해 영어와 중국어 공개 벤치마크에서 광범위한 평가를 수행했습니다. 평가는 다음과 같은 주요 카테고리에서 이루어졌습니다.

다중 주제 객관식 데이터셋에서는 MMLU, C-Eval, CMMLU를 사용했습니다. 이러한 데이터셋들은 다양한 학문 분야에 걸친 지식을 평가하는데, MMLU는 영어 기반의 평가를, C-Eval과 CMMLU는 중국어 기반의 평가를 제공합니다.

언어 이해와 추론 능력 평가를 위해서는 HellaSwag, PIQA, ARC, OpenBookQA, BigBench Hard(BBH) 데이터셋을 활용했습니다. 이러한 데이터셋들은 상식적 추론, 과학적 추론, 그리고 복잡한 문제 해결 능력을 측정합니다.

폐쇄형 질의응답 능력은 TriviaQA와 NaturalQuestions 데이터셋으로 평가했으며, 독해력 평가에는 RACE, DROP, C3 데이터셋을 사용했습니다. 참조 명확화 능력은 WinoGrande와 CLUEWSC를 통해 평가했고, 언어 모델링 능력은 Pile 데이터셋으로 측정했습니다.

중국어 이해력과 문화적 지식은 CHID와 CCPM 데이터셋으로 평가했습니다. 수학적 능력 평가에는 GSM8K, MATH, CMath를, 코딩 능력 평가에는 HumanEval과 MBPP를 사용했습니다. 표준화된 시험 성능은 AGIEval을 통해 평가했습니다.

평가 방식은 크게 두 가지로 나뉩니다. 첫째, 퍼플렉시티 기반 평가는 여러 선택지 중에서 답을 고르는 방식의 데이터셋에 적용되었습니다. 각 선택지의 퍼플렉시티를 계산하여 가장 낮은 값을 가진 선택지를 모델의 예측으로 선택했습니다. ARC와 OpenBookQA에서는 무조건부 정규화를, 다른 데이터셋에서는 길이 정규화를 적용했습니다.

둘째, 생성 기반 평가는 TriviaQA, NaturalQuestions, DROP, MATH, GSM8K, HumanEval, MBPP, BBH, AGIEval, CLUEWSC, CMath에 적용되었습니다. 이 방식에서는 모델이 자유롭게 텍스트를 생성하고, 생성된 텍스트에서 결과를 추출합니다. 생성 기반 평가에서는 탐욕적 디코딩(greedy decoding)을 사용했습니다.

Pile-test에 대해서는 언어 모델링 기반 평가를 수행했으며, 이는 테스트 코퍼스에서의 바이트당 비트(bits-per-byte)를 계산하는 방식입니다. 벤치마크에 따라 2048 또는 4096의 최대 시퀀스 길이를 사용했습니다.

![벤치마크 결과표](https://ar5iv.org//html/2401.02954/assets/figures/pretrain_metric.png)

위 그래프는 DeepSeek LLM Base 모델의 벤치마크 메트릭 곡선을 보여줍니다. HumanEval, TriviaQA, GSM8K, BBH, ChineseQA와 같은 다양한 벤치마크에서의 성능을 확인할 수 있습니다. 학습이 진행됨에 따라 모든 벤치마크에서 일관된 성능 향상을 보여주고 있으며, 학습이 계속된다면 성능이 더욱 향상될 것으로 예상됩니다.
### 기본 모델의 벤치마크 성능 분석

DeepSeek LLM의 기본 모델 평가 결과는 영어와 중국어 태스크 모두에서 주목할 만한 성과를 보여줍니다. 2조 개의 이중 언어 코퍼스로 학습된 DeepSeek 모델은 영어에 중점을 둔 LLaMA2 모델과 비교했을 때 영어 언어 이해 벤치마크에서 대등한 성능을 달성했습니다.

특히 DeepSeek 67B는 MATH, GSM8K, HumanEval, MBPP, BBH와 같은 수학 및 코딩 관련 태스크에서 LLaMA2 70B를 크게 앞섰습니다. 중국어 벤치마크에서도 우수한 성능을 보여주었습니다. 모델 규모가 증가함에 따라 GSM8K와 BBH와 같은 태스크에서 성능이 크게 향상되는 것을 확인할 수 있었습니다. 이는 대규모 모델의 강력한 퓨샷 학습 능력을 보여주는 결과입니다.

주목할 만한 점은 DeepSeek 67B가 LLaMA2 70B에 비해 보이는 성능 우위가 DeepSeek 7B와 LLaMA2 7B 간의 차이보다 더 크다는 것입니다. 이는 작은 모델에서 언어 충돌의 영향이 더 크게 나타남을 시사합니다. 또한 중국어 데이터로 특별히 학습되지 않은 LLaMA2도 CMath와 같은 일부 중국어 태스크에서 인상적인 성능을 보여주었습니다. 이는 수학적 추론과 같은 기본적인 능력이 언어 간에 효과적으로 전이될 수 있음을 보여줍니다. 그러나 중국어 관용구 사용을 평가하는 CHID와 같은 태스크에서는 사전 학습 과정에서 상당한 양의 중국어 토큰이 필요하며, 이러한 태스크에서 LLaMA2는 DeepSeek LLM에 비해 현저히 낮은 성능을 보였습니다.

### 채팅 모델의 벤치마크 성능 분석

DeepSeek 채팅 모델은 파인튜닝 이후 대부분의 태스크에서 전반적인 성능 향상을 보여주었습니다. 그러나 일부 태스크에서는 성능이 감소하는 현상도 관찰되었습니다. 이러한 성능 변화는 다음과 같은 카테고리별 특성을 보입니다.

지식 관련 태스크(TriviaQA, MMLU, C-Eval)에서는 기본 모델과 채팅 모델 간의 성능 변동이 관찰되었습니다. 그러나 이러한 변동이 지도 학습 파인튜닝(SFT) 이후 지식의 획득이나 손실을 의미하지는 않습니다. SFT의 가치는 실제 시나리오에 부합하는 방식으로, 채팅 모델이 제로샷 설정에서 기본 모델의 퓨샷 설정과 비슷한 점수를 달성할 수 있게 하는 데 있습니다.

추론 태스크에서는 체인 오브 소트 형식의 SFT 인스턴스가 상당 부분을 차지하여, BBH와 NaturalQuestions와 같은 태스크에서 약간의 성능 향상이 있었습니다. 그러나 SFT 단계가 추론 능력 자체를 학습하는 것이 아니라 추론 경로의 올바른 형식을 학습하는 것으로 보입니다.
### 채팅 모델의 성능 저하 분석과 수학/코드 태스크 개선

HellaSwag와 같은 클로즈 태스크나 문장 완성 태스크에서는 모델 크기나 사전 학습된 체크포인트와 관계없이 파인튜닝 후 일관되게 성능이 감소했습니다. 이는 순수 언어 모델이 이러한 유형의 태스크를 처리하는 데 더 적합하다는 것을 시사합니다.

수학과 코딩 태스크에서는 파인튜닝 후 상당한 성능 향상이 있었습니다. HumanEval과 GSM8K에서 20포인트 이상의 점수 향상을 보였습니다. 이는 기본 모델이 이러한 태스크에 대해 초기에 과소적합(underfitting) 상태였으며, SFT 단계에서 방대한 SFT 데이터를 통해 코딩과 수학 분야의 추가 지식을 학습했기 때문입니다. 그러나 모델의 능력이 주로 코드 완성과 대수학 문제에 집중되어 있다는 점에 주목해야 합니다. 수학과 코딩에 대한 포괄적인 이해를 위해서는 사전 학습 단계에서 다양한 데이터를 통합하는 것이 중요하며, 이는 향후 연구 과제로 남아있습니다.

7B 모델의 파인튜닝에서는 먼저 모든 데이터로 모델을 파인튜닝한 후, 두 번째 단계에서 수학과 코드 데이터를 제외하고 진행했습니다. 이러한 접근 방식을 채택한 이유는 1단계 모델이 2.0%의 반복 비율을 보였는데, 2단계 조정 후에는 벤치마크 점수를 유지하면서도 반복 비율이 1.4%로 감소했기 때문입니다. 67B 모델의 경우, 첫 번째 단계 파인튜닝 이후 이미 반복 비율이 1% 미만이었고, 두 번째 단계는 오히려 벤치마크 점수를 저하시켰기 때문에 1단계 SFT만 수행했습니다.

### AlignBench 평가 결과

AlignBench 리더보드에서 DeepSeek 67B 채팅 모델은 ChatGPT와 다른 기준 모델들을 큰 차이로 앞섰습니다. 이는 기본적인 중국어 언어 태스크와 고급 중국어 추론 태스크 모두에서 우수한 성능을 보여줍니다. DPO 과정이 거의 모든 분야에서 성능 향상을 가져왔다는 점도 주목할 만합니다.
### 개방형 평가 결과

채팅 모델의 경우, 표준 벤치마크의 메트릭 관찰 외에도 개방형 도메인과 개방형 질문에서 생성된 결과의 품질이 실제 사용자 경험에 직접적인 영향을 미칩니다. 따라서 중국어와 영어 태스크에서 채팅 모델의 개방형 생성 능력을 별도로 평가했습니다.

중국어 개방형 평가를 위해 AlignBench라는 고품질 개방형 질문 테스트셋에서 다양한 도메인에 걸친 모델의 종합적인 능력을 테스트했습니다. AlignBench는 총 8개의 주요 카테고리, 36개의 하위 카테고리를 포함하며 683개의 질문으로 구성되어 있습니다. 각 질문에 대해 AlignBench는 전문가의 참조 답변과 GPT-4가 응답의 품질을 판단하기 위한 평가 템플릿을 제공합니다.

평가 과정에서는 공식 AlignBench GitHub 코드 저장소를 활용했으며, 원본 설정과 정확히 일치하도록 주요 온도 파라미터를 조정했습니다. 역할 수행, 작문 능력, 개방형 질문에 대해서는 생성 온도를 0.7로 설정했고, 다른 태스크에 대해서는 0.1로 설정했습니다.

DeepSeek 67B 채팅 모델은 ChatGPT와 다른 기준 모델들을 능가했으며, GPT-4의 두 버전에 이어 3위를 기록했습니다. 이는 다른 오픈소스 또는 독점 중국어 대규모 언어 모델들과 비교했을 때 다양한 중국어 태스크에서 우수한 성능을 보여줍니다. DPO 모델은 거의 모든 메트릭에서 향상을 보였으며, 이는 DPO 학습 과정이 모델 정렬에 긍정적인 영향을 미쳤음을 입증합니다.

기본적인 중국어 언어 태스크에서 DeepSeek 모델은 최상위 티어에 속했으며, DPO 모델의 중국어 기본 언어 능력은 최신 버전의 GPT-4보다도 높았습니다. 고급 중국어 추론 태스크에서도 다른 중국어 LLM들과 비교하여 논리적 추론과 수학적 계산에서 월등히 높은 점수를 기록했습니다.

영어 개방형 평가에서는 MT-Bench 벤치마크를 사용했습니다. MT-Bench는 8개의 서로 다른 카테고리의 다중 턴 질문들을 포함합니다. DeepSeek LLM 67B 채팅 모델은 LLaMA-2-Chat 70B, Xwin 70b v0.1, TÜLU 2+DPO 70B와 같은 다른 오픈소스 모델들을 능가했으며, GPT-3.5-turbo와 비슷한 8.35점을 달성했습니다. DPO 단계 이후에는 점수가 8.76으로 더욱 향상되어 GPT-4에 이어 2위를 기록했습니다. 이러한 결과는 DeepSeek LLM의 강력한 다중 턴 개방형 생성 능력을 보여줍니다.
### 보류 평가 데이터셋을 통한 성능 검증

데이터 오염과 벤치마크 과적합은 LLM 평가에서 중요한 도전 과제입니다. 이를 해결하기 위한 일반적인 방법은 최근 발표된 테스트셋을 보류 테스트셋으로 활용하여 모델을 평가하는 것입니다. DeepSeek LLM의 보류 평가를 위해 세 가지 주요 데이터셋을 활용했습니다.

코딩 능력 평가를 위해 LeetCode 주간 콘테스트(Weekly Contest 351-372, Bi-Weekly Contest 108-117, 2023년 7월부터 11월까지)의 문제들을 크롤링하여 수집했습니다. 총 126개의 문제로 구성되어 있으며, 각 문제마다 20개 이상의 테스트 케이스가 포함되어 있습니다. HumanEval과 유사한 평가 방식을 적용하여, 모델이 생성한 코드가 모든 테스트 케이스를 통과할 경우 해당 문제를 성공적으로 해결한 것으로 간주했습니다.

수학적 능력 평가를 위해서는 Grok-1과 마찬가지로 헝가리 전국 고등학교 시험을 활용했습니다. 이 시험은 33개의 문제로 구성되어 있으며, 공식 답안지의 채점 기준에 따라 인간 평가자가 모델의 점수를 산정했습니다.

지시사항 준수 능력 평가를 위해서는 2023년 11월 15일에 Google이 공개한 평가 데이터셋을 활용했습니다. 이 데이터셋은 25가지 유형의 검증 가능한 지시사항을 식별하고 약 500개의 프롬프트를 구성했으며, 각 프롬프트는 하나 이상의 검증 가능한 지시사항을 포함합니다. 평가에는 프롬프트 수준의 느슨한 메트릭을 적용했습니다.

보류 평가 데이터셋에서 DeepSeek LLM은 다양한 기준 모델들과 비교하여 우수한 성능을 보여주었습니다. 특히 큰 모델과 작은 모델 사이에 상당한 성능 차이가 있음을 확인할 수 있었습니다. 예를 들어, ChatGLM3는 코드 테스트셋인 MBPP에서 52.4점을 기록하여 DeepSeek 67B와 비슷한 성능을 보였지만, 새로운 벤치마크에서는 DeepSeek 67B에 비해 현저히 낮은 성능을 보였습니다. 수학 데이터셋에서도 유사한 경향이 관찰되었는데, ChatGLM3는 GSM8K에서 72.3점의 높은 성능을 보였지만, 헝가리 시험 점수에서는 대형 모델들에 비해 낮은 성능을 기록했습니다.

지시사항 준수 능력에서도 총 계산량이 중요한 역할을 하는 것으로 나타났습니다. 동일한 학습 파이프라인을 사용한 DeepSeek 7B와 67B 모델 사이에 상당한 성능 차이가 있었습니다. 주관적 평가를 통해 67B 규모로 모델 크기를 확장할 때 다양한 태스크에서 지능적 능력의 현저한 차이가 있음을 관찰했습니다. DeepSeek 7B는 표준 벤치마크에서 다른 소형 언어 모델들에 비해 낮은 성능을 보였지만, 보류 태스크에서는 상대적으로 우수한 성능을 보여주었습니다.
### 안전성 평가 방법론과 결과

인공지능의 안전성은 일반 인공지능 개발에 있어 핵심적인 요소입니다. 진정으로 도움이 되는 인공지능 모델을 구축하기 위해서는 인간의 가치와 일치하고 인류에 대한 친화성을 보여주는 것이 전제 조건입니다. DeepSeek LLM은 사전 학습, SFT, DPO를 포함한 전체 학습 과정에서 모델의 안전성을 보장하기 위한 노력을 기울였습니다.

모델의 안전성을 검증하기 위해 다양한 분야의 전문가 20명으로 구성된 팀을 구성하고, 인간의 가치와 부합하는 안전 콘텐츠 분류 체계를 구축했습니다. 이 전문가 팀은 각 안전성 하위 카테고리에 대해 수십 개의 고품질 테스트 케이스를 수작업으로 구성했습니다.

안전성 콘텐츠의 다양성뿐만 아니라 형식의 다양성도 중요하게 고려했습니다. 악명 높은 "할머니" 취약점은 모델이 쿼리의 표면적 형식에 속아 안전하지 않은 응답을 제공할 수 있음을 보여줍니다. 따라서 전문가 팀은 유도, 역할 수행, 다중 턴 대화, 사전 설정된 입장 등 다양한 방식으로 질문을 구성했습니다. 최종적으로 2,400개의 질문으로 구성된 안전성 테스트셋을 구축했습니다.

전문가 팀은 각각의 콘텐츠 유형과 형식 유형에 대한 기본적인 안전성 검토 지침도 구성했습니다. 이 테스트셋에 대한 모델의 출력 결과는 수동으로 검사되었으며, 검토 팀은 충분한 교육을 받았고 주석 결과에 대한 교차 검증이 수행되었습니다. 주석자들은 각 질문에 대해 안전, 불안전, 모델 거부의 세 가지 카테고리로 주석을 달았습니다.

DeepSeek 67B 채팅 모델의 안전성 평가 결과, 다양한 안전성 테스트 카테고리에서 우수한 성능을 보여주었습니다. 안전하게 응답하거나 모델이 거부한 테스트 케이스를 모두 안전한 응답으로 분류했을 때, 대부분의 카테고리에서 90% 이상의 높은 안전성을 달성했습니다.

추가적으로 "Do-Not-Answer" 데이터셋을 활용하여 DeepSeek 67B 채팅 모델의 안전성 메커니즘을 평가했습니다. 939개의 위험 분류된 프롬프트로 구성된 이 데이터셋에서 DeepSeek 67B 채팅 모델은 97.8점을 달성하여 ChatGPT와 GPT-4보다 높은 점수를 기록했습니다. 이는 모델이 민감한 쿼리를 안전하게 처리할 수 있는 능력이 우수함을 보여주며, 이 분야의 선도적인 모델들과 경쟁력 있는 수준임을 입증합니다.

- - -
### References
* [DeepSeek LLM: Scaling Open-Source Language Models with Longtermism](http://arxiv.org/pdf/2401.02954v1)