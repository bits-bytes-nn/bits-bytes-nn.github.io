---
layout: post
title: "DeepSeek LLM: Scaling Open-Source Language Models with Longtermism"
date: 2024-01-05 18:59:13
author: "DeepSeek-AI"
categories: "Language-Models"
tags: ["Scaling-Laws-for-Large-Language-Models", "Optimal-Model/Data-Scaling-Up-Allocation", "Multi-Step-Learning-Rate-Scheduler", "Grouped-Query-Attention", "Supervised-Fine-Tuning", "Direct-Preference-Optimization", "DeepSeekMath-Corpus"]
use_math: true
cover: /assets/images/language-models.webp
---
### TL;DR
#### 이 연구를 시작하게 된 배경과 동기는 무엇입니까?
대규모 언어 모델(LLMs)의 오픈소스 개발이 급속도로 발전하는 가운데, 기존 연구들이 제시한 스케일링 법칙들 간의 불일치가 존재했습니다. 특히 컴퓨팅 예산 증가에 따른 모델과 데이터의 최적 스케일링 전략에 대해 서로 다른 결론들이 제시되었고, 하이퍼파라미터 설정에 대한 체계적인 연구도 부족했습니다. 이러한 불확실성은 AGI 개발의 초기 단계에 있는 오픈소스 LLM의 효율적인 확장을 저해하는 요인이 되었습니다. DeepSeek 연구진은 이러한 간극을 메우고 장기적 관점에서 오픈소스 LLM의 체계적인 확장 전략을 수립하고자 이 연구를 시작했습니다.

#### 이 연구에서 제시하는 새로운 해결 방법은 무엇입니까?
연구진은 먼저 하이퍼파라미터의 스케일링 법칙을 체계적으로 연구하여 컴퓨팅 예산과 최적 배치 크기 및 학습률 간의 멱법칙 관계를 도출했습니다. 또한 기존의 모델 규모 표현 방식(파라미터 수 기반)의 한계를 극복하기 위해 비임베딩 FLOPs/토큰이라는 새로운 모델 규모 지표를 제안했습니다. 이를 통해 더 정확한 컴퓨팅 비용 예측과 스케일링 전략 수립이 가능해졌습니다. 특히 주목할 만한 점은 데이터 품질이 최적 모델/데이터 스케일링 할당에 미치는 영향을 체계적으로 분석하여, 데이터 품질이 향상될수록 컴퓨팅 예산을 모델 확장에 더 많이 할당해야 한다는 새로운 통찰을 제시했다는 것입니다.

#### 제안된 방법은 어떻게 구현되었습니까?
연구진은 2조 개의 토큰으로 구성된 다국어 데이터셋을 구축하고, LLaMA 아키텍처를 기반으로 하되 다단계 학습률 스케줄러를 도입하여 7B와 67B 규모의 모델을 개발했습니다. 특히 67B 모델에서는 추론 효율성을 위해 그룹드-쿼리 어텐션을 도입했고, 네트워크 깊이를 95개 레이어로 확장했습니다. 정렬 파이프라인은 지도 학습 미세조정과 직접 선호도 최적화를 통해 구현되었으며, 150만 개의 지시 데이터를 활용했습니다. 또한 20명의 전문가로 구성된 팀을 통해 2,400개의 안전성 테스트 케이스를 구축하여 모델의 안전성을 검증했습니다.

#### 이 연구의 결과가 가지는 의미는 무엇입니까?
이 연구는 오픈소스 LLM의 효율적인 확장을 위한 체계적인 프레임워크를 제시했다는 점에서 큰 의의를 가집니다. 특히 데이터 품질과 스케일링 전략 간의 관계를 밝힘으로써, 향후 LLM 개발에서 데이터 품질 향상의 중요성을 부각시켰습니다. 개발된 DeepSeek LLM 67B는 코드, 수학, 추론 분야에서 LLaMA-2 70B를 능가했으며, 채팅 모델은 GPT-3.5보다 우수한 성능을 보여주었습니다. 이는 제안된 스케일링 전략의 효과성을 입증하며, 오픈소스 LLM이 상용 모델과 견줄 만한 성능에 도달할 수 있다는 가능성을 보여줍니다. 또한 안전성 평가에서도 우수한 결과를 보여, 성능과 안전성을 동시에 달성할 수 있다는 것을 입증했습니다.
- - -
## DeepSeek LLM: 장기적 관점에서의 오픈소스 언어 모델 확장

### 서론

대규모 언어 모델(Large Language Models, LLMs)의 오픈소스 개발은 놀라운 속도로 발전해왔습니다. 그러나 기존 연구에서 제시된 스케일링 법칙들은 서로 다른 결론을 보여주며, 이는 LLM 스케일링에 대한 불확실성을 야기했습니다. DeepSeek 연구진은 이러한 스케일링 법칙을 심도 있게 연구하여, 현재 널리 사용되는 7B와 67B 파라미터 규모의 오픈소스 모델 구성에서 대규모 모델 확장을 가능하게 하는 독특한 발견을 제시합니다.

연구진은 스케일링 법칙을 기반으로 장기적 관점에서 오픈소스 언어 모델을 발전시키기 위한 DeepSeek LLM 프로젝트를 소개합니다. 사전학습을 위해 현재 2조 개의 토큰으로 구성되어 있으며 지속적으로 확장되고 있는 데이터셋을 구축했습니다. DeepSeek LLM 베이스 모델에 지도 학습 미세조정(Supervised Fine-tuning, SFT)과 직접 선호도 최적화(Direct Preference Optimization, DPO)를 적용하여 DeepSeek Chat 모델을 개발했습니다.

평가 결과에 따르면 DeepSeek LLM 67B는 특히 코드, 수학, 추론 영역에서 LLaMA-2 70B를 능가하는 성능을 보여줍니다. 더불어 개방형 평가에서 DeepSeek LLM 67B Chat은 GPT-3.5보다 우수한 성능을 보여주었습니다. 이러한 성과는 Kaplan과 연구진이 제시한 스케일링 법칙과 Hoffmann과 연구진의 컴퓨트 최적 스케일링 연구를 기반으로 한 체계적인 모델 확장 전략의 효과를 입증합니다.

### 대규모 언어 모델의 발전과 현황

최근 몇 년간 디코더 전용 트랜스포머를 기반으로 하는 대규모 언어 모델(Large Language Models, LLMs)은 인공일반지능(AGI)을 달성하기 위한 핵심 기술로 자리잡았습니다. 이러한 모델들은 연속적인 텍스트에서 다음 단어를 예측하는 자기지도 학습을 통해 사전학습되며, 이를 통해 창작, 텍스트 요약, 코드 완성 등 다양한 능력을 갖추게 됩니다.

지도 학습 미세조정과 보상 모델링의 발전으로 대규모 언어 모델은 사용자의 의도와 지시를 더 잘 따르게 되었고, 이는 더욱 다재다능한 대화 능력으로 이어졌습니다. ChatGPT, Claude, Bard와 같은 상용 제품들이 이러한 발전을 주도했으며, 이들은 막대한 컴퓨팅 자원과 데이터 주석 비용을 투자하여 개발되었습니다.

이러한 상용 제품들의 성공은 오픈소스 언어 모델에 대한 커뮤니티의 기대치를 크게 높였고, 이는 일련의 연구들을 촉발했습니다. 특히 LLaMA 시리즈 모델은 효율적이고 안정적인 아키텍처를 통합하여 7B에서 70B 파라미터에 이르는 우수한 성능의 모델을 구축했으며, 오픈소스 모델의 아키텍처와 성능에 대한 사실상의 기준이 되었습니다.

LLaMA 이후 오픈소스 커뮤니티는 주로 고정된 크기(7B, 13B, 34B, 70B)의 고품질 모델 학습에 집중했으며, 언어 모델 스케일링 법칙에 대한 연구는 상대적으로 소홀히 다뤄졌습니다. 그러나 현재의 오픈소스 모델들이 AGI 개발의 초기 단계에 있다는 점을 고려할 때, 스케일링 법칙에 대한 연구는 매우 중요합니다. 특히 초기 연구들은 컴퓨팅 예산 증가에 따른 모델과 데이터의 스케일링에 대해 서로 다른 결론을 도출했으며, 하이퍼파라미터에 대한 논의도 충분히 이루어지지 않았습니다.
### 스케일링 법칙 연구와 DeepSeek LLM의 개발

본 논문에서는 언어 모델의 스케일링 동작을 광범위하게 조사하고, 이를 7B와 67B 파라미터 규모의 두 가지 널리 사용되는 대규모 모델 구성에 적용했습니다. 연구진은 배치 크기와 학습률의 스케일링 법칙을 먼저 검토하여 모델 크기에 따른 경향성을 파악했으며, 이를 바탕으로 데이터와 모델 규모의 스케일링 법칙에 대한 포괄적인 연구를 수행했습니다.

이러한 연구를 통해 최적의 모델/데이터 스케일링 할당 전략을 밝혀냈고, 대규모 모델의 예상 성능을 예측할 수 있었습니다. 특히 주목할 만한 발견은 서로 다른 데이터셋에서 도출된 스케일링 법칙이 상당한 차이를 보인다는 점입니다. 이는 데이터셋의 선택이 스케일링 동작에 큰 영향을 미친다는 것을 시사하며, 스케일링 법칙을 데이터셋 간에 일반화할 때 주의가 필요함을 보여줍니다.

이러한 스케일링 법칙의 지침 아래, 연구진은 중국어와 영어를 중심으로 2조 개의 토큰을 수집하여 사전학습에 활용했습니다. 모델 아키텍처는 기본적으로 LLaMA를 따랐지만, 코사인 학습률 스케줄러 대신 다단계 학습률 스케줄러를 도입하여 성능을 유지하면서도 지속적인 학습을 용이하게 했습니다.

지도 학습 미세조정을 위해 다양한 출처에서 100만 개 이상의 데이터를 수집했으며, 직접 선호도 최적화(DPO)를 활용하여 모델의 대화 성능을 향상시켰습니다. 이러한 노력의 결과로 개발된 DeepSeek LLM은 코드, 수학, 추론 분야에서 LLaMA-2 70B를 능가하는 성능을 보여주었으며, DeepSeek 67B 채팅 모델은 중국어와 영어 모두에서 GPT-3.5를 뛰어넘는 성능을 달성했습니다.

### 데이터셋 구축 및 토크나이저 설계

DeepSeek LLM의 핵심 목표는 데이터셋의 풍부성과 다양성을 포괄적으로 향상시키는 것입니다. 이를 위해 연구진은 중복제거(deduplication), 필터링(filtering), 리믹싱(remixing)이라는 세 가지 핵심 단계로 접근 방식을 구성했습니다. 

중복제거 단계에서는 적극적인 전략을 채택하여 중복제거 범위를 확장했습니다. 연구진의 분석에 따르면 전체 Common Crawl 코퍼스에 대한 중복제거는 단일 덤프 내에서의 중복제거보다 더 많은 중복 인스턴스를 제거할 수 있었습니다. 91개의 덤프에 걸친 중복제거는 단일 덤프 방식에 비해 4배 더 많은 문서를 제거했으며, 덤프 수가 증가할수록 중복제거율도 22.2%에서 89.8%까지 점진적으로 증가했습니다.

필터링 단계에서는 문서 품질 평가를 위한 강력한 기준을 개발했습니다. 이는 언어적 평가와 의미론적 평가를 모두 포함하는 상세한 분석을 통해 개별 및 전체적 관점에서 데이터 품질을 평가합니다. 리믹싱 단계에서는 데이터 불균형을 해결하기 위해 접근 방식을 조정했으며, 특히 과소 대표된 도메인의 비중을 높이는 데 중점을 두었습니다.

토크나이저 구현에 있어서는 토크나이저 라이브러리를 기반으로 바이트 수준 바이트 쌍 인코딩(BBPE) 알고리즘을 구현했습니다. GPT-2와 유사하게 개행, 문장부호, 한중일(CJK) 기호와 같은 서로 다른 문자 범주의 토큰이 병합되는 것을 방지하기 위해 사전 토크나이징을 적용했습니다. 또한 Touvron과 연구진의 접근 방식을 따라 숫자를 개별 자릿수로 분할했습니다.

연구진의 경험을 바탕으로 어휘 사전의 일반 토큰 수를 100,000개로 설정했으며, 약 24GB 크기의 다국어 코퍼스에서 토크나이저를 학습시켰습니다. 최종 어휘 사전에는 15개의 특수 토큰을 추가하여 총 100,015개의 토큰으로 구성했습니다. 학습 시 계산 효율성을 확보하고 향후 추가 특수 토큰을 위한 여유 공간을 확보하기 위해 모델의 어휘 사전 크기를 102,400으로 설정했습니다.
### 모델 아키텍처와 하이퍼파라미터 설계

DeepSeek LLM의 아키텍처는 LLaMA의 기본 설계를 따르면서도 몇 가지 중요한 차별점을 가지고 있습니다. 모델은 RMSNorm 함수를 사용하는 Pre-Norm 구조를 채택했으며, 피드포워드 네트워크(FFN)의 활성화 함수로 SwiGLU를 사용합니다. FFN의 중간 계층 차원은 $\frac{8}{3}d_{model}$로 설정되었으며, 위치 인코딩을 위해 로터리 임베딩을 적용했습니다.

67B 모델의 경우, 추론 비용을 최적화하기 위해 전통적인 멀티헤드 어텐션(MHA) 대신 그룹드-쿼리 어텐션(GQA)을 도입했습니다. 특히 주목할 만한 점은 DeepSeek LLM의 네트워크 깊이 설계입니다. 7B 모델은 30개의 레이어로 구성되어 있으며, 67B 모델은 95개의 레이어를 가지고 있습니다. 이러한 레이어 조정은 다른 오픈소스 모델들과의 파라미터 일관성을 유지하면서도 모델의 파이프라인 분할을 최적화하여 학습과 추론 효율성을 높이는 데 기여합니다.

대부분의 GQA를 사용하는 연구들과 달리, 67B 모델에서는 FFN 레이어의 중간 너비를 넓히는 일반적인 방식 대신 네트워크 깊이를 확장하는 접근법을 선택했습니다. 이는 더 나은 성능을 달성하기 위한 전략적 선택이었습니다. 모델의 컨텍스트 길이는 4096 토큰으로 설정되었으며, 학습 시퀀스 길이는 4096 토큰, 배치 크기는 7B 모델의 경우 2304, 67B 모델의 경우 4608로 설정되었습니다. 학습률은 각각 4.2e-4와 3.2e-4로 설정되어 모델 크기에 따른 최적화를 고려했습니다.

### 모델 학습 및 최적화 설정

DeepSeek LLM은 0.006의 표준편차로 초기화되었으며, AdamW 옵티마이저를 사용하여 학습되었습니다. 이 옵티마이저의 주요 하이퍼파라미터는 $\beta_1=0.9$, $\beta_2=0.95$, 그리고 $\text{weight decay}=0.1$로 설정되었습니다. 

일반적으로 사용되는 코사인 스케줄러 대신 다단계 학습률 스케줄러를 사전학습에 도입했습니다. 구체적으로, 모델의 학습률은 2000 웜업 스텝 후 최대값에 도달하고, 전체 학습 토큰의 80%를 처리한 후에는 최대값의 31.6%로 감소하며, 90%의 토큰을 처리한 후에는 최대값의 10%로 더욱 감소합니다. 학습 과정에서 그래디언트 클리핑은 1.0으로 설정되었습니다.

연구진의 실험 결과에 따르면, 학습 중 손실 감소 추세에는 차이가 있지만 다단계 학습률 스케줄러를 사용한 최종 성능은 코사인 스케줄러와 실질적으로 동일한 수준을 보여주었습니다. 아래 그래프에서 이러한 비교 결과를 확인할 수 있습니다.

![학습률 스케줄러 비교](https://ar5iv.org//html/2401.02954/assets/figures/loss_step_cosine.png)

다단계 학습률 스케줄러의 주요 장점은 모델 크기를 고정한 상태에서 학습 규모를 조정할 때 첫 번째 단계의 학습을 재사용할 수 있다는 점입니다. 이러한 특성은 지속적인 학습에 있어 독특한 편의성을 제공합니다.

![다단계 비율 비교](https://ar5iv.org//html/2401.02954/assets/figures/loss_diff_step.png)

다단계 학습률 스케줄러의 각 단계 비율을 조정하면 약간의 성능 향상을 얻을 수 있음을 실험을 통해 확인했습니다. 그러나 연구진은 지속적 학습에서의 재사용 비율과 모델 성능 사이의 균형을 고려하여 세 단계의 비율을 80%, 10%, 10%로 설정했습니다.

### 인프라 구조

DeepSeek LLM의 학습과 평가를 위해 HAI-LLM이라는 효율적이고 경량화된 학습 프레임워크를 활용했습니다. 이 프레임워크는 Megatron에서 구현된 것과 같이 데이터 병렬화, 텐서 병렬화, 시퀀스 병렬화, 그리고 1F1B 파이프라인 병렬화를 통합했습니다. 하드웨어 활용도를 높이기 위해 플래시 어텐션 기술을 적용했으며, 데이터 병렬 랭크에 걸쳐 옵티마이저 상태를 분할하기 위해 ZeRO-1을 활용했습니다.
### 스케일링 법칙 연구

대규모 언어 모델이 등장하기 이전부터 스케일링 법칙에 대한 연구는 진행되어 왔습니다. 스케일링 법칙은 컴퓨팅 예산 $C$, 모델 규모 $N$, 그리고 데이터 규모 $D$가 증가함에 따라 모델 성능이 예측 가능한 방식으로 향상된다는 것을 보여줍니다. 모델 규모 $N$이 모델 파라미터를 나타내고 데이터 규모 $D$가 토큰 수를 나타낼 때, 컴퓨팅 예산 $C$는 $C=6ND$로 근사할 수 있습니다.

이러한 스케일링 법칙 연구는 컴퓨팅 예산을 증가시킬 때 모델과 데이터 규모 사이의 최적 할당을 찾는 것을 중요한 연구 목표로 삼고 있습니다. 대규모 언어 모델의 발전과 함께, 더 큰 모델이 예상치 못한 현저한 성능 향상을 보여주면서 스케일링 법칙 연구는 새로운 정점에 도달했습니다.

스케일링 법칙의 연구 결과들은 컴퓨팅 예산을 확장하는 것이 지속적으로 상당한 이점을 제공한다는 것을 보여주며, 이는 모델 규모의 증가를 더욱 촉진했습니다. 그러나 초기 연구들에서 제시된 최적의 모델/데이터 스케일링 할당 전략이 서로 다른 결론을 보여주면서 스케일링 법칙의 일반적 적용 가능성에 대한 의문이 제기되었습니다.

더욱이 이러한 연구들은 대부분 하이퍼파라미터 설정에 대한 완전한 설명이 부족했기 때문에, 서로 다른 컴퓨팅 예산에서 모델들이 최적의 성능에 도달했는지 확실하지 않았습니다. 따라서 연구진은 이러한 불확실성을 해소하고 컴퓨팅의 효율적인 스케일업 경로를 확인하기 위해 스케일링 법칙을 재검토했습니다.

서로 다른 컴퓨팅 예산에서 모델들이 최적의 성능을 달성할 수 있도록 하기 위해, 연구진은 먼저 하이퍼파라미터의 스케일링 법칙을 연구했습니다. 경험적으로 대부분의 파라미터의 최적값은 컴퓨팅 예산이 변화해도 크게 변하지 않는 것으로 관찰되었습니다. 그러나 성능에 가장 큰 영향을 미치는 하이퍼파라미터인 배치 크기와 학습률은 재검토가 필요했습니다.

초기 연구들은 배치 크기와 학습률 설정에 대한 경험적 관찰을 제공했지만, 연구진의 예비 실험에서 이러한 관찰들의 적용 가능성이 제한적임을 발견했습니다. 광범위한 실험을 통해 연구진은 컴퓨팅 예산 $C$와 최적의 배치 크기 및 학습률 사이의 멱법칙 관계를 모델링했습니다.
### 스케일링 법칙의 실험적 검증과 발견

연구진이 발견한 하이퍼파라미터의 스케일링 법칙은 모델의 성능을 최적화하기 위한 경험적 프레임워크를 제공합니다. 이러한 관계를 하이퍼파라미터의 스케일링 법칙이라고 부르며, 이를 통해 서로 다른 컴퓨팅 예산에서 모델들이 근접 최적 성능에 도달할 수 있도록 합니다.

이후 연구진은 모델과 데이터 규모의 스케일링 법칙을 연구했습니다. 실험 비용과 피팅의 어려움을 줄이기 위해 Chinchilla에서 사용된 IsoFLOP 프로파일 접근 방식을 채택하여 스케일링 곡선을 피팅했습니다. 모델 규모를 더 정확하게 표현하기 위해 기존에 사용되던 모델 파라미터 $N$ 대신 비임베딩 FLOPs/토큰 $M$이라는 새로운 모델 규모 표현을 도입했고, 근사적인 컴퓨팅 예산 공식 $C=6ND$를 더 정확한 $C=MD$로 대체했습니다.

실험 결과는 최적의 모델/데이터 스케일링 할당 전략과 성능 예측에 대한 통찰을 제공했으며, DeepSeek LLM 7B와 67B 모델의 예상 성능을 정확하게 예측했습니다. 또한 스케일링 법칙을 탐구하는 과정에서 사용된 데이터는 여러 차례의 반복을 거쳐 품질이 지속적으로 향상되었습니다.

연구진은 다양한 데이터셋에서 스케일링 곡선을 피팅하려 시도했고, 데이터 품질이 최적의 모델/데이터 스케일링 할당 전략에 상당한 영향을 미친다는 것을 발견했습니다. 데이터 품질이 높을수록 증가된 컴퓨팅 예산을 모델 스케일링에 더 많이 할당해야 했습니다. 이는 동일한 데이터 규모에서도 고품질 데이터가 더 큰 모델의 학습을 가능하게 한다는 것을 의미합니다.

최적의 모델/데이터 스케일링 할당 전략의 차이는 데이터 품질을 평가하는 간접적인 방법으로도 활용될 수 있습니다. 연구진은 데이터 품질의 변화와 이것이 스케일링 법칙에 미치는 영향에 대해 지속적으로 주목하고 있으며, 향후 연구에서 더 많은 분석을 제공할 예정입니다.
### 하이퍼파라미터 스케일링 법칙의 실험적 검증

연구진은 먼저 1e17의 컴퓨팅 예산에서 작은 규모의 실험을 통해 배치 크기와 학습률에 대한 격자 탐색을 수행했습니다. 특정 모델 크기(177M FLOPs/토큰)에 대한 결과는 배치 크기와 학습률의 광범위한 선택에 걸쳐 일반화 오차가 안정적으로 유지됨을 보여주었습니다. 이는 상대적으로 넓은 파라미터 공간 내에서 근접 최적 성능을 달성할 수 있다는 것을 시사합니다.

이후 연구진은 앞서 설명한 다단계 학습률 스케줄러를 활용하여 첫 번째 단계를 재사용함으로써 1e17에서 2e19까지의 다양한 컴퓨팅 예산에서 서로 다른 배치 크기와 학습률을 가진 여러 모델을 효과적으로 학습했습니다. 파라미터 공간의 중복성을 고려하여, 일반화 오차가 최소값을 0.25% 이상 초과하지 않는 모델들의 파라미터를 근접 최적 하이퍼파라미터로 간주했습니다.

연구진은 컴퓨팅 예산 $C$에 대한 배치 크기 $B$와 학습률 $\eta$를 피팅했습니다. 피팅 결과는 최적의 배치 크기 $B$가 컴퓨팅 예산 $C$의 증가에 따라 점진적으로 증가하는 반면, 최적의 학습률 $\eta$는 점진적으로 감소함을 보여줍니다. 이는 모델을 스케일업할 때 배치 크기와 학습률에 대한 직관적인 경험적 설정과 일치합니다.

최종적으로 피팅된 배치 크기와 학습률의 공식은 다음과 같습니다.

$$ \eta_{\mathrm{opt}} = 0.3118 \cdot C^{-0.1250} $$
$$ B_{\mathrm{opt}} = 0.2920 \cdot C^{0.3271} $$

연구진은 1e20 컴퓨팅 예산을 가진 일련의 모델들에서 이 공식들을 검증했으며, 특정 모델 크기(2.94B FLOPs/토큰)에 대한 결과는 피팅된 파라미터들이 최적 파라미터 공간의 중심에 위치함을 보여줍니다. 이후 섹션에서도 DeepSeek LLM 7B와 67B 모델들에 대해 피팅된 파라미터들이 유사하게 좋은 성능을 달성했음을 보여줍니다.

그러나 연구진은 아직 컴퓨팅 예산 $C$ 이외의 요인들이 최적 하이퍼파라미터에 미치는 영향을 고려하지 않았습니다. 이는 최적의 배치 크기가 일반화 오차 $L$에만 관련되어 있다고 제안한 일부 초기 연구들과 일치하지 않습니다. 또한 동일한 컴퓨팅 예산을 가진 모델들 사이에서도 모델/데이터 할당이 다른 경우 최적 파라미터 공간이 약간씩 달라지는 것을 관찰했습니다. 이는 하이퍼파라미터 선택과 학습 동역학을 이해하기 위한 추가 연구가 필요함을 시사합니다.

### 최적 모델 및 데이터 스케일링 전략 분석

연구진은 근접 최적 하이퍼파라미터를 도출한 후, 스케일링 곡선을 피팅하고 최적의 모델/데이터 스케일링 할당 전략을 분석했습니다. 이 전략은 모델 스케일링 지수 $a$와 데이터 스케일링 지수 $b$를 찾는 것으로, 각각 $N_{opt} \propto C^a$와 $D_{opt} \propto C^b$를 만족합니다. 데이터 규모 $D$는 데이터셋의 토큰 수로 일관되게 표현될 수 있습니다.

이전 연구들에서는 모델 규모를 주로 모델 파라미터로 표현했는데, 비임베딩 파라미터 $N_1$ (Kaplan과 연구진)과 전체 파라미터 $N_2$ (Hoffmann과 연구진)를 사용했습니다. 컴퓨팅 예산 $C$와 모델/데이터 규모의 관계는 $C = 6ND$로 근사될 수 있었으며, 따라서 $6N_1$ 또는 $6N_2$를 모델 규모의 근사치로 사용할 수 있었습니다.

그러나 $6N_1$과 $6N_2$ 모두 어텐션 연산의 계산 오버헤드를 고려하지 않으며, $6N_2$는 모델 용량에 덜 기여하는 어휘 계산도 포함하기 때문에 특정 설정에서 상당한 근사 오차를 보입니다. 이러한 오차를 줄이기 위해 연구진은 새로운 모델 규모 표현인 비임베딩 FLOPs/토큰 $M$을 도입했습니다. $M$은 어텐션 연산의 계산 오버헤드를 포함하지만 어휘 계산은 고려하지 않습니다. $M$으로 모델 규모를 표현할 때, 컴퓨팅 예산 $C$는 간단히 $C = MD$로 표현될 수 있습니다.

$6N_1$, $6N_2$, $M$ 사이의 구체적인 차이는 다음 수식들로 나타낼 수 있습니다.

$$ 6N_1 = 72n_{layer}d_{model}^2 $$

$$ 6N_2 = 72n_{layer}d_{model}^2 + 6n_{vocab}d_{model} $$

$$ M = 72n_{layer}d_{model}^2 + 12n_{layer}d_{model}l_{seq} $$

여기서 $n_{layer}$는 레이어 수, $d_{model}$은 모델 너비, $n_{vocab}$은 어휘 크기, $l_{seq}$는 시퀀스 길이를 나타냅니다.

![모델 규모 표현 비교](https://ar5iv.org//html/2401.02954/assets/figures/nosafe_flops_per_token_bpb.png)

연구진은 다양한 규모의 모델들에서 이 세 가지 표현 방식의 차이를 평가했습니다. 결과는 $6N_1$과 $6N_2$ 모두 서로 다른 규모의 모델에서 계산 비용을 과대 또는 과소 추정한다는 것을 보여줍니다. 이러한 차이는 특히 소규모 모델에서 두드러지며, 최대 50%까지 차이가 날 수 있습니다. 이러한 부정확성은 스케일링 곡선을 피팅할 때 상당한 통계적 오차를 초래할 수 있습니다.
### 최적 스케일링 전략의 실험적 검증

$M$을 모델 규모 표현으로 채택한 후, 연구진의 목표는 더욱 명확해졌습니다. 주어진 컴퓨팅 예산 $C = MD$에서 모델의 일반화 오차를 최소화하는 최적의 모델 규모 $M_{opt}$와 데이터 규모 $D_{opt}$를 찾는 것입니다. 이는 다음과 같은 수식으로 형식화할 수 있습니다.

$$ M_{opt}(C), D_{opt}(C) = \underset{M,D\,\mathrm{s.t.}\,C=MD}{\mathrm{argmin}}L(N,D) $$

실험 비용과 피팅의 어려움을 줄이기 위해 연구진은 Hoffmann과 연구진이 제안한 IsoFLOP 프로파일 접근 방식을 활용했습니다. 1e17에서 3e20까지 8개의 서로 다른 컴퓨팅 예산을 선택하고, 각 예산에 대해 약 10개의 서로 다른 모델/데이터 규모 할당을 설계했습니다. 각 예산에 대한 하이퍼파라미터는 앞서 도출한 공식을 통해 결정되었으며, 일반화 오차는 학습 세트와 유사하게 분포된 100M 토큰의 독립적인 검증 세트에서 계산되었습니다.

![IsoFLOP 곡선과 스케일링 곡선](https://ar5iv.org//html/2401.02954/assets/figures/nosafe_flops_flops_per_token.png)

연구진은 각 컴퓨팅 예산에 대한 최적의 모델/데이터 할당을 사용하여 IsoFLOP 곡선과 모델/데이터 스케일링 곡선을 피팅했습니다. 최적의 비임베딩 FLOPs/토큰 $M_{opt}$와 최적의 토큰 수 $D_{opt}$에 대한 구체적인 공식은 다음과 같습니다.

$$ M_{opt} = M_{base} \cdot C^a, \quad M_{base} = 0.1715, \quad a = 0.5243 $$
$$ D_{opt} = D_{base} \cdot C^b, \quad D_{base} = 5.8316, \quad b = 0.4757 $$

![성능 스케일링 곡선](https://ar5iv.org//html/2401.02954/assets/figures/flops_bpb.png)

추가로 연구진은 컴퓨팅 예산 $C$와 최적 일반화 오차에 따른 손실 스케일링 곡선을 피팅하여 DeepSeek LLM 7B와 67B의 일반화 오차를 예측했습니다. 결과는 작은 규모의 실험으로도 1000배의 컴퓨팅 예산을 가진 모델의 성능을 정확하게 예측할 수 있다는 것을 보여줍니다. 이는 더 큰 규모의 모델 학습에 대한 확신과 지침을 제공합니다.
### 데이터 품질과 스케일링 법칙의 관계

DeepSeek LLM의 개발 과정에서 연구진은 데이터셋을 여러 차례 반복적으로 개선했으며, 이 과정에서 서로 다른 데이터 소스의 비율을 조정하고 전반적인 품질을 향상시켰습니다. 이를 통해 서로 다른 데이터셋이 스케일링 법칙에 미치는 영향을 심층적으로 분석할 수 있었습니다.

연구진은 세 가지 서로 다른 데이터셋을 사용하여 스케일링 법칙을 연구했습니다. 초기 사내 데이터, 현재 사내 데이터, 그리고 Kaplan과 연구진이 스케일링 법칙 연구에 사용했던 OpenWebText2입니다. 내부 데이터 평가 결과, 현재 사내 데이터는 초기 사내 데이터보다 더 높은 데이터 품질을 보여주었습니다. 더욱이 OpenWebText2는 규모가 작아 더 세밀한 처리가 가능했기 때문에 현재 사내 데이터보다도 더 높은 품질을 보여주었습니다.

분석에서 가장 흥미로운 발견은 이 세 가지 데이터셋에서의 최적 모델/데이터 스케일링 할당 전략이 데이터 품질과 일관된 관계를 보여주었다는 점입니다. 데이터 품질이 향상됨에 따라 모델 스케일링 지수 $a$는 점진적으로 증가하고 데이터 스케일링 지수 $b$는 감소하는 것으로 나타났습니다. 이는 컴퓨팅 예산이 증가할 때 데이터보다 모델에 더 많은 자원을 할당해야 한다는 것을 시사합니다.

이러한 발견은 이전 스케일링 법칙 연구들에서 관찰된 최적 모델/데이터 스케일링 할당의 큰 차이를 설명할 수 있습니다. 고품질 데이터는 일반적으로 논리적 명확성이 높고 충분한 학습 후에는 예측의 어려움이 줄어든다는 점을 고려할 때, 컴퓨팅 예산을 증가시킬 때 모델 크기를 확장하는 것이 더 유리하다는 직관적인 추론이 가능합니다.

연구진은 데이터 품질의 변화와 이것이 스케일링 법칙에 미치는 영향에 대해 지속적으로 주목하고 있으며, 향후 연구에서 더 많은 분석을 제공할 예정입니다. 이러한 연구는 대규모 언어 모델의 효율적인 학습과 확장을 위한 중요한 지침을 제공할 것으로 기대됩니다.

### 모델 학습 데이터셋 구성과 정렬 파이프라인

DeepSeek 연구진은 영어와 중국어로 약 150만 개의 지시 데이터를 수집했습니다. 이 데이터셋은 유용성과 안전성 측면을 모두 고려하여 구성되었습니다. 유용성 관련 데이터는 120만 개의 인스턴스로 구성되어 있으며, 일반 언어 과제가 31.2%, 수학 문제가 46.6%, 코딩 연습이 22.2%의 비율로 분포되어 있습니다. 안전성 관련 데이터는 30만 개의 인스턴스로 구성되어 있으며, 다양한 민감한 주제들을 다루고 있습니다.

연구진의 정렬 파이프라인은 두 단계로 구성됩니다. 첫 번째 단계인 지도 학습 미세조정에서는 7B 모델의 경우 4번의 에포크로, 67B 모델의 경우에는 과적합 문제를 고려하여 2번의 에포크로 학습을 진행했습니다. 학습률은 7B 모델에서는 1e-5, 67B 모델에서는 5e-6로 설정되었습니다. GSM8K와 HumanEval 벤치마크에서 7B 모델은 지속적인 성능 향상을 보였지만, 67B 모델은 빠르게 상한에 도달하는 것이 관찰되었습니다.

연구진은 미세조정 과정에서 채팅 모델의 반복 생성 비율도 모니터링했습니다. 3,868개의 중국어와 영어 프롬프트를 수집하여 생성된 응답이 종료되지 않고 텍스트 시퀀스를 무한히 반복하는 비율을 측정했습니다. 수학 관련 지도 학습 미세조정 데이터의 양이 증가할수록 반복 생성 비율이 높아지는 경향이 관찰되었는데, 이는 수학 데이터에 포함된 유사한 추론 패턴 때문인 것으로 분석되었습니다. 특히 성능이 낮은 모델들은 이러한 추론 패턴을 제대로 학습하지 못해 반복적인 응답을 생성하는 문제가 발생했습니다.

이 문제를 해결하기 위해 연구진은 두 가지 접근 방식을 시도했습니다. 첫째는 2단계 미세조정 방식이고, 둘째는 직접 선호도 최적화(DPO) 방식입니다. 두 방법 모두 벤치마크 점수를 거의 유지하면서도 반복 생성을 크게 줄일 수 있었습니다.

두 번째 단계인 DPO에서는 모델의 능력을 더욱 향상시키기 위해 직접 선호도 최적화 알고리즘을 활용했습니다. 연구진은 유용성과 안전성 측면에서 선호도 데이터를 구성했습니다. 유용성 데이터의 경우, 창의적 글쓰기, 질문 답변, 지시 따르기 등 다양한 카테고리를 포함하는 다국어 프롬프트를 수집했고, DeepSeek Chat 모델을 사용하여 응답 후보를 생성했습니다. 안전성 선호도 데이터도 유사한 방식으로 구성되었습니다.

DPO 학습은 1 에포크 동안 진행되었으며, 학습률은 5e-6, 배치 크기는 512로 설정되었습니다. 또한 학습률 웜업과 코사인 학습률 스케줄러를 적용했습니다. 연구 결과, DPO는 표준 벤치마크에서의 성능은 거의 그대로 유지하면서도 모델의 개방형 생성 능력을 강화할 수 있다는 것이 확인되었습니다.

### 모델 평가 방법론과 벤치마크 구성

DeepSeek LLM의 성능을 평가하기 위해 연구진은 영어와 중국어 모두에서 다양한 공개 벤치마크를 활용했습니다. 평가 프레임워크는 크게 다중 과목 선택형 데이터셋, 언어 이해 및 추론 데이터셋, 비공개 질의응답 데이터셋, 독해력 데이터셋, 참조 모호성 해소 데이터셋, 언어 모델링 데이터셋, 중국어 이해 및 문화 데이터셋, 수학 데이터셋, 코드 데이터셋, 그리고 표준화된 시험 데이터셋으로 구성되어 있습니다.

다중 과목 선택형 데이터셋에는 MMLU, C-Eval, CMMLU가 포함되어 있으며, 이들은 각각 영어와 중국어로 된 광범위한 학문 분야의 지식을 평가합니다. 언어 이해 및 추론 능력은 HellaSwag, PIQA, ARC, OpenBookQA, BigBench Hard(BBH)를 통해 평가됩니다. 비공개 질의응답 능력은 TriviaQA와 NaturalQuestions를 통해 측정되며, 독해력은 RACE와 DROP, C3 데이터셋을 통해 평가됩니다.

참조 모호성 해소 능력은 WinoGrande와 CLUEWSC를 통해 테스트되며, 언어 모델링 성능은 Pile 데이터셋을 통해 평가됩니다. 중국어 특화 평가를 위해서는 CHID와 CCPM이 사용되었고, 수학적 능력은 GSM8K, MATH, CMath를 통해 평가되었습니다. 코딩 능력은 HumanEval과 MBPP를 통해 측정되었으며, 종합적인 능력 평가를 위해 AGIEval이 활용되었습니다.

평가 방식은 크게 세 가지로 나뉩니다. 첫째, 선택형 문항이 있는 데이터셋(HellaSwag, PIQA 등)에는 퍼플렉시티 기반 평가를 적용했습니다. 이는 각 선택지의 퍼플렉시티를 계산하고 가장 낮은 값을 가진 선택지를 모델의 예측으로 선택하는 방식입니다. ARC와 OpenBookQA의 경우 무조건부 정규화를, 다른 데이터셋에는 길이 정규화를 적용했습니다.

둘째, TriviaQA, NaturalQuestions, DROP 등의 데이터셋에는 생성 기반 평가를 적용했습니다. 이는 모델이 자유롭게 텍스트를 생성하고 생성된 텍스트에서 결과를 파싱하는 방식입니다. 생성 기반 평가에서는 탐욕적 디코딩(greedy decoding)을 사용했습니다.

셋째, Pile-test에는 언어 모델링 기반 평가를 적용했으며, 이는 테스트 코퍼스에서의 바이트당 비트(bits-per-byte)를 계산하는 방식입니다. 평가를 위한 최대 시퀀스 길이는 벤치마크에 따라 2048 또는 4096으로 설정되었습니다.
### 베이스 모델의 성능 평가 결과

DeepSeek LLM의 베이스 모델 성능 평가 결과는 LLaMA2와의 비교를 통해 분석되었습니다. 영어 언어 이해 벤치마크에서 DeepSeek 모델은 2조 개의 이중 언어 코퍼스로 학습되었음에도 불구하고, 영어에 중점을 둔 LLaMA2와 비슷한 수준의 성능을 보여주었습니다. 특히 주목할 만한 점은 DeepSeek 67B가 MATH, GSM8K, HumanEval, MBPP, BBH와 같은 수학 및 코딩 관련 벤치마크와 중국어 벤치마크에서 LLaMA2 70B를 크게 앞섰다는 것입니다.

모델 규모에 따른 성능 향상을 분석한 결과, GSM8K와 BBH와 같은 일부 과제에서는 모델 크기가 증가함에 따라 성능이 크게 향상되는 것으로 나타났습니다. 7B와 67B 모델이 동일한 데이터셋에서 학습되었다는 점을 고려할 때, 이러한 성능 향상은 대규모 모델의 강력한 퓨 샷 학습 능력에 기인한 것으로 해석됩니다. 다만, 수학적 데이터의 비중이 증가할수록 소규모와 대규모 모델 간의 성능 차이는 감소하는 경향을 보였습니다.

흥미로운 발견은 DeepSeek 67B와 LLaMA2 70B 사이의 성능 격차가 DeepSeek 7B와 LLaMA2 7B 사이의 격차보다 더 크다는 점입니다. 이는 언어 충돌이 소규모 모델에 더 큰 영향을 미친다는 것을 시사합니다. 또한 LLaMA2는 중국어 데이터로 특별히 학습되지 않았음에도 CMath와 같은 특정 중국어 과제에서 인상적인 성능을 보여주었습니다. 이는 수학적 추론과 같은 기본적인 능력이 언어 간에 효과적으로 전이될 수 있다는 것을 보여줍니다. 그러나 CHID와 같이 중국어 관용구의 사용을 평가하는 과제에서는 LLaMA2가 DeepSeek LLM에 비해 현저히 낮은 성능을 보였는데, 이는 사전학습 과정에서 상당한 양의 중국어 토큰을 소비해야 하는 과제의 특성을 반영합니다.
### 채팅 모델의 성능 평가 결과

DeepSeek 채팅 모델의 성능 평가 결과는 대부분의 과제에서 미세조정 후 전반적인 향상을 보여주었습니다. 지식 관련 과제에서는 TriviaQA, MMLU, C-Eval과 같은 벤치마크에서 베이스 모델과 채팅 모델 간의 성능 변동이 관찰되었습니다. 그러나 이러한 변동이 지도 학습 미세조정(SFT) 이후 지식의 획득이나 손실을 의미하지는 않습니다. SFT의 진정한 가치는 베이스 모델의 퓨 샷 설정에서 달성한 것과 비슷한 점수를 채팅 모델이 제로 샷 설정에서도 달성할 수 있다는 점에 있으며, 이는 실제 사용 시나리오와도 부합합니다.

추론 능력 측면에서는 SFT 인스턴스의 상당 부분이 체인오브소트 형식으로 구성되어 있어, 채팅 모델은 BBH와 NaturalQuestions와 같은 추론 과제에서 약간의 성능 향상을 보여주었습니다. 그러나 연구진은 SFT 단계가 추론 능력 자체를 학습하는 것이 아니라 추론 경로의 올바른 형식을 학습하는 것이라고 분석했습니다.

모델 크기나 사전학습된 체크포인트와 관계없이 일부 과제에서는 미세조정 후 성능이 일관되게 하락했습니다. 이러한 과제들은 주로 HellaSwag와 같은 빈칸 채우기나 문장 완성 과제였습니다. 이는 순수한 언어 모델이 이러한 유형의 과제를 더 잘 처리할 수 있다는 것을 시사합니다.

수학과 코드 분야에서는 미세조정 후 상당한 성능 향상이 관찰되었습니다. 특히 HumanEval과 GSM8K에서는 20포인트 이상의 점수 향상이 있었습니다. 연구진은 이러한 현상이 베이스 모델이 이러한 과제에 대해 초기에 과소적합 상태였고, SFT 단계에서 방대한 SFT 데이터를 통해 코딩과 수학 분야의 추가 지식을 학습했기 때문이라고 설명합니다. 그러나 모델의 능력이 주로 코드 완성과 대수학적 문제에 집중되어 있다는 점에 주목해야 합니다. 수학과 코딩에 대한 포괄적인 이해를 위해서는 사전학습 단계에서 다양한 데이터를 통합하는 것이 중요하며, 이는 향후 연구 과제로 남아있습니다.

7B 모델의 미세조정에서는 먼저 모든 데이터를 사용하여 모델을 미세조정한 후, 두 번째 단계에서는 수학과 코드 데이터를 제외하고 진행했습니다. 이러한 접근 방식을 채택한 이유는 1단계 모델에서 2.0%였던 반복 비율이 2단계 미세조정 후 1.4%로 감소하면서도 벤치마크 점수를 유지할 수 있었기 때문입니다. 67B 모델의 경우, 첫 번째 단계 미세조정 후 이미 반복 비율이 1% 미만이었고, 두 번째 단계는 오히려 벤치마크 점수를 저하시켰기 때문에 한 단계의 SFT만 진행되었습니다.
### AlignBench를 통한 중국어 오픈 평가 결과

DeepSeek 67B 채팅 모델은 AlignBench 리더보드에서 ChatGPT와 다른 기준 모델들을 크게 앞서는 성능을 보여주었습니다. 이는 기본적인 중국어 언어 과제와 고급 중국어 추론 과제 모두에서 모델의 우수한 성능을 입증합니다. DPO 과정을 거친 후에는 거의 모든 분야에서 성능이 향상되었습니다.

AlignBench 평가 결과에서 DeepSeek 67B 채팅 모델은 GPT-4의 두 버전에 이어 3위를 기록했습니다. 특히 기본적인 중국어 언어 과제에서는 최신 버전의 GPT-4보다도 높은 점수를 달성했습니다. 고급 중국어 추론 과제에서도 다른 중국어 LLM들과 비교하여 월등히 높은 점수를 기록했으며, 이는 복잡한 중국어 논리 추론과 수학적 계산에서 모델의 우수한 성능을 보여줍니다.

### 영어 오픈 평가 결과

영어 오픈 평가를 위해 MT-Bench 벤치마크를 활용했으며, 이는 8가지 다른 카테고리의 다중 턴 질문들로 구성되어 있습니다. DeepSeek LLM 67B 채팅 모델은 LLaMA-2-Chat 70B, Xwin 70b v0.1, TÜLU 2+DPO 70B와 같은 다른 오픈소스 모델들을 능가하는 성능을 보여주었으며, GPT-3.5-turbo와 비슷한 수준인 8.35점을 달성했습니다. DPO 단계를 거친 후에는 평균 점수가 8.76으로 더욱 향상되어 GPT-4에 이어 두 번째로 높은 성능을 기록했습니다. 이러한 결과는 DeepSeek LLM의 강력한 다중 턴 오픈 생성 능력을 입증합니다.

### 홀드아웃 평가 결과

데이터 오염과 벤치마크 과적합 문제를 해결하기 위해 최근 공개된 테스트셋을 홀드아웃 평가에 활용했습니다. LeetCode 주간 대회(Weekly Contest 351-372, Bi-Weekly Contest 108-117)의 문제들을 크롤링하여 코딩 능력을 평가했으며, 각 문제마다 20개 이상의 테스트 케이스를 포함한 총 126개의 문제로 구성되었습니다. 헝가리 국가 고등학교 시험을 통해 수학적 능력을 평가했으며, 33개의 문제에 대한 점수는 인간 주석을 통해 결정되었습니다. 또한 구글이 2023년 11월 15일에 공개한 지시 따르기 평가 데이터셋을 활용했습니다.
### 안전성 평가 결과

DeepSeek 연구진은 일반 인공지능의 안전성이 갖는 중요성을 깊이 인식하고 있습니다. 진정으로 도움이 되는 인공지능 모델을 구축하기 위한 전제 조건은 인간의 가치와 일치하는 가치관을 가지고 인류에 대한 친화성을 보여주는 것입니다. 이를 위해 연구진은 사전학습, SFT, DPO를 포함한 전체 학습 과정에 걸쳐 모델의 안전성 보장을 통합했습니다.

모델의 안전성을 검증하기 위해 연구진은 다양한 분야의 전문가 20명으로 구성된 팀을 구성하고 인간의 가치와 부합하는 안전 콘텐츠 분류 체계를 구축했습니다. 전문가 팀은 각 안전성 하위 카테고리에 대해 수십 개의 고품질 테스트 케이스를 수작업으로 구성했습니다. 안전 콘텐츠 영역의 다양성뿐만 아니라 안전 콘텐츠의 형식 다양성에도 주목했습니다.

악명 높은 "할머니" 취약점은 모델이 쿼리의 표면적 형식에 속아 안전하지 않은 응답을 제공할 수 있다는 것을 보여줍니다. 따라서 전문가 팀은 유도, 역할극, 다중 턴 대화, 사전 설정된 입장 등 다양한 방식을 통해 질문을 구성하는 데 주의를 기울였습니다. 최종적으로 2,400개의 질문으로 구성된 안전성 테스트 세트를 구축했습니다.

전문가 팀은 각각의 콘텐츠 유형과 형식 유형에 대한 기본적인 안전성 검토 지침도 구성했습니다. 이 테스트 세트에 대한 모델의 출력 결과를 수동으로 검사했으며, 검토 팀은 충분한 훈련을 받았고 주석 결과에 대한 교차 검증이 수행되었습니다. 주석자들은 각 질문에 대해 안전, 불안전, 모델 거부의 세 가지 카테고리로 주석을 수행했습니다.

추가로 연구진은 "Do-Not-Answer" 데이터셋을 활용하여 DeepSeek 67B 채팅 모델의 안전 메커니즘을 평가했습니다. 939개의 위험 분류된 프롬프트로 구성된 이 데이터셋에서 DeepSeek 67B 채팅 모델은 97.8점을 달성하여 ChatGPT와 GPT-4를 모두 능가하는 성능을 보여주었습니다. 이는 모델이 민감한 쿼리를 안전하게 처리하는 능력이 뛰어나다는 것을 입증합니다.

- - -
### References
* [DeepSeek LLM: Scaling Open-Source Language Models with Longtermism](http://arxiv.org/pdf/2401.02954v1)